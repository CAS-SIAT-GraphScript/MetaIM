{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('/home/zjy/project/MetaIM')\n",
    "pwd = '/home/zjy/project/MetaIM'\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "cora_dataset = Planetoid(root=pwd+'/data/cora', name='cora')\n",
    "data = cora_dataset[0]\n",
    "edge_index = data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 2708), (1000, 2, 2708))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "individual_infection_path = pwd+'/data/for_meta/cora_individual_infection_sir_200.npy'\n",
    "seeds_infection_path = pwd+'/data/for_meta/cora_seed_infection_sir_200_sample_1000.npy'\n",
    "\n",
    "individual_infection = np.load(individual_infection_path)\n",
    "seeds_infection = np.load(seeds_infection_path)\n",
    "individual_infection.shape,seeds_infection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, individual_infection,seeds_infection):\n",
    "        self.individual_infection = individual_infection\n",
    "        self.seeds_infection = seeds_infection\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seeds_infection)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        return self.seeds_infection[idx][0], self.seeds_infection[idx][1]\n",
    "\n",
    "dataset = CustomDataset(individual_infection, seeds_infection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义划分比例\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "# 划分数据集\n",
    "train_dataset, test_dataset = random_split(dataset, [int(len(dataset)*train_ratio), int(len(dataset)*test_ratio)])\n",
    "\n",
    "train_batch_size = 32\n",
    "test_batch_size = 2\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 自定义 Dataset 类\n",
    "class MatrixDataset(Dataset):\n",
    "    def __init__(self, matrix):\n",
    "        self.matrix = matrix\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matrix)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.matrix[idx]\n",
    "        return torch.tensor(sample, dtype=torch.float)\n",
    "\n",
    "\n",
    "\n",
    "# 创建自定义 Dataset 对象\n",
    "dataset = MatrixDataset(individual_infection)\n",
    "\n",
    "# 创建 DataLoader 对象\n",
    "vae_train_batch_size = 32\n",
    "vae_data_loader = DataLoader(dataset, batch_size=vae_train_batch_size, shuffle=True)\n",
    "\n",
    "# # 遍历 DataLoader 加载数据\n",
    "# for batch_idx, data in enumerate(vae_data_loader):\n",
    "#     # data 是一个包含了 batch_size 个样本的张量，每个样本的形状为 (10,)，代表矩阵的一行数据\n",
    "#     # 在这里可以将 data 输入模型进行训练\n",
    "#     print(\"Batch\", batch_idx, \"Data shape:\", data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.FC_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.FC_input2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # self.bn = nn.BatchNorm1d(latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_ = F.relu(self.FC_input(x))\n",
    "        h_ = F.relu(self.FC_input2(h_))\n",
    "        h_ = F.relu(self.FC_input2(h_))\n",
    "        output = self.FC_output(h_)\n",
    "\n",
    "        return output\n",
    "\n",
    "# class GCNEncoder(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Simple GCN-structured Encoder\n",
    "#     \"\"\"\n",
    "#     def __init__(self, input_dim, hidden_dim, latent_dim, gcn_outdim, out_dim, dropout=0.0):\n",
    "#         super(GCNEncoder, self).__init__()\n",
    "#         self.gc1 = GCNConv(input_dim, hidden_dim)\n",
    "#         self.gc2 = GCNConv(hidden_dim, latent_dim)\n",
    "#         self.FC_mean = nn.Linear(2810*latent_dim, out_dim)\n",
    "#         self.FC_var = nn.Linear(2810*latent_dim, out_dim)\n",
    "        \n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "#     def forward(self, x, adj):\n",
    "#         # x = self.dropout(x)\n",
    "#         x = F.relu(self.gc1(x, adj))\n",
    "#         x = self.dropout(x)\n",
    "#         x = F.relu(self.gc2(x, adj))\n",
    "#         '''\n",
    "#         # max pooling over nodes\n",
    "#         x = torch.max(x, dim=1)[0].squeeze()\n",
    "#         '''\n",
    "#         mean = self.FC_mean(x.view(8, -1))\n",
    "#         log_var = self.FC_var(x.view(8, -1))\n",
    "#         return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.FC_input = nn.Linear(input_dim, latent_dim)\n",
    "        self.FC_hidden_1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.FC_hidden_2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.FC_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.prelu = nn.PReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.FC_input(x))\n",
    "        h = F.relu(self.FC_hidden_1(h))\n",
    "        h = F.relu(self.FC_hidden_2(h))\n",
    "        # x_hat = self.FC_output(h)\n",
    "        x_hat = F.sigmoid(self.FC_output(h))\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEModel(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super(VAEModel, self).__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "        \n",
    "    def reparameterization(self, mean, var):\n",
    "        std = torch.exp(0.5*var) # standard deviation\n",
    "        epsilon = torch.randn_like(var)\n",
    "        return mean + std*epsilon\n",
    "\n",
    "    def forward(self, x, adj=None):\n",
    "        if adj != None:\n",
    "            mean,log_var = self.Encoder(x, adj)\n",
    "        else:\n",
    "            z = self.Encoder(x)\n",
    "        # z = mean + log_var # takes exponential function (log var -> var)\n",
    "        x_hat = self.Decoder(z)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAEModel(\n",
       "  (Encoder): Encoder(\n",
       "    (FC_input): Linear(in_features=2708, out_features=1024, bias=True)\n",
       "    (FC_input2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (FC_output): Linear(in_features=1024, out_features=128, bias=True)\n",
       "  )\n",
       "  (Decoder): Decoder(\n",
       "    (FC_input): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (FC_hidden_1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "    (FC_hidden_2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (FC_output): Linear(in_features=1024, out_features=2708, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from data import model \n",
    "# from data.model.model import VAEModel, Encoder, Decoder\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# # hidden_dim = 256\n",
    "# # latent_dim = 64\n",
    "hidden_dim = 1024\n",
    "latent_dim = 128\n",
    "\n",
    "encoder = Encoder(input_dim= len(seeds_infection[0][0]), \n",
    "                  hidden_dim=hidden_dim, \n",
    "                  latent_dim=latent_dim)\n",
    "# encoder = GCNEncoder(input_dim= len(seeds_infection[0][0]), \n",
    "#                   hidden_dim=hidden_dim, \n",
    "#                   latent_dim=latent_dim)\n",
    "\n",
    "decoder = Decoder(input_dim=latent_dim, \n",
    "                  latent_dim=latent_dim, \n",
    "                  hidden_dim=hidden_dim, \n",
    "                  output_dim=len(seeds_infection[0][0]))\n",
    "\n",
    "vae_model = VAEModel(Encoder=encoder, Decoder=decoder).to(device)\n",
    "\n",
    "optimizer_vae = Adam([{'params': vae_model.parameters()}], \n",
    "                 lr=1e-3)\n",
    "vae_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "Epoch: 1 \tTrain_vae_loss: 0.0588\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "Epoch: 2 \tTrain_vae_loss: 0.0564\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "Epoch: 3 \tTrain_vae_loss: 0.0539\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "Epoch: 4 \tTrain_vae_loss: 0.0518\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "Epoch: 5 \tTrain_vae_loss: 0.0496\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n",
      "\tTest_accuracy: 1.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m     train_vae_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     39\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m/\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     41\u001b[0m     optimizer_vae\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain_vae_loss: \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_vae_loss \u001b[38;5;241m/\u001b[39m count),\n\u001b[1;32m     45\u001b[0m     )\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param in vae_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for epoch in range(200):\n",
    "    train_vae_loss = 0\n",
    "    mean_train_accuracy = 0\n",
    "    count = 0\n",
    "    for batch_idx, seeds_label in enumerate(train_loader): \n",
    "        count += 1       \n",
    "        x = seeds_label[0].to(device)\n",
    "        optimizer_vae.zero_grad()\n",
    "        loss = 0\n",
    "        for i, x_i in enumerate(x):\n",
    "            x_hat = vae_model(x_i)\n",
    "\n",
    "            reproduction_loss = F.binary_cross_entropy(x_hat, x_i, reduction='sum')   \n",
    "            # reproduction_loss = F.mse_loss(x_hat, x_i, reduction='sum')   \n",
    "            loss += reproduction_loss  \n",
    "            \n",
    "             \n",
    "            _, top_seeds_predict = torch.topk(x_hat, seed_num)\n",
    "            _, top_seeds_true = torch.topk(x_i, seed_num)\n",
    "\n",
    "        \n",
    "            # 将张量数组转换为Python列表\n",
    "            list_pre = top_seeds_predict.tolist()\n",
    "            list_true = top_seeds_true.tolist()\n",
    "\n",
    "\n",
    "            # 使用集合操作找到交集\n",
    "            intersection = list(set(list_pre) & set(list_true))\n",
    "            accuracy = len(intersection) / seed_num  \n",
    "            if accuracy > 0:\n",
    "                print(\n",
    "                        \"\\tTest_accuracy: {:.4f}\".format(accuracy)\n",
    "                    ) \n",
    "            \n",
    "        train_vae_loss += loss.item()\n",
    "        loss = loss/x.size(0)\n",
    "        loss.backward()\n",
    "        optimizer_vae.step()\n",
    "        \n",
    "    print(\"Epoch: {}\".format(epoch+1), \n",
    "        \"\\tTrain_vae_loss: {:.4f}\".format(train_vae_loss / count),\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, seeds_dim, inflect_dim, hidden_channels, out_channels, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.linear1 = nn.Linear(seeds_dim + inflect_dim, seeds_dim + inflect_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(seeds_dim + inflect_dim)\n",
    "        self.conv1 = GATConv(seeds_dim + inflect_dim, hidden_channels, heads=num_heads)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_channels * num_heads)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels * num_heads, heads=1)\n",
    "        self.bn3 = nn.BatchNorm1d(seeds_dim)\n",
    "        self.linear2 = nn.Linear(hidden_channels * num_heads + seeds_dim, out_channels)\n",
    "\n",
    "    def forward(self, seeds_i, inflect_i, edge_index):\n",
    "        x =  torch.cat((seeds_i, inflect_i), dim=-1)\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        seeds_i = self.bn3(seeds_i)\n",
    "        x =  torch.cat((x, seeds_i), dim=-1)\n",
    "        x = self.linear2(x)\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# 转换为 scipy 稀疏矩阵\n",
    "adj = to_scipy_sparse_matrix(edge_index)\n",
    "\n",
    "adj = torch.Tensor(adj.toarray()).to_sparse()\n",
    "adj = adj.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1): GATConv(256, 512, heads=4)\n",
       "  (bn2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): GATConv(2048, 2048, heads=1)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (linear2): Linear(in_features=2176, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflect_dim = latent_dim\n",
    "seeds_dim = latent_dim\n",
    "\n",
    "forward_model = GAT(seeds_dim,inflect_dim, 512, 1, 4)\n",
    "\n",
    "optimizer = Adam([{'params': forward_model.parameters()}], \n",
    "                 lr=0.0001)\n",
    "\n",
    "adj = adj.to(device)\n",
    "forward_model = forward_model.to(device)\n",
    "forward_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in vae_model.parameters():\n",
    "    param.requires_grad = False \n",
    "encoder = vae_model.Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0069, 0.0076,  ..., 0.0000, 0.0070, 0.0076],\n",
       "        [0.0028, 1.0000, 0.1019,  ..., 0.0000, 0.0028, 0.0029],\n",
       "        [0.0273, 0.1277, 1.0000,  ..., 0.0000, 0.0273, 0.0287],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
       "        [0.0050, 0.0048, 0.0055,  ..., 0.0000, 1.0000, 0.1276],\n",
       "        [0.0156, 0.0150, 0.0170,  ..., 0.0000, 0.1388, 1.0000]],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflected = torch.tensor(individual_infection).T.detach().to(device)\n",
    "inflected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTotal: 210.8944 \tMean_train_accuracy: 0.7807\n",
      "\tMean_test_accuracy: 0.7798\n",
      "Epoch: 2 \tTotal: 207.9959 \tMean_train_accuracy: 0.7835\n",
      "\tMean_test_accuracy: 0.7860\n",
      "Epoch: 3 \tTotal: 208.9373 \tMean_train_accuracy: 0.7841\n",
      "\tMean_test_accuracy: 0.7838\n",
      "Epoch: 4 \tTotal: 205.9480 \tMean_train_accuracy: 0.7858\n",
      "\tMean_test_accuracy: 0.7854\n",
      "Epoch: 5 \tTotal: 205.6588 \tMean_train_accuracy: 0.7868\n",
      "\tMean_test_accuracy: 0.7887\n",
      "Epoch: 6 \tTotal: 206.1344 \tMean_train_accuracy: 0.7875\n",
      "\tMean_test_accuracy: 0.7895\n",
      "Epoch: 7 \tTotal: 208.9184 \tMean_train_accuracy: 0.7859\n",
      "\tMean_test_accuracy: 0.7937\n",
      "Epoch: 8 \tTotal: 207.3111 \tMean_train_accuracy: 0.7884\n",
      "\tMean_test_accuracy: 0.7877\n",
      "Epoch: 9 \tTotal: 204.6173 \tMean_train_accuracy: 0.7912\n",
      "\tMean_test_accuracy: 0.7966\n",
      "Epoch: 10 \tTotal: 203.3069 \tMean_train_accuracy: 0.7923\n",
      "\tMean_test_accuracy: 0.7885\n",
      "Epoch: 11 \tTotal: 203.7345 \tMean_train_accuracy: 0.7916\n",
      "\tMean_test_accuracy: 0.7924\n",
      "Epoch: 12 \tTotal: 201.4554 \tMean_train_accuracy: 0.7942\n",
      "\tMean_test_accuracy: 0.7953\n",
      "Epoch: 13 \tTotal: 203.2625 \tMean_train_accuracy: 0.7950\n",
      "\tMean_test_accuracy: 0.7952\n",
      "Epoch: 14 \tTotal: 204.0290 \tMean_train_accuracy: 0.7937\n",
      "\tMean_test_accuracy: 0.7951\n",
      "Epoch: 15 \tTotal: 200.4645 \tMean_train_accuracy: 0.7965\n",
      "\tMean_test_accuracy: 0.8033\n",
      "Epoch: 16 \tTotal: 201.8355 \tMean_train_accuracy: 0.7969\n",
      "\tMean_test_accuracy: 0.7993\n",
      "Epoch: 17 \tTotal: 198.7590 \tMean_train_accuracy: 0.7996\n",
      "\tMean_test_accuracy: 0.7976\n",
      "Epoch: 18 \tTotal: 198.7652 \tMean_train_accuracy: 0.8003\n",
      "\tMean_test_accuracy: 0.8029\n",
      "Epoch: 19 \tTotal: 200.7737 \tMean_train_accuracy: 0.7993\n",
      "\tMean_test_accuracy: 0.8048\n",
      "Epoch: 20 \tTotal: 209.4598 \tMean_train_accuracy: 0.7908\n",
      "\tMean_test_accuracy: 0.7988\n",
      "Epoch: 21 \tTotal: 208.7533 \tMean_train_accuracy: 0.7946\n",
      "\tMean_test_accuracy: 0.8001\n",
      "Epoch: 22 \tTotal: 198.1147 \tMean_train_accuracy: 0.8032\n",
      "\tMean_test_accuracy: 0.8028\n",
      "Epoch: 23 \tTotal: 196.2253 \tMean_train_accuracy: 0.8045\n",
      "\tMean_test_accuracy: 0.8072\n",
      "Epoch: 24 \tTotal: 195.1395 \tMean_train_accuracy: 0.8058\n",
      "\tMean_test_accuracy: 0.8026\n",
      "Epoch: 25 \tTotal: 196.2327 \tMean_train_accuracy: 0.8059\n",
      "\tMean_test_accuracy: 0.8016\n",
      "Epoch: 26 \tTotal: 195.5655 \tMean_train_accuracy: 0.8067\n",
      "\tMean_test_accuracy: 0.8129\n",
      "Epoch: 27 \tTotal: 195.1420 \tMean_train_accuracy: 0.8088\n",
      "\tMean_test_accuracy: 0.8112\n",
      "Epoch: 28 \tTotal: 193.8551 \tMean_train_accuracy: 0.8101\n",
      "\tMean_test_accuracy: 0.8103\n",
      "Epoch: 29 \tTotal: 204.0592 \tMean_train_accuracy: 0.7951\n",
      "\tMean_test_accuracy: 0.8032\n",
      "Epoch: 30 \tTotal: 198.9379 \tMean_train_accuracy: 0.8052\n",
      "\tMean_test_accuracy: 0.7998\n",
      "Epoch: 31 \tTotal: 196.7543 \tMean_train_accuracy: 0.8092\n",
      "\tMean_test_accuracy: 0.8125\n",
      "Epoch: 32 \tTotal: 193.3001 \tMean_train_accuracy: 0.8120\n",
      "\tMean_test_accuracy: 0.8083\n",
      "Epoch: 33 \tTotal: 194.3995 \tMean_train_accuracy: 0.8122\n",
      "\tMean_test_accuracy: 0.8135\n",
      "Epoch: 34 \tTotal: 193.8226 \tMean_train_accuracy: 0.8134\n",
      "\tMean_test_accuracy: 0.8057\n",
      "Epoch: 35 \tTotal: 194.1744 \tMean_train_accuracy: 0.8134\n",
      "\tMean_test_accuracy: 0.8193\n",
      "Epoch: 36 \tTotal: 193.5687 \tMean_train_accuracy: 0.8146\n",
      "\tMean_test_accuracy: 0.8078\n"
     ]
    }
   ],
   "source": [
    "edge_index = edge_index.to(device)\n",
    "top_num = 500\n",
    "for param in forward_model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for epoch in range(2000):\n",
    "\n",
    "    total_loss = 0\n",
    "    \n",
    "\n",
    "    total_train_accuracy = 0\n",
    "    \n",
    "    count_train = 0\n",
    "    for batch_idx, seeds_label in enumerate(train_loader): \n",
    "        count_train += 1\n",
    "        forward_loss = 0 \n",
    "        seeds =  seeds_label[0].to(device)     \n",
    "        labels = seeds_label[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        train_accuracy = 0\n",
    "        for i, seeds_i in enumerate(seeds):\n",
    "            infection = inflected * torch.unsqueeze(seeds_i, 1)\n",
    "\n",
    "            \n",
    "            infection_i = encoder(infection).detach()\n",
    "            seeds_i = encoder(seeds_i).detach()\n",
    "            seeds_i = seeds_i.expand(seeds.shape[1], -1)\n",
    "            \n",
    "            y_i = labels[i]\n",
    "            y_hat = forward_model(seeds_i, infection_i, edge_index)\n",
    "            \n",
    "            \n",
    "            \n",
    "            _, top_indices_true = torch.topk(y_i.clone(), top_num)\n",
    "            label_2 = torch.zeros(y_i.shape).to(device)\n",
    "            label_2[top_indices_true] = 1\n",
    "            \n",
    "            _, top_indices_predict = torch.topk(y_hat.clone().squeeze(-1), top_num)\n",
    "            \n",
    "            # 将张量数组转换为Python列表\n",
    "            list1 = top_indices_true.tolist()\n",
    "            list_pre = top_indices_predict.tolist()\n",
    "\n",
    "            # 使用集合操作找到交集\n",
    "            intersection = list(set(list1) & set(list_pre))\n",
    "            accuracy_i = len(intersection) / top_num       \n",
    "            train_accuracy += accuracy_i \n",
    "\n",
    "            forward_loss = 0.5*F.mse_loss(y_hat.squeeze(-1), y_i, reduction='sum') + F.mse_loss(y_hat.squeeze(-1), label_2, reduction='sum')    \n",
    "            loss += forward_loss    \n",
    "        \n",
    "           \n",
    "        train_accuracy /= seeds.size(0)\n",
    "        total_train_accuracy += train_accuracy\n",
    "        loss = loss/seeds.size(0)\n",
    "        total_loss += loss.item() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # for p in forward_model.parameters():\n",
    "        #     p.data.clamp_(min=0)\n",
    "        \n",
    "\n",
    "    print(\"Epoch: {}\".format(epoch+1), \n",
    "        \"\\tTotal: {:.4f}\".format(total_loss / count_train),\n",
    "        \"\\tMean_train_accuracy: {:.4f}\".format(total_train_accuracy/ count_train),\n",
    "        )  \n",
    "    \n",
    "    total_test_accuracy = 0\n",
    "    \n",
    "    count_test = 0\n",
    "\n",
    "    for batch_idx, seeds_label in enumerate(test_loader): \n",
    "        count_test += 1 \n",
    "        seeds =  seeds_label[0].to(device)     \n",
    "        labels = seeds_label[1].to(device)\n",
    "        test_accuracy = 0\n",
    "        for i, seeds_i in enumerate(seeds):\n",
    "            infection = inflected * torch.unsqueeze(seeds_i, 1)\n",
    "\n",
    "            \n",
    "            infection_i = encoder(infection).detach()\n",
    "            seeds_i = encoder(seeds_i).detach()\n",
    "            seeds_i = seeds_i.expand(seeds.shape[1], -1)\n",
    "            \n",
    "            y_i = labels[i]\n",
    "            \n",
    "            y_hat = forward_model(seeds_i, infection_i, edge_index)\n",
    "            \n",
    "            _, top_indices_true = torch.topk(y_i, top_num)\n",
    "            \n",
    "            \n",
    "            _, top_indices_predict = torch.topk(y_hat.squeeze(-1), top_num)\n",
    "\n",
    "            \n",
    "            # 将张量数组转换为Python列表\n",
    "            list1 = top_indices_true.tolist()\n",
    "            list_pre = top_indices_predict.tolist()\n",
    "            \n",
    "\n",
    "            # 使用集合操作找到交集\n",
    "            intersection = list(set(list1) & set(list_pre))\n",
    "\n",
    "            \n",
    "            accuracy_i = len(intersection) / top_num       \n",
    "            test_accuracy += accuracy_i \n",
    "        test_accuracy /= len(seeds)\n",
    "        total_test_accuracy += test_accuracy\n",
    "        \n",
    "\n",
    "    print(\n",
    "        \"\\tMean_test_accuracy: {:.4f}\".format(total_test_accuracy / count_test),\n",
    "        )  \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = int(seeds_infection[0][0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-15.8256,   9.3942, -14.5716,  -1.8016, -10.9304,  -9.0476,   1.9405,\n",
       "         -5.9418,  -7.2755,  -2.3160,  -8.8318,   3.6691,  -9.6138,  -7.4737,\n",
       "          2.0120,   9.9650,  -2.9229,   5.9986,  19.6495,  -6.0859, -12.0895,\n",
       "          2.7196,  -1.5339,  -2.7836,  -8.3204,  18.9299,   1.8092,  -5.8844,\n",
       "         -1.5355,  -1.5399,  -3.7231,   5.7365,  -1.9843,   1.3458, -10.2723,\n",
       "        -13.9716,   3.7695, -15.2706,   8.1369,  -6.6956,  11.0900, -11.0053,\n",
       "        -14.4424,  -8.1227,   9.4071,   0.5336,  -3.5448,  -7.9275,   3.4934,\n",
       "          1.5888,   0.8160,  -3.6923,  -5.1798,   2.7547,  -1.1598,  -0.9557,\n",
       "          0.6237,   1.6972,   2.9166,  -3.7392,   3.8625,  -6.5930,   4.7135,\n",
       "          2.9414,  -3.0494,  -2.6371,   3.9670,   3.8667,   2.4902,   4.5109,\n",
       "         -3.2444,  -8.7053,   6.7489,   6.4975,   4.9768,  -9.4911,   1.6093,\n",
       "          5.2086,   7.5076,   1.7600,  -1.4895,  -0.2063,  11.2404,   5.6331,\n",
       "          7.0710,   5.5784,   9.1933,   1.8897,  13.5695,   0.1401,   2.7320,\n",
       "          1.2507,   8.7789,  -0.1908,  -5.7543,  -0.3788,   3.9876, -16.2288,\n",
       "        -11.0971,  -0.3929, -14.0738,  -3.3833, -15.1810,  -7.3592,  16.5950,\n",
       "         -3.1281,   4.2295,  14.4033,   1.4628,  -2.9380,  -0.2706,  -6.4188,\n",
       "         -2.9474, -17.5370,   2.1639,   5.5936,  -4.2919,   2.8199,   0.2836,\n",
       "         -2.4708,   1.4585,   4.9498,  -7.6156,   1.3989,  -3.2952,   6.5332,\n",
       "         -7.1871,  -3.1260], device='cuda:1')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = torch.tensor(seeds_infection[222][0]).to(device)\n",
    "z_hat = encoder(init).detach().to(device)\n",
    "z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 \t Total Loss:650.01917 \tTest_accuracy: 0.1704\n",
      "Iteration: 2 \t Total Loss:646.40869 \tTest_accuracy: 0.1704\n",
      "Iteration: 3 \t Total Loss:644.17078 \tTest_accuracy: 0.1704\n",
      "Iteration: 4 \t Total Loss:658.68091 \tTest_accuracy: 0.1704\n",
      "Iteration: 5 \t Total Loss:648.34576 \tTest_accuracy: 0.1704\n",
      "Iteration: 6 \t Total Loss:638.31793 \tTest_accuracy: 0.1704\n",
      "Iteration: 7 \t Total Loss:646.81805 \tTest_accuracy: 0.1704\n",
      "Iteration: 8 \t Total Loss:657.01166 \tTest_accuracy: 0.1704\n",
      "Iteration: 9 \t Total Loss:649.49188 \tTest_accuracy: 0.1704\n",
      "Iteration: 10 \t Total Loss:647.20935 \tTest_accuracy: 0.1704\n",
      "Iteration: 11 \t Total Loss:641.89911 \tTest_accuracy: 0.1704\n",
      "Iteration: 12 \t Total Loss:642.49945 \tTest_accuracy: 0.1704\n",
      "Iteration: 13 \t Total Loss:657.58063 \tTest_accuracy: 0.1704\n",
      "Iteration: 14 \t Total Loss:635.80432 \tTest_accuracy: 0.1704\n",
      "Iteration: 15 \t Total Loss:645.18115 \tTest_accuracy: 0.1704\n",
      "Iteration: 16 \t Total Loss:647.48846 \tTest_accuracy: 0.1704\n",
      "Iteration: 17 \t Total Loss:645.34906 \tTest_accuracy: 0.1704\n",
      "Iteration: 18 \t Total Loss:632.55273 \tTest_accuracy: 0.1704\n",
      "Iteration: 19 \t Total Loss:642.10425 \tTest_accuracy: 0.1704\n",
      "Iteration: 20 \t Total Loss:640.96405 \tTest_accuracy: 0.1704\n",
      "Iteration: 21 \t Total Loss:635.63538 \tTest_accuracy: 0.1704\n",
      "Iteration: 22 \t Total Loss:649.27014 \tTest_accuracy: 0.1704\n",
      "Iteration: 23 \t Total Loss:641.26251 \tTest_accuracy: 0.1704\n",
      "Iteration: 24 \t Total Loss:637.83569 \tTest_accuracy: 0.1704\n",
      "Iteration: 25 \t Total Loss:636.26520 \tTest_accuracy: 0.1704\n",
      "Iteration: 26 \t Total Loss:647.42920 \tTest_accuracy: 0.1704\n",
      "Iteration: 27 \t Total Loss:652.31354 \tTest_accuracy: 0.1704\n",
      "Iteration: 28 \t Total Loss:638.86493 \tTest_accuracy: 0.1704\n",
      "Iteration: 29 \t Total Loss:644.98077 \tTest_accuracy: 0.1704\n",
      "Iteration: 30 \t Total Loss:638.97375 \tTest_accuracy: 0.1704\n",
      "Iteration: 31 \t Total Loss:654.02258 \tTest_accuracy: 0.1704\n",
      "Iteration: 32 \t Total Loss:642.67780 \tTest_accuracy: 0.1704\n",
      "Iteration: 33 \t Total Loss:640.60626 \tTest_accuracy: 0.1704\n",
      "Iteration: 34 \t Total Loss:641.90533 \tTest_accuracy: 0.1704\n",
      "Iteration: 35 \t Total Loss:638.17035 \tTest_accuracy: 0.1704\n",
      "Iteration: 36 \t Total Loss:639.27533 \tTest_accuracy: 0.1704\n",
      "Iteration: 37 \t Total Loss:641.50787 \tTest_accuracy: 0.1704\n",
      "Iteration: 38 \t Total Loss:649.56323 \tTest_accuracy: 0.1704\n",
      "Iteration: 39 \t Total Loss:655.71936 \tTest_accuracy: 0.1704\n",
      "Iteration: 40 \t Total Loss:636.00867 \tTest_accuracy: 0.1704\n",
      "Iteration: 41 \t Total Loss:655.40460 \tTest_accuracy: 0.1704\n",
      "Iteration: 42 \t Total Loss:643.10211 \tTest_accuracy: 0.1704\n",
      "Iteration: 43 \t Total Loss:637.38910 \tTest_accuracy: 0.1704\n",
      "Iteration: 44 \t Total Loss:650.77203 \tTest_accuracy: 0.1704\n",
      "Iteration: 45 \t Total Loss:641.18512 \tTest_accuracy: 0.1704\n",
      "Iteration: 46 \t Total Loss:649.93561 \tTest_accuracy: 0.1704\n",
      "Iteration: 47 \t Total Loss:645.63379 \tTest_accuracy: 0.1704\n",
      "Iteration: 48 \t Total Loss:656.11292 \tTest_accuracy: 0.1704\n",
      "Iteration: 49 \t Total Loss:637.99969 \tTest_accuracy: 0.1704\n",
      "Iteration: 50 \t Total Loss:646.24689 \tTest_accuracy: 0.1704\n",
      "Iteration: 51 \t Total Loss:648.76996 \tTest_accuracy: 0.1704\n",
      "Iteration: 52 \t Total Loss:647.71490 \tTest_accuracy: 0.1704\n",
      "Iteration: 53 \t Total Loss:636.82867 \tTest_accuracy: 0.1704\n",
      "Iteration: 54 \t Total Loss:652.23010 \tTest_accuracy: 0.1704\n",
      "Iteration: 55 \t Total Loss:643.67792 \tTest_accuracy: 0.1704\n",
      "Iteration: 56 \t Total Loss:634.56006 \tTest_accuracy: 0.1704\n",
      "Iteration: 57 \t Total Loss:641.64813 \tTest_accuracy: 0.1704\n",
      "Iteration: 58 \t Total Loss:647.85199 \tTest_accuracy: 0.1704\n",
      "Iteration: 59 \t Total Loss:650.96472 \tTest_accuracy: 0.1704\n",
      "Iteration: 60 \t Total Loss:644.00513 \tTest_accuracy: 0.1704\n",
      "Iteration: 61 \t Total Loss:645.55017 \tTest_accuracy: 0.1704\n",
      "Iteration: 62 \t Total Loss:636.72125 \tTest_accuracy: 0.1704\n",
      "Iteration: 63 \t Total Loss:644.82971 \tTest_accuracy: 0.1704\n",
      "Iteration: 64 \t Total Loss:648.30768 \tTest_accuracy: 0.1704\n",
      "Iteration: 65 \t Total Loss:665.13947 \tTest_accuracy: 0.1704\n",
      "Iteration: 66 \t Total Loss:647.14777 \tTest_accuracy: 0.1704\n",
      "Iteration: 67 \t Total Loss:636.30164 \tTest_accuracy: 0.1704\n",
      "Iteration: 68 \t Total Loss:634.97107 \tTest_accuracy: 0.1704\n",
      "Iteration: 69 \t Total Loss:642.85199 \tTest_accuracy: 0.1704\n",
      "Iteration: 70 \t Total Loss:639.93292 \tTest_accuracy: 0.1704\n",
      "Iteration: 71 \t Total Loss:649.73212 \tTest_accuracy: 0.1704\n",
      "Iteration: 72 \t Total Loss:643.76031 \tTest_accuracy: 0.1704\n",
      "Iteration: 73 \t Total Loss:641.42133 \tTest_accuracy: 0.1704\n",
      "Iteration: 74 \t Total Loss:641.13593 \tTest_accuracy: 0.1704\n",
      "Iteration: 75 \t Total Loss:643.46271 \tTest_accuracy: 0.1704\n",
      "Iteration: 76 \t Total Loss:641.41888 \tTest_accuracy: 0.1704\n",
      "Iteration: 77 \t Total Loss:651.85382 \tTest_accuracy: 0.1704\n",
      "Iteration: 78 \t Total Loss:647.15192 \tTest_accuracy: 0.1704\n",
      "Iteration: 79 \t Total Loss:638.07074 \tTest_accuracy: 0.1704\n",
      "Iteration: 80 \t Total Loss:635.90649 \tTest_accuracy: 0.1704\n",
      "Iteration: 81 \t Total Loss:653.99945 \tTest_accuracy: 0.1704\n",
      "Iteration: 82 \t Total Loss:645.15350 \tTest_accuracy: 0.1704\n",
      "Iteration: 83 \t Total Loss:651.26025 \tTest_accuracy: 0.1704\n",
      "Iteration: 84 \t Total Loss:639.22583 \tTest_accuracy: 0.1704\n",
      "Iteration: 85 \t Total Loss:644.60016 \tTest_accuracy: 0.1704\n",
      "Iteration: 86 \t Total Loss:652.11395 \tTest_accuracy: 0.1704\n",
      "Iteration: 87 \t Total Loss:648.78192 \tTest_accuracy: 0.1704\n",
      "Iteration: 88 \t Total Loss:651.04010 \tTest_accuracy: 0.1704\n",
      "Iteration: 89 \t Total Loss:646.93774 \tTest_accuracy: 0.1704\n",
      "Iteration: 90 \t Total Loss:646.81372 \tTest_accuracy: 0.1704\n",
      "Iteration: 91 \t Total Loss:659.81641 \tTest_accuracy: 0.1704\n",
      "Iteration: 92 \t Total Loss:643.86639 \tTest_accuracy: 0.1704\n",
      "Iteration: 93 \t Total Loss:634.44318 \tTest_accuracy: 0.1704\n",
      "Iteration: 94 \t Total Loss:650.70612 \tTest_accuracy: 0.1704\n",
      "Iteration: 95 \t Total Loss:639.86505 \tTest_accuracy: 0.1704\n",
      "Iteration: 96 \t Total Loss:653.13574 \tTest_accuracy: 0.1704\n",
      "Iteration: 97 \t Total Loss:642.10272 \tTest_accuracy: 0.1704\n",
      "Iteration: 98 \t Total Loss:650.29419 \tTest_accuracy: 0.1704\n",
      "Iteration: 99 \t Total Loss:647.39813 \tTest_accuracy: 0.1704\n",
      "Iteration: 100 \t Total Loss:636.77100 \tTest_accuracy: 0.1704\n",
      "Iteration: 101 \t Total Loss:635.34729 \tTest_accuracy: 0.1704\n",
      "Iteration: 102 \t Total Loss:647.46838 \tTest_accuracy: 0.1704\n",
      "Iteration: 103 \t Total Loss:637.74353 \tTest_accuracy: 0.1704\n",
      "Iteration: 104 \t Total Loss:651.44672 \tTest_accuracy: 0.1704\n",
      "Iteration: 105 \t Total Loss:635.91052 \tTest_accuracy: 0.1704\n",
      "Iteration: 106 \t Total Loss:665.72168 \tTest_accuracy: 0.1704\n",
      "Iteration: 107 \t Total Loss:644.72845 \tTest_accuracy: 0.1704\n",
      "Iteration: 108 \t Total Loss:645.09222 \tTest_accuracy: 0.1704\n",
      "Iteration: 109 \t Total Loss:646.45868 \tTest_accuracy: 0.1704\n",
      "Iteration: 110 \t Total Loss:649.76465 \tTest_accuracy: 0.1704\n",
      "Iteration: 111 \t Total Loss:640.58575 \tTest_accuracy: 0.1704\n",
      "Iteration: 112 \t Total Loss:632.95343 \tTest_accuracy: 0.1704\n",
      "Iteration: 113 \t Total Loss:647.72705 \tTest_accuracy: 0.1704\n",
      "Iteration: 114 \t Total Loss:642.45819 \tTest_accuracy: 0.1704\n",
      "Iteration: 115 \t Total Loss:636.08429 \tTest_accuracy: 0.1704\n",
      "Iteration: 116 \t Total Loss:654.55939 \tTest_accuracy: 0.1704\n",
      "Iteration: 117 \t Total Loss:665.00879 \tTest_accuracy: 0.1704\n",
      "Iteration: 118 \t Total Loss:649.26715 \tTest_accuracy: 0.1704\n",
      "Iteration: 119 \t Total Loss:648.36060 \tTest_accuracy: 0.1704\n",
      "Iteration: 120 \t Total Loss:666.91260 \tTest_accuracy: 0.1704\n",
      "Iteration: 121 \t Total Loss:649.79413 \tTest_accuracy: 0.1704\n",
      "Iteration: 122 \t Total Loss:648.34485 \tTest_accuracy: 0.1704\n",
      "Iteration: 123 \t Total Loss:649.38965 \tTest_accuracy: 0.1704\n",
      "Iteration: 124 \t Total Loss:641.65564 \tTest_accuracy: 0.1704\n",
      "Iteration: 125 \t Total Loss:636.54608 \tTest_accuracy: 0.1704\n",
      "Iteration: 126 \t Total Loss:654.64801 \tTest_accuracy: 0.1704\n",
      "Iteration: 127 \t Total Loss:646.48138 \tTest_accuracy: 0.1704\n",
      "Iteration: 128 \t Total Loss:642.51215 \tTest_accuracy: 0.1704\n",
      "Iteration: 129 \t Total Loss:642.52936 \tTest_accuracy: 0.1704\n",
      "Iteration: 130 \t Total Loss:651.81464 \tTest_accuracy: 0.1704\n",
      "Iteration: 131 \t Total Loss:650.20575 \tTest_accuracy: 0.1704\n",
      "Iteration: 132 \t Total Loss:648.41486 \tTest_accuracy: 0.1704\n",
      "Iteration: 133 \t Total Loss:645.60309 \tTest_accuracy: 0.1704\n",
      "Iteration: 134 \t Total Loss:637.35699 \tTest_accuracy: 0.1704\n",
      "Iteration: 135 \t Total Loss:652.32294 \tTest_accuracy: 0.1704\n",
      "Iteration: 136 \t Total Loss:636.33636 \tTest_accuracy: 0.1704\n",
      "Iteration: 137 \t Total Loss:643.87067 \tTest_accuracy: 0.1704\n",
      "Iteration: 138 \t Total Loss:646.04449 \tTest_accuracy: 0.1704\n",
      "Iteration: 139 \t Total Loss:647.42389 \tTest_accuracy: 0.1704\n",
      "Iteration: 140 \t Total Loss:646.64862 \tTest_accuracy: 0.1704\n",
      "Iteration: 141 \t Total Loss:650.51611 \tTest_accuracy: 0.1704\n",
      "Iteration: 142 \t Total Loss:644.42438 \tTest_accuracy: 0.1704\n",
      "Iteration: 143 \t Total Loss:650.82758 \tTest_accuracy: 0.1704\n",
      "Iteration: 144 \t Total Loss:641.12567 \tTest_accuracy: 0.1704\n",
      "Iteration: 145 \t Total Loss:645.61688 \tTest_accuracy: 0.1704\n",
      "Iteration: 146 \t Total Loss:644.27399 \tTest_accuracy: 0.1704\n",
      "Iteration: 147 \t Total Loss:648.40173 \tTest_accuracy: 0.1704\n",
      "Iteration: 148 \t Total Loss:651.12616 \tTest_accuracy: 0.1704\n",
      "Iteration: 149 \t Total Loss:646.84680 \tTest_accuracy: 0.1704\n",
      "Iteration: 150 \t Total Loss:655.74249 \tTest_accuracy: 0.1704\n",
      "Iteration: 151 \t Total Loss:655.77338 \tTest_accuracy: 0.1704\n",
      "Iteration: 152 \t Total Loss:638.94263 \tTest_accuracy: 0.1704\n",
      "Iteration: 153 \t Total Loss:637.50104 \tTest_accuracy: 0.1704\n",
      "Iteration: 154 \t Total Loss:643.10126 \tTest_accuracy: 0.1704\n",
      "Iteration: 155 \t Total Loss:649.81891 \tTest_accuracy: 0.1704\n",
      "Iteration: 156 \t Total Loss:654.27374 \tTest_accuracy: 0.1704\n",
      "Iteration: 157 \t Total Loss:644.23828 \tTest_accuracy: 0.1704\n",
      "Iteration: 158 \t Total Loss:650.11438 \tTest_accuracy: 0.1704\n",
      "Iteration: 159 \t Total Loss:644.29688 \tTest_accuracy: 0.1704\n",
      "Iteration: 160 \t Total Loss:647.23877 \tTest_accuracy: 0.1704\n",
      "Iteration: 161 \t Total Loss:640.32275 \tTest_accuracy: 0.1704\n",
      "Iteration: 162 \t Total Loss:646.00964 \tTest_accuracy: 0.1704\n",
      "Iteration: 163 \t Total Loss:646.48053 \tTest_accuracy: 0.1704\n",
      "Iteration: 164 \t Total Loss:657.63055 \tTest_accuracy: 0.1704\n",
      "Iteration: 165 \t Total Loss:634.63605 \tTest_accuracy: 0.1704\n",
      "Iteration: 166 \t Total Loss:652.15393 \tTest_accuracy: 0.1704\n",
      "Iteration: 167 \t Total Loss:641.01581 \tTest_accuracy: 0.1704\n",
      "Iteration: 168 \t Total Loss:644.29071 \tTest_accuracy: 0.1704\n",
      "Iteration: 169 \t Total Loss:647.97333 \tTest_accuracy: 0.1704\n",
      "Iteration: 170 \t Total Loss:658.38092 \tTest_accuracy: 0.1704\n",
      "Iteration: 171 \t Total Loss:633.58051 \tTest_accuracy: 0.1704\n",
      "Iteration: 172 \t Total Loss:635.15771 \tTest_accuracy: 0.1704\n",
      "Iteration: 173 \t Total Loss:651.19135 \tTest_accuracy: 0.1704\n",
      "Iteration: 174 \t Total Loss:647.06396 \tTest_accuracy: 0.1704\n",
      "Iteration: 175 \t Total Loss:645.72198 \tTest_accuracy: 0.1704\n",
      "Iteration: 176 \t Total Loss:640.03802 \tTest_accuracy: 0.1704\n",
      "Iteration: 177 \t Total Loss:642.00739 \tTest_accuracy: 0.1704\n",
      "Iteration: 178 \t Total Loss:646.85870 \tTest_accuracy: 0.1704\n",
      "Iteration: 179 \t Total Loss:654.88184 \tTest_accuracy: 0.1704\n",
      "Iteration: 180 \t Total Loss:649.69489 \tTest_accuracy: 0.1704\n",
      "Iteration: 181 \t Total Loss:648.28693 \tTest_accuracy: 0.1704\n",
      "Iteration: 182 \t Total Loss:660.58246 \tTest_accuracy: 0.1704\n",
      "Iteration: 183 \t Total Loss:637.95715 \tTest_accuracy: 0.1704\n",
      "Iteration: 184 \t Total Loss:640.42322 \tTest_accuracy: 0.1704\n",
      "Iteration: 185 \t Total Loss:650.52527 \tTest_accuracy: 0.1704\n",
      "Iteration: 186 \t Total Loss:639.52228 \tTest_accuracy: 0.1704\n",
      "Iteration: 187 \t Total Loss:653.96783 \tTest_accuracy: 0.1704\n",
      "Iteration: 188 \t Total Loss:632.31976 \tTest_accuracy: 0.1704\n",
      "Iteration: 189 \t Total Loss:637.97278 \tTest_accuracy: 0.1704\n",
      "Iteration: 190 \t Total Loss:636.83612 \tTest_accuracy: 0.1704\n",
      "Iteration: 191 \t Total Loss:659.65784 \tTest_accuracy: 0.1704\n",
      "Iteration: 192 \t Total Loss:656.10614 \tTest_accuracy: 0.1704\n",
      "Iteration: 193 \t Total Loss:653.17023 \tTest_accuracy: 0.1704\n",
      "Iteration: 194 \t Total Loss:646.73334 \tTest_accuracy: 0.1704\n",
      "Iteration: 195 \t Total Loss:663.28693 \tTest_accuracy: 0.1704\n",
      "Iteration: 196 \t Total Loss:648.58423 \tTest_accuracy: 0.1704\n",
      "Iteration: 197 \t Total Loss:643.42548 \tTest_accuracy: 0.1704\n",
      "Iteration: 198 \t Total Loss:632.30975 \tTest_accuracy: 0.1704\n",
      "Iteration: 199 \t Total Loss:637.93463 \tTest_accuracy: 0.1704\n",
      "Iteration: 200 \t Total Loss:647.31451 \tTest_accuracy: 0.1704\n",
      "Iteration: 201 \t Total Loss:646.38483 \tTest_accuracy: 0.1704\n",
      "Iteration: 202 \t Total Loss:645.93829 \tTest_accuracy: 0.1704\n",
      "Iteration: 203 \t Total Loss:638.37946 \tTest_accuracy: 0.1704\n",
      "Iteration: 204 \t Total Loss:638.28436 \tTest_accuracy: 0.1704\n",
      "Iteration: 205 \t Total Loss:655.14917 \tTest_accuracy: 0.1704\n",
      "Iteration: 206 \t Total Loss:655.43994 \tTest_accuracy: 0.1704\n",
      "Iteration: 207 \t Total Loss:646.97241 \tTest_accuracy: 0.1704\n",
      "Iteration: 208 \t Total Loss:660.32208 \tTest_accuracy: 0.1704\n",
      "Iteration: 209 \t Total Loss:637.61920 \tTest_accuracy: 0.1704\n",
      "Iteration: 210 \t Total Loss:649.44373 \tTest_accuracy: 0.1704\n",
      "Iteration: 211 \t Total Loss:654.57733 \tTest_accuracy: 0.1704\n",
      "Iteration: 212 \t Total Loss:653.78644 \tTest_accuracy: 0.1704\n",
      "Iteration: 213 \t Total Loss:648.04291 \tTest_accuracy: 0.1704\n",
      "Iteration: 214 \t Total Loss:644.54938 \tTest_accuracy: 0.1704\n",
      "Iteration: 215 \t Total Loss:642.32745 \tTest_accuracy: 0.1704\n",
      "Iteration: 216 \t Total Loss:636.33862 \tTest_accuracy: 0.1704\n",
      "Iteration: 217 \t Total Loss:639.87158 \tTest_accuracy: 0.1704\n",
      "Iteration: 218 \t Total Loss:653.01605 \tTest_accuracy: 0.1704\n",
      "Iteration: 219 \t Total Loss:646.19965 \tTest_accuracy: 0.1704\n",
      "Iteration: 220 \t Total Loss:647.89514 \tTest_accuracy: 0.1704\n",
      "Iteration: 221 \t Total Loss:638.47650 \tTest_accuracy: 0.1704\n",
      "Iteration: 222 \t Total Loss:636.41693 \tTest_accuracy: 0.1704\n",
      "Iteration: 223 \t Total Loss:638.23651 \tTest_accuracy: 0.1704\n",
      "Iteration: 224 \t Total Loss:644.83185 \tTest_accuracy: 0.1704\n",
      "Iteration: 225 \t Total Loss:647.00104 \tTest_accuracy: 0.1704\n",
      "Iteration: 226 \t Total Loss:649.22479 \tTest_accuracy: 0.1704\n",
      "Iteration: 227 \t Total Loss:657.59009 \tTest_accuracy: 0.1704\n",
      "Iteration: 228 \t Total Loss:643.15808 \tTest_accuracy: 0.1704\n",
      "Iteration: 229 \t Total Loss:634.32147 \tTest_accuracy: 0.1704\n",
      "Iteration: 230 \t Total Loss:652.39044 \tTest_accuracy: 0.1704\n",
      "Iteration: 231 \t Total Loss:646.52643 \tTest_accuracy: 0.1704\n",
      "Iteration: 232 \t Total Loss:650.01410 \tTest_accuracy: 0.1704\n",
      "Iteration: 233 \t Total Loss:649.07617 \tTest_accuracy: 0.1704\n",
      "Iteration: 234 \t Total Loss:639.71063 \tTest_accuracy: 0.1704\n",
      "Iteration: 235 \t Total Loss:647.54926 \tTest_accuracy: 0.1704\n",
      "Iteration: 236 \t Total Loss:652.38715 \tTest_accuracy: 0.1704\n",
      "Iteration: 237 \t Total Loss:664.43756 \tTest_accuracy: 0.1704\n",
      "Iteration: 238 \t Total Loss:649.48285 \tTest_accuracy: 0.1704\n",
      "Iteration: 239 \t Total Loss:646.38965 \tTest_accuracy: 0.1704\n",
      "Iteration: 240 \t Total Loss:650.92719 \tTest_accuracy: 0.1704\n",
      "Iteration: 241 \t Total Loss:646.28925 \tTest_accuracy: 0.1704\n",
      "Iteration: 242 \t Total Loss:654.17493 \tTest_accuracy: 0.1704\n",
      "Iteration: 243 \t Total Loss:658.35455 \tTest_accuracy: 0.1704\n",
      "Iteration: 244 \t Total Loss:640.26044 \tTest_accuracy: 0.1704\n",
      "Iteration: 245 \t Total Loss:656.93622 \tTest_accuracy: 0.1704\n",
      "Iteration: 246 \t Total Loss:653.83453 \tTest_accuracy: 0.1704\n",
      "Iteration: 247 \t Total Loss:642.77142 \tTest_accuracy: 0.1704\n",
      "Iteration: 248 \t Total Loss:642.39801 \tTest_accuracy: 0.1704\n",
      "Iteration: 249 \t Total Loss:660.03052 \tTest_accuracy: 0.1704\n",
      "Iteration: 250 \t Total Loss:635.48883 \tTest_accuracy: 0.1704\n",
      "Iteration: 251 \t Total Loss:644.60138 \tTest_accuracy: 0.1704\n",
      "Iteration: 252 \t Total Loss:633.91956 \tTest_accuracy: 0.1704\n",
      "Iteration: 253 \t Total Loss:645.74554 \tTest_accuracy: 0.1704\n",
      "Iteration: 254 \t Total Loss:653.13934 \tTest_accuracy: 0.1704\n",
      "Iteration: 255 \t Total Loss:652.45538 \tTest_accuracy: 0.1704\n",
      "Iteration: 256 \t Total Loss:660.31262 \tTest_accuracy: 0.1704\n",
      "Iteration: 257 \t Total Loss:651.22797 \tTest_accuracy: 0.1704\n",
      "Iteration: 258 \t Total Loss:652.80719 \tTest_accuracy: 0.1704\n",
      "Iteration: 259 \t Total Loss:644.84961 \tTest_accuracy: 0.1704\n",
      "Iteration: 260 \t Total Loss:645.60266 \tTest_accuracy: 0.1704\n",
      "Iteration: 261 \t Total Loss:653.99249 \tTest_accuracy: 0.1704\n",
      "Iteration: 262 \t Total Loss:640.38153 \tTest_accuracy: 0.1704\n",
      "Iteration: 263 \t Total Loss:647.53326 \tTest_accuracy: 0.1704\n",
      "Iteration: 264 \t Total Loss:651.36316 \tTest_accuracy: 0.1704\n",
      "Iteration: 265 \t Total Loss:641.46472 \tTest_accuracy: 0.1704\n",
      "Iteration: 266 \t Total Loss:636.77295 \tTest_accuracy: 0.1704\n",
      "Iteration: 267 \t Total Loss:637.87323 \tTest_accuracy: 0.1704\n",
      "Iteration: 268 \t Total Loss:651.09088 \tTest_accuracy: 0.1704\n",
      "Iteration: 269 \t Total Loss:634.90143 \tTest_accuracy: 0.1704\n",
      "Iteration: 270 \t Total Loss:639.26147 \tTest_accuracy: 0.1704\n",
      "Iteration: 271 \t Total Loss:651.61346 \tTest_accuracy: 0.1704\n",
      "Iteration: 272 \t Total Loss:646.69513 \tTest_accuracy: 0.1704\n",
      "Iteration: 273 \t Total Loss:651.45721 \tTest_accuracy: 0.1704\n",
      "Iteration: 274 \t Total Loss:653.25665 \tTest_accuracy: 0.1704\n",
      "Iteration: 275 \t Total Loss:654.25726 \tTest_accuracy: 0.1704\n",
      "Iteration: 276 \t Total Loss:640.39789 \tTest_accuracy: 0.1704\n",
      "Iteration: 277 \t Total Loss:639.18109 \tTest_accuracy: 0.1704\n",
      "Iteration: 278 \t Total Loss:639.27643 \tTest_accuracy: 0.1704\n",
      "Iteration: 279 \t Total Loss:641.23969 \tTest_accuracy: 0.1704\n",
      "Iteration: 280 \t Total Loss:644.64990 \tTest_accuracy: 0.1704\n",
      "Iteration: 281 \t Total Loss:646.78314 \tTest_accuracy: 0.1704\n",
      "Iteration: 282 \t Total Loss:635.29523 \tTest_accuracy: 0.1704\n",
      "Iteration: 283 \t Total Loss:639.64410 \tTest_accuracy: 0.1704\n",
      "Iteration: 284 \t Total Loss:653.60864 \tTest_accuracy: 0.1704\n",
      "Iteration: 285 \t Total Loss:659.30322 \tTest_accuracy: 0.1704\n",
      "Iteration: 286 \t Total Loss:646.68927 \tTest_accuracy: 0.1704\n",
      "Iteration: 287 \t Total Loss:633.82507 \tTest_accuracy: 0.1704\n",
      "Iteration: 288 \t Total Loss:646.24908 \tTest_accuracy: 0.1704\n",
      "Iteration: 289 \t Total Loss:653.77789 \tTest_accuracy: 0.1704\n",
      "Iteration: 290 \t Total Loss:643.71570 \tTest_accuracy: 0.1704\n",
      "Iteration: 291 \t Total Loss:638.66071 \tTest_accuracy: 0.1704\n",
      "Iteration: 292 \t Total Loss:632.92206 \tTest_accuracy: 0.1704\n",
      "Iteration: 293 \t Total Loss:655.11371 \tTest_accuracy: 0.1704\n",
      "Iteration: 294 \t Total Loss:640.24432 \tTest_accuracy: 0.1704\n",
      "Iteration: 295 \t Total Loss:645.28137 \tTest_accuracy: 0.1704\n",
      "Iteration: 296 \t Total Loss:638.24298 \tTest_accuracy: 0.1704\n",
      "Iteration: 297 \t Total Loss:657.49463 \tTest_accuracy: 0.1704\n",
      "Iteration: 298 \t Total Loss:655.60944 \tTest_accuracy: 0.1704\n",
      "Iteration: 299 \t Total Loss:655.79510 \tTest_accuracy: 0.1704\n",
      "Iteration: 300 \t Total Loss:657.27313 \tTest_accuracy: 0.1704\n",
      "Iteration: 301 \t Total Loss:638.14606 \tTest_accuracy: 0.1704\n",
      "Iteration: 302 \t Total Loss:639.14117 \tTest_accuracy: 0.1704\n",
      "Iteration: 303 \t Total Loss:634.88068 \tTest_accuracy: 0.1704\n",
      "Iteration: 304 \t Total Loss:643.55524 \tTest_accuracy: 0.1704\n",
      "Iteration: 305 \t Total Loss:640.81726 \tTest_accuracy: 0.1704\n",
      "Iteration: 306 \t Total Loss:654.01678 \tTest_accuracy: 0.1704\n",
      "Iteration: 307 \t Total Loss:656.92664 \tTest_accuracy: 0.1704\n",
      "Iteration: 308 \t Total Loss:640.50885 \tTest_accuracy: 0.1704\n",
      "Iteration: 309 \t Total Loss:640.14551 \tTest_accuracy: 0.1704\n",
      "Iteration: 310 \t Total Loss:643.44263 \tTest_accuracy: 0.1704\n",
      "Iteration: 311 \t Total Loss:653.79858 \tTest_accuracy: 0.1704\n",
      "Iteration: 312 \t Total Loss:643.74054 \tTest_accuracy: 0.1704\n",
      "Iteration: 313 \t Total Loss:651.77100 \tTest_accuracy: 0.1704\n",
      "Iteration: 314 \t Total Loss:654.03979 \tTest_accuracy: 0.1704\n",
      "Iteration: 315 \t Total Loss:644.56921 \tTest_accuracy: 0.1704\n",
      "Iteration: 316 \t Total Loss:643.17651 \tTest_accuracy: 0.1704\n",
      "Iteration: 317 \t Total Loss:648.35114 \tTest_accuracy: 0.1704\n",
      "Iteration: 318 \t Total Loss:657.92017 \tTest_accuracy: 0.1704\n",
      "Iteration: 319 \t Total Loss:640.41394 \tTest_accuracy: 0.1704\n",
      "Iteration: 320 \t Total Loss:646.27673 \tTest_accuracy: 0.1704\n",
      "Iteration: 321 \t Total Loss:642.72882 \tTest_accuracy: 0.1704\n",
      "Iteration: 322 \t Total Loss:662.98175 \tTest_accuracy: 0.1704\n",
      "Iteration: 323 \t Total Loss:646.05750 \tTest_accuracy: 0.1704\n",
      "Iteration: 324 \t Total Loss:636.74133 \tTest_accuracy: 0.1704\n",
      "Iteration: 325 \t Total Loss:656.71600 \tTest_accuracy: 0.1704\n",
      "Iteration: 326 \t Total Loss:638.18011 \tTest_accuracy: 0.1704\n",
      "Iteration: 327 \t Total Loss:631.61322 \tTest_accuracy: 0.1704\n",
      "Iteration: 328 \t Total Loss:648.14325 \tTest_accuracy: 0.1704\n",
      "Iteration: 329 \t Total Loss:638.75439 \tTest_accuracy: 0.1704\n",
      "Iteration: 330 \t Total Loss:656.41736 \tTest_accuracy: 0.1704\n",
      "Iteration: 331 \t Total Loss:639.66278 \tTest_accuracy: 0.1704\n",
      "Iteration: 332 \t Total Loss:653.60327 \tTest_accuracy: 0.1704\n",
      "Iteration: 333 \t Total Loss:638.23553 \tTest_accuracy: 0.1704\n",
      "Iteration: 334 \t Total Loss:648.37537 \tTest_accuracy: 0.1704\n",
      "Iteration: 335 \t Total Loss:662.24402 \tTest_accuracy: 0.1704\n",
      "Iteration: 336 \t Total Loss:649.80084 \tTest_accuracy: 0.1704\n",
      "Iteration: 337 \t Total Loss:638.02020 \tTest_accuracy: 0.1704\n",
      "Iteration: 338 \t Total Loss:644.17480 \tTest_accuracy: 0.1704\n",
      "Iteration: 339 \t Total Loss:649.15759 \tTest_accuracy: 0.1704\n",
      "Iteration: 340 \t Total Loss:643.68317 \tTest_accuracy: 0.1704\n",
      "Iteration: 341 \t Total Loss:645.65295 \tTest_accuracy: 0.1704\n",
      "Iteration: 342 \t Total Loss:655.69678 \tTest_accuracy: 0.1704\n",
      "Iteration: 343 \t Total Loss:640.10107 \tTest_accuracy: 0.1704\n",
      "Iteration: 344 \t Total Loss:651.48029 \tTest_accuracy: 0.1704\n",
      "Iteration: 345 \t Total Loss:640.38385 \tTest_accuracy: 0.1704\n",
      "Iteration: 346 \t Total Loss:639.97162 \tTest_accuracy: 0.1704\n",
      "Iteration: 347 \t Total Loss:644.64862 \tTest_accuracy: 0.1704\n",
      "Iteration: 348 \t Total Loss:641.06958 \tTest_accuracy: 0.1704\n",
      "Iteration: 349 \t Total Loss:651.59912 \tTest_accuracy: 0.1704\n",
      "Iteration: 350 \t Total Loss:654.14270 \tTest_accuracy: 0.1704\n",
      "Iteration: 351 \t Total Loss:634.88483 \tTest_accuracy: 0.1704\n",
      "Iteration: 352 \t Total Loss:644.78168 \tTest_accuracy: 0.1704\n",
      "Iteration: 353 \t Total Loss:646.67584 \tTest_accuracy: 0.1704\n",
      "Iteration: 354 \t Total Loss:636.32330 \tTest_accuracy: 0.1704\n",
      "Iteration: 355 \t Total Loss:656.07001 \tTest_accuracy: 0.1704\n",
      "Iteration: 356 \t Total Loss:651.67804 \tTest_accuracy: 0.1704\n",
      "Iteration: 357 \t Total Loss:661.85852 \tTest_accuracy: 0.1704\n",
      "Iteration: 358 \t Total Loss:655.56598 \tTest_accuracy: 0.1704\n",
      "Iteration: 359 \t Total Loss:646.33356 \tTest_accuracy: 0.1704\n",
      "Iteration: 360 \t Total Loss:637.11859 \tTest_accuracy: 0.1704\n",
      "Iteration: 361 \t Total Loss:647.20447 \tTest_accuracy: 0.1704\n",
      "Iteration: 362 \t Total Loss:663.26825 \tTest_accuracy: 0.1704\n",
      "Iteration: 363 \t Total Loss:645.79205 \tTest_accuracy: 0.1704\n",
      "Iteration: 364 \t Total Loss:644.70538 \tTest_accuracy: 0.1704\n",
      "Iteration: 365 \t Total Loss:640.55658 \tTest_accuracy: 0.1704\n",
      "Iteration: 366 \t Total Loss:637.53198 \tTest_accuracy: 0.1704\n",
      "Iteration: 367 \t Total Loss:645.70605 \tTest_accuracy: 0.1704\n",
      "Iteration: 368 \t Total Loss:649.83417 \tTest_accuracy: 0.1704\n",
      "Iteration: 369 \t Total Loss:635.12933 \tTest_accuracy: 0.1704\n",
      "Iteration: 370 \t Total Loss:648.33765 \tTest_accuracy: 0.1704\n",
      "Iteration: 371 \t Total Loss:653.84521 \tTest_accuracy: 0.1704\n",
      "Iteration: 372 \t Total Loss:646.87372 \tTest_accuracy: 0.1704\n",
      "Iteration: 373 \t Total Loss:643.42413 \tTest_accuracy: 0.1704\n",
      "Iteration: 374 \t Total Loss:656.11304 \tTest_accuracy: 0.1704\n",
      "Iteration: 375 \t Total Loss:652.42493 \tTest_accuracy: 0.1704\n",
      "Iteration: 376 \t Total Loss:647.03149 \tTest_accuracy: 0.1704\n",
      "Iteration: 377 \t Total Loss:637.02008 \tTest_accuracy: 0.1704\n",
      "Iteration: 378 \t Total Loss:642.03528 \tTest_accuracy: 0.1704\n",
      "Iteration: 379 \t Total Loss:647.25146 \tTest_accuracy: 0.1704\n",
      "Iteration: 380 \t Total Loss:660.43439 \tTest_accuracy: 0.1704\n",
      "Iteration: 381 \t Total Loss:636.46667 \tTest_accuracy: 0.1704\n",
      "Iteration: 382 \t Total Loss:639.34033 \tTest_accuracy: 0.1704\n",
      "Iteration: 383 \t Total Loss:645.36865 \tTest_accuracy: 0.1704\n",
      "Iteration: 384 \t Total Loss:641.30829 \tTest_accuracy: 0.1704\n",
      "Iteration: 385 \t Total Loss:651.56104 \tTest_accuracy: 0.1704\n",
      "Iteration: 386 \t Total Loss:649.14502 \tTest_accuracy: 0.1704\n",
      "Iteration: 387 \t Total Loss:643.77631 \tTest_accuracy: 0.1704\n",
      "Iteration: 388 \t Total Loss:644.86041 \tTest_accuracy: 0.1704\n",
      "Iteration: 389 \t Total Loss:650.62000 \tTest_accuracy: 0.1704\n",
      "Iteration: 390 \t Total Loss:642.66925 \tTest_accuracy: 0.1704\n",
      "Iteration: 391 \t Total Loss:652.54968 \tTest_accuracy: 0.1704\n",
      "Iteration: 392 \t Total Loss:647.82611 \tTest_accuracy: 0.1704\n",
      "Iteration: 393 \t Total Loss:642.11047 \tTest_accuracy: 0.1704\n",
      "Iteration: 394 \t Total Loss:643.71008 \tTest_accuracy: 0.1704\n",
      "Iteration: 395 \t Total Loss:639.13196 \tTest_accuracy: 0.1704\n",
      "Iteration: 396 \t Total Loss:644.83325 \tTest_accuracy: 0.1704\n",
      "Iteration: 397 \t Total Loss:636.71564 \tTest_accuracy: 0.1704\n",
      "Iteration: 398 \t Total Loss:644.28571 \tTest_accuracy: 0.1704\n",
      "Iteration: 399 \t Total Loss:646.63806 \tTest_accuracy: 0.1704\n",
      "Iteration: 400 \t Total Loss:643.86292 \tTest_accuracy: 0.1704\n",
      "Iteration: 401 \t Total Loss:645.24506 \tTest_accuracy: 0.1704\n",
      "Iteration: 402 \t Total Loss:660.42218 \tTest_accuracy: 0.1704\n",
      "Iteration: 403 \t Total Loss:643.44189 \tTest_accuracy: 0.1704\n",
      "Iteration: 404 \t Total Loss:647.70349 \tTest_accuracy: 0.1704\n",
      "Iteration: 405 \t Total Loss:657.18958 \tTest_accuracy: 0.1704\n",
      "Iteration: 406 \t Total Loss:638.72931 \tTest_accuracy: 0.1704\n",
      "Iteration: 407 \t Total Loss:649.44092 \tTest_accuracy: 0.1704\n",
      "Iteration: 408 \t Total Loss:645.47992 \tTest_accuracy: 0.1704\n",
      "Iteration: 409 \t Total Loss:634.33142 \tTest_accuracy: 0.1704\n",
      "Iteration: 410 \t Total Loss:642.06274 \tTest_accuracy: 0.1704\n",
      "Iteration: 411 \t Total Loss:654.27911 \tTest_accuracy: 0.1704\n",
      "Iteration: 412 \t Total Loss:643.37018 \tTest_accuracy: 0.1704\n",
      "Iteration: 413 \t Total Loss:650.45441 \tTest_accuracy: 0.1704\n",
      "Iteration: 414 \t Total Loss:643.56702 \tTest_accuracy: 0.1704\n",
      "Iteration: 415 \t Total Loss:639.66400 \tTest_accuracy: 0.1704\n",
      "Iteration: 416 \t Total Loss:651.28772 \tTest_accuracy: 0.1704\n",
      "Iteration: 417 \t Total Loss:648.56635 \tTest_accuracy: 0.1704\n",
      "Iteration: 418 \t Total Loss:640.03473 \tTest_accuracy: 0.1704\n",
      "Iteration: 419 \t Total Loss:639.98938 \tTest_accuracy: 0.1704\n",
      "Iteration: 420 \t Total Loss:641.16290 \tTest_accuracy: 0.1704\n",
      "Iteration: 421 \t Total Loss:659.55438 \tTest_accuracy: 0.1704\n",
      "Iteration: 422 \t Total Loss:651.85535 \tTest_accuracy: 0.1704\n",
      "Iteration: 423 \t Total Loss:640.55878 \tTest_accuracy: 0.1704\n",
      "Iteration: 424 \t Total Loss:636.86365 \tTest_accuracy: 0.1704\n",
      "Iteration: 425 \t Total Loss:651.51746 \tTest_accuracy: 0.1704\n",
      "Iteration: 426 \t Total Loss:637.57397 \tTest_accuracy: 0.1704\n",
      "Iteration: 427 \t Total Loss:645.12494 \tTest_accuracy: 0.1704\n",
      "Iteration: 428 \t Total Loss:643.64612 \tTest_accuracy: 0.1704\n",
      "Iteration: 429 \t Total Loss:646.87372 \tTest_accuracy: 0.1704\n",
      "Iteration: 430 \t Total Loss:652.23743 \tTest_accuracy: 0.1704\n",
      "Iteration: 431 \t Total Loss:639.80243 \tTest_accuracy: 0.1704\n",
      "Iteration: 432 \t Total Loss:647.99829 \tTest_accuracy: 0.1704\n",
      "Iteration: 433 \t Total Loss:654.52576 \tTest_accuracy: 0.1704\n",
      "Iteration: 434 \t Total Loss:643.14343 \tTest_accuracy: 0.1704\n",
      "Iteration: 435 \t Total Loss:650.43939 \tTest_accuracy: 0.1704\n",
      "Iteration: 436 \t Total Loss:643.80658 \tTest_accuracy: 0.1704\n",
      "Iteration: 437 \t Total Loss:637.65973 \tTest_accuracy: 0.1704\n",
      "Iteration: 438 \t Total Loss:649.54913 \tTest_accuracy: 0.1704\n",
      "Iteration: 439 \t Total Loss:641.01788 \tTest_accuracy: 0.1704\n",
      "Iteration: 440 \t Total Loss:636.09979 \tTest_accuracy: 0.1704\n",
      "Iteration: 441 \t Total Loss:641.42303 \tTest_accuracy: 0.1704\n",
      "Iteration: 442 \t Total Loss:644.07794 \tTest_accuracy: 0.1704\n",
      "Iteration: 443 \t Total Loss:651.72906 \tTest_accuracy: 0.1704\n",
      "Iteration: 444 \t Total Loss:642.09668 \tTest_accuracy: 0.1704\n",
      "Iteration: 445 \t Total Loss:642.22742 \tTest_accuracy: 0.1704\n",
      "Iteration: 446 \t Total Loss:636.74744 \tTest_accuracy: 0.1704\n",
      "Iteration: 447 \t Total Loss:635.45001 \tTest_accuracy: 0.1704\n",
      "Iteration: 448 \t Total Loss:650.71387 \tTest_accuracy: 0.1704\n",
      "Iteration: 449 \t Total Loss:638.76599 \tTest_accuracy: 0.1704\n",
      "Iteration: 450 \t Total Loss:647.02582 \tTest_accuracy: 0.1704\n",
      "Iteration: 451 \t Total Loss:652.26349 \tTest_accuracy: 0.1704\n",
      "Iteration: 452 \t Total Loss:640.47742 \tTest_accuracy: 0.1704\n",
      "Iteration: 453 \t Total Loss:649.06183 \tTest_accuracy: 0.1704\n",
      "Iteration: 454 \t Total Loss:644.75592 \tTest_accuracy: 0.1704\n",
      "Iteration: 455 \t Total Loss:640.66040 \tTest_accuracy: 0.1704\n",
      "Iteration: 456 \t Total Loss:639.62860 \tTest_accuracy: 0.1704\n",
      "Iteration: 457 \t Total Loss:644.88715 \tTest_accuracy: 0.1704\n",
      "Iteration: 458 \t Total Loss:638.88763 \tTest_accuracy: 0.1704\n",
      "Iteration: 459 \t Total Loss:637.65240 \tTest_accuracy: 0.1704\n",
      "Iteration: 460 \t Total Loss:644.11804 \tTest_accuracy: 0.1704\n",
      "Iteration: 461 \t Total Loss:656.19244 \tTest_accuracy: 0.1704\n",
      "Iteration: 462 \t Total Loss:657.79248 \tTest_accuracy: 0.1704\n",
      "Iteration: 463 \t Total Loss:650.60004 \tTest_accuracy: 0.1704\n",
      "Iteration: 464 \t Total Loss:635.42712 \tTest_accuracy: 0.1704\n",
      "Iteration: 465 \t Total Loss:648.70502 \tTest_accuracy: 0.1704\n",
      "Iteration: 466 \t Total Loss:639.32391 \tTest_accuracy: 0.1704\n",
      "Iteration: 467 \t Total Loss:641.58014 \tTest_accuracy: 0.1704\n",
      "Iteration: 468 \t Total Loss:656.06171 \tTest_accuracy: 0.1704\n",
      "Iteration: 469 \t Total Loss:639.09698 \tTest_accuracy: 0.1704\n",
      "Iteration: 470 \t Total Loss:649.70563 \tTest_accuracy: 0.1704\n",
      "Iteration: 471 \t Total Loss:643.05872 \tTest_accuracy: 0.1704\n",
      "Iteration: 472 \t Total Loss:650.04083 \tTest_accuracy: 0.1704\n",
      "Iteration: 473 \t Total Loss:650.67975 \tTest_accuracy: 0.1704\n",
      "Iteration: 474 \t Total Loss:651.49115 \tTest_accuracy: 0.1704\n",
      "Iteration: 475 \t Total Loss:641.30939 \tTest_accuracy: 0.1704\n",
      "Iteration: 476 \t Total Loss:640.87335 \tTest_accuracy: 0.1704\n",
      "Iteration: 477 \t Total Loss:646.96552 \tTest_accuracy: 0.1704\n",
      "Iteration: 478 \t Total Loss:636.30939 \tTest_accuracy: 0.1704\n",
      "Iteration: 479 \t Total Loss:652.44202 \tTest_accuracy: 0.1704\n",
      "Iteration: 480 \t Total Loss:656.42804 \tTest_accuracy: 0.1704\n",
      "Iteration: 481 \t Total Loss:642.82056 \tTest_accuracy: 0.1704\n",
      "Iteration: 482 \t Total Loss:642.95013 \tTest_accuracy: 0.1704\n",
      "Iteration: 483 \t Total Loss:640.19403 \tTest_accuracy: 0.1704\n",
      "Iteration: 484 \t Total Loss:635.63275 \tTest_accuracy: 0.1704\n",
      "Iteration: 485 \t Total Loss:643.63654 \tTest_accuracy: 0.1704\n",
      "Iteration: 486 \t Total Loss:642.16217 \tTest_accuracy: 0.1704\n",
      "Iteration: 487 \t Total Loss:646.43927 \tTest_accuracy: 0.1704\n",
      "Iteration: 488 \t Total Loss:641.91858 \tTest_accuracy: 0.1704\n",
      "Iteration: 489 \t Total Loss:652.52191 \tTest_accuracy: 0.1704\n",
      "Iteration: 490 \t Total Loss:644.04559 \tTest_accuracy: 0.1704\n",
      "Iteration: 491 \t Total Loss:638.23700 \tTest_accuracy: 0.1704\n",
      "Iteration: 492 \t Total Loss:644.79755 \tTest_accuracy: 0.1704\n",
      "Iteration: 493 \t Total Loss:654.26581 \tTest_accuracy: 0.1704\n",
      "Iteration: 494 \t Total Loss:652.95648 \tTest_accuracy: 0.1704\n",
      "Iteration: 495 \t Total Loss:641.41986 \tTest_accuracy: 0.1704\n",
      "Iteration: 496 \t Total Loss:641.76465 \tTest_accuracy: 0.1704\n",
      "Iteration: 497 \t Total Loss:648.57239 \tTest_accuracy: 0.1704\n",
      "Iteration: 498 \t Total Loss:652.12354 \tTest_accuracy: 0.1704\n",
      "Iteration: 499 \t Total Loss:652.31769 \tTest_accuracy: 0.1704\n",
      "Iteration: 500 \t Total Loss:636.62726 \tTest_accuracy: 0.1704\n",
      "Iteration: 501 \t Total Loss:641.75897 \tTest_accuracy: 0.1704\n",
      "Iteration: 502 \t Total Loss:647.56329 \tTest_accuracy: 0.1704\n",
      "Iteration: 503 \t Total Loss:643.86554 \tTest_accuracy: 0.1704\n",
      "Iteration: 504 \t Total Loss:641.15472 \tTest_accuracy: 0.1704\n",
      "Iteration: 505 \t Total Loss:638.46387 \tTest_accuracy: 0.1704\n",
      "Iteration: 506 \t Total Loss:658.43323 \tTest_accuracy: 0.1704\n",
      "Iteration: 507 \t Total Loss:650.69147 \tTest_accuracy: 0.1704\n",
      "Iteration: 508 \t Total Loss:648.11847 \tTest_accuracy: 0.1704\n",
      "Iteration: 509 \t Total Loss:638.16669 \tTest_accuracy: 0.1704\n",
      "Iteration: 510 \t Total Loss:639.53760 \tTest_accuracy: 0.1704\n",
      "Iteration: 511 \t Total Loss:653.60223 \tTest_accuracy: 0.1704\n",
      "Iteration: 512 \t Total Loss:649.19672 \tTest_accuracy: 0.1704\n",
      "Iteration: 513 \t Total Loss:651.60223 \tTest_accuracy: 0.1704\n",
      "Iteration: 514 \t Total Loss:643.71344 \tTest_accuracy: 0.1704\n",
      "Iteration: 515 \t Total Loss:651.73871 \tTest_accuracy: 0.1704\n",
      "Iteration: 516 \t Total Loss:654.71490 \tTest_accuracy: 0.1704\n",
      "Iteration: 517 \t Total Loss:657.16510 \tTest_accuracy: 0.1704\n",
      "Iteration: 518 \t Total Loss:650.42535 \tTest_accuracy: 0.1704\n",
      "Iteration: 519 \t Total Loss:631.86688 \tTest_accuracy: 0.1704\n",
      "Iteration: 520 \t Total Loss:658.05640 \tTest_accuracy: 0.1704\n",
      "Iteration: 521 \t Total Loss:638.62665 \tTest_accuracy: 0.1704\n",
      "Iteration: 522 \t Total Loss:642.97437 \tTest_accuracy: 0.1704\n",
      "Iteration: 523 \t Total Loss:642.60760 \tTest_accuracy: 0.1704\n",
      "Iteration: 524 \t Total Loss:655.80780 \tTest_accuracy: 0.1704\n",
      "Iteration: 525 \t Total Loss:647.33966 \tTest_accuracy: 0.1704\n",
      "Iteration: 526 \t Total Loss:656.45294 \tTest_accuracy: 0.1704\n",
      "Iteration: 527 \t Total Loss:653.51190 \tTest_accuracy: 0.1704\n",
      "Iteration: 528 \t Total Loss:637.41278 \tTest_accuracy: 0.1704\n",
      "Iteration: 529 \t Total Loss:636.00946 \tTest_accuracy: 0.1704\n",
      "Iteration: 530 \t Total Loss:654.76141 \tTest_accuracy: 0.1704\n",
      "Iteration: 531 \t Total Loss:634.52612 \tTest_accuracy: 0.1704\n",
      "Iteration: 532 \t Total Loss:653.40656 \tTest_accuracy: 0.1704\n",
      "Iteration: 533 \t Total Loss:640.18188 \tTest_accuracy: 0.1704\n",
      "Iteration: 534 \t Total Loss:650.62152 \tTest_accuracy: 0.1704\n",
      "Iteration: 535 \t Total Loss:645.86310 \tTest_accuracy: 0.1704\n",
      "Iteration: 536 \t Total Loss:641.97711 \tTest_accuracy: 0.1704\n",
      "Iteration: 537 \t Total Loss:645.89893 \tTest_accuracy: 0.1704\n",
      "Iteration: 538 \t Total Loss:643.30011 \tTest_accuracy: 0.1704\n",
      "Iteration: 539 \t Total Loss:658.57184 \tTest_accuracy: 0.1704\n",
      "Iteration: 540 \t Total Loss:635.43903 \tTest_accuracy: 0.1704\n",
      "Iteration: 541 \t Total Loss:639.52582 \tTest_accuracy: 0.1704\n",
      "Iteration: 542 \t Total Loss:644.52423 \tTest_accuracy: 0.1704\n",
      "Iteration: 543 \t Total Loss:641.59515 \tTest_accuracy: 0.1704\n",
      "Iteration: 544 \t Total Loss:634.26691 \tTest_accuracy: 0.1704\n",
      "Iteration: 545 \t Total Loss:635.30042 \tTest_accuracy: 0.1704\n",
      "Iteration: 546 \t Total Loss:649.97528 \tTest_accuracy: 0.1704\n",
      "Iteration: 547 \t Total Loss:649.00024 \tTest_accuracy: 0.1704\n",
      "Iteration: 548 \t Total Loss:638.38397 \tTest_accuracy: 0.1704\n",
      "Iteration: 549 \t Total Loss:640.93378 \tTest_accuracy: 0.1704\n",
      "Iteration: 550 \t Total Loss:641.87000 \tTest_accuracy: 0.1704\n",
      "Iteration: 551 \t Total Loss:639.21777 \tTest_accuracy: 0.1704\n",
      "Iteration: 552 \t Total Loss:644.71600 \tTest_accuracy: 0.1704\n",
      "Iteration: 553 \t Total Loss:657.43439 \tTest_accuracy: 0.1704\n",
      "Iteration: 554 \t Total Loss:645.45911 \tTest_accuracy: 0.1704\n",
      "Iteration: 555 \t Total Loss:660.69147 \tTest_accuracy: 0.1704\n",
      "Iteration: 556 \t Total Loss:651.61145 \tTest_accuracy: 0.1704\n",
      "Iteration: 557 \t Total Loss:653.91565 \tTest_accuracy: 0.1704\n",
      "Iteration: 558 \t Total Loss:652.97809 \tTest_accuracy: 0.1704\n",
      "Iteration: 559 \t Total Loss:643.90851 \tTest_accuracy: 0.1704\n",
      "Iteration: 560 \t Total Loss:652.00153 \tTest_accuracy: 0.1704\n",
      "Iteration: 561 \t Total Loss:641.03766 \tTest_accuracy: 0.1704\n",
      "Iteration: 562 \t Total Loss:644.90991 \tTest_accuracy: 0.1704\n",
      "Iteration: 563 \t Total Loss:641.48950 \tTest_accuracy: 0.1704\n",
      "Iteration: 564 \t Total Loss:636.78802 \tTest_accuracy: 0.1704\n",
      "Iteration: 565 \t Total Loss:644.19659 \tTest_accuracy: 0.1704\n",
      "Iteration: 566 \t Total Loss:642.30133 \tTest_accuracy: 0.1704\n",
      "Iteration: 567 \t Total Loss:656.58783 \tTest_accuracy: 0.1704\n",
      "Iteration: 568 \t Total Loss:642.22430 \tTest_accuracy: 0.1704\n",
      "Iteration: 569 \t Total Loss:642.06488 \tTest_accuracy: 0.1704\n",
      "Iteration: 570 \t Total Loss:642.67828 \tTest_accuracy: 0.1704\n",
      "Iteration: 571 \t Total Loss:639.29321 \tTest_accuracy: 0.1704\n",
      "Iteration: 572 \t Total Loss:647.13818 \tTest_accuracy: 0.1704\n",
      "Iteration: 573 \t Total Loss:651.44928 \tTest_accuracy: 0.1704\n",
      "Iteration: 574 \t Total Loss:648.16016 \tTest_accuracy: 0.1704\n",
      "Iteration: 575 \t Total Loss:636.88574 \tTest_accuracy: 0.1704\n",
      "Iteration: 576 \t Total Loss:634.82806 \tTest_accuracy: 0.1704\n",
      "Iteration: 577 \t Total Loss:643.50354 \tTest_accuracy: 0.1704\n",
      "Iteration: 578 \t Total Loss:651.42657 \tTest_accuracy: 0.1704\n",
      "Iteration: 579 \t Total Loss:644.93878 \tTest_accuracy: 0.1704\n",
      "Iteration: 580 \t Total Loss:658.16919 \tTest_accuracy: 0.1704\n",
      "Iteration: 581 \t Total Loss:634.49237 \tTest_accuracy: 0.1704\n",
      "Iteration: 582 \t Total Loss:642.50226 \tTest_accuracy: 0.1704\n",
      "Iteration: 583 \t Total Loss:642.61206 \tTest_accuracy: 0.1704\n",
      "Iteration: 584 \t Total Loss:650.39966 \tTest_accuracy: 0.1704\n",
      "Iteration: 585 \t Total Loss:651.74792 \tTest_accuracy: 0.1704\n",
      "Iteration: 586 \t Total Loss:640.47919 \tTest_accuracy: 0.1704\n",
      "Iteration: 587 \t Total Loss:657.98785 \tTest_accuracy: 0.1704\n",
      "Iteration: 588 \t Total Loss:647.52820 \tTest_accuracy: 0.1704\n",
      "Iteration: 589 \t Total Loss:656.73413 \tTest_accuracy: 0.1704\n",
      "Iteration: 590 \t Total Loss:641.82245 \tTest_accuracy: 0.1704\n",
      "Iteration: 591 \t Total Loss:643.19385 \tTest_accuracy: 0.1704\n",
      "Iteration: 592 \t Total Loss:641.98480 \tTest_accuracy: 0.1704\n",
      "Iteration: 593 \t Total Loss:648.41534 \tTest_accuracy: 0.1704\n",
      "Iteration: 594 \t Total Loss:644.76880 \tTest_accuracy: 0.1704\n",
      "Iteration: 595 \t Total Loss:654.04132 \tTest_accuracy: 0.1704\n",
      "Iteration: 596 \t Total Loss:646.37799 \tTest_accuracy: 0.1704\n",
      "Iteration: 597 \t Total Loss:642.98676 \tTest_accuracy: 0.1704\n",
      "Iteration: 598 \t Total Loss:637.14459 \tTest_accuracy: 0.1704\n",
      "Iteration: 599 \t Total Loss:653.46661 \tTest_accuracy: 0.1704\n",
      "Iteration: 600 \t Total Loss:648.00159 \tTest_accuracy: 0.1704\n",
      "Iteration: 601 \t Total Loss:637.99591 \tTest_accuracy: 0.1704\n",
      "Iteration: 602 \t Total Loss:647.44165 \tTest_accuracy: 0.1704\n",
      "Iteration: 603 \t Total Loss:666.33759 \tTest_accuracy: 0.1704\n",
      "Iteration: 604 \t Total Loss:635.46393 \tTest_accuracy: 0.1704\n",
      "Iteration: 605 \t Total Loss:655.67291 \tTest_accuracy: 0.1704\n",
      "Iteration: 606 \t Total Loss:648.70074 \tTest_accuracy: 0.1704\n",
      "Iteration: 607 \t Total Loss:639.57257 \tTest_accuracy: 0.1704\n",
      "Iteration: 608 \t Total Loss:643.17682 \tTest_accuracy: 0.1704\n",
      "Iteration: 609 \t Total Loss:633.35693 \tTest_accuracy: 0.1704\n",
      "Iteration: 610 \t Total Loss:647.84302 \tTest_accuracy: 0.1704\n",
      "Iteration: 611 \t Total Loss:643.97937 \tTest_accuracy: 0.1704\n",
      "Iteration: 612 \t Total Loss:651.00171 \tTest_accuracy: 0.1704\n",
      "Iteration: 613 \t Total Loss:642.03107 \tTest_accuracy: 0.1704\n",
      "Iteration: 614 \t Total Loss:634.59546 \tTest_accuracy: 0.1704\n",
      "Iteration: 615 \t Total Loss:648.91565 \tTest_accuracy: 0.1704\n",
      "Iteration: 616 \t Total Loss:647.22455 \tTest_accuracy: 0.1704\n",
      "Iteration: 617 \t Total Loss:632.19019 \tTest_accuracy: 0.1704\n",
      "Iteration: 618 \t Total Loss:639.76654 \tTest_accuracy: 0.1704\n",
      "Iteration: 619 \t Total Loss:637.12567 \tTest_accuracy: 0.1704\n",
      "Iteration: 620 \t Total Loss:640.39612 \tTest_accuracy: 0.1704\n",
      "Iteration: 621 \t Total Loss:644.17609 \tTest_accuracy: 0.1704\n",
      "Iteration: 622 \t Total Loss:643.66907 \tTest_accuracy: 0.1704\n",
      "Iteration: 623 \t Total Loss:650.33978 \tTest_accuracy: 0.1704\n",
      "Iteration: 624 \t Total Loss:661.48401 \tTest_accuracy: 0.1704\n",
      "Iteration: 625 \t Total Loss:648.31757 \tTest_accuracy: 0.1704\n",
      "Iteration: 626 \t Total Loss:656.38666 \tTest_accuracy: 0.1704\n",
      "Iteration: 627 \t Total Loss:639.46490 \tTest_accuracy: 0.1704\n",
      "Iteration: 628 \t Total Loss:645.94843 \tTest_accuracy: 0.1704\n",
      "Iteration: 629 \t Total Loss:659.53308 \tTest_accuracy: 0.1704\n",
      "Iteration: 630 \t Total Loss:643.43854 \tTest_accuracy: 0.1704\n",
      "Iteration: 631 \t Total Loss:641.35980 \tTest_accuracy: 0.1704\n",
      "Iteration: 632 \t Total Loss:661.41583 \tTest_accuracy: 0.1704\n",
      "Iteration: 633 \t Total Loss:648.28827 \tTest_accuracy: 0.1704\n",
      "Iteration: 634 \t Total Loss:644.75183 \tTest_accuracy: 0.1704\n",
      "Iteration: 635 \t Total Loss:667.36188 \tTest_accuracy: 0.1704\n",
      "Iteration: 636 \t Total Loss:641.02911 \tTest_accuracy: 0.1704\n",
      "Iteration: 637 \t Total Loss:635.56915 \tTest_accuracy: 0.1704\n",
      "Iteration: 638 \t Total Loss:638.17792 \tTest_accuracy: 0.1704\n",
      "Iteration: 639 \t Total Loss:639.69440 \tTest_accuracy: 0.1704\n",
      "Iteration: 640 \t Total Loss:640.62860 \tTest_accuracy: 0.1704\n",
      "Iteration: 641 \t Total Loss:640.53607 \tTest_accuracy: 0.1704\n",
      "Iteration: 642 \t Total Loss:654.47876 \tTest_accuracy: 0.1704\n",
      "Iteration: 643 \t Total Loss:640.83521 \tTest_accuracy: 0.1704\n",
      "Iteration: 644 \t Total Loss:650.85162 \tTest_accuracy: 0.1704\n",
      "Iteration: 645 \t Total Loss:645.92865 \tTest_accuracy: 0.1704\n",
      "Iteration: 646 \t Total Loss:649.51855 \tTest_accuracy: 0.1704\n",
      "Iteration: 647 \t Total Loss:650.65643 \tTest_accuracy: 0.1704\n",
      "Iteration: 648 \t Total Loss:636.25751 \tTest_accuracy: 0.1704\n",
      "Iteration: 649 \t Total Loss:639.71466 \tTest_accuracy: 0.1704\n",
      "Iteration: 650 \t Total Loss:644.85767 \tTest_accuracy: 0.1704\n",
      "Iteration: 651 \t Total Loss:651.02826 \tTest_accuracy: 0.1704\n",
      "Iteration: 652 \t Total Loss:645.72943 \tTest_accuracy: 0.1704\n",
      "Iteration: 653 \t Total Loss:647.48956 \tTest_accuracy: 0.1704\n",
      "Iteration: 654 \t Total Loss:642.40002 \tTest_accuracy: 0.1704\n",
      "Iteration: 655 \t Total Loss:635.48785 \tTest_accuracy: 0.1704\n",
      "Iteration: 656 \t Total Loss:651.19666 \tTest_accuracy: 0.1704\n",
      "Iteration: 657 \t Total Loss:645.31317 \tTest_accuracy: 0.1704\n",
      "Iteration: 658 \t Total Loss:649.86243 \tTest_accuracy: 0.1704\n",
      "Iteration: 659 \t Total Loss:641.62762 \tTest_accuracy: 0.1704\n",
      "Iteration: 660 \t Total Loss:638.65179 \tTest_accuracy: 0.1704\n",
      "Iteration: 661 \t Total Loss:668.24847 \tTest_accuracy: 0.1704\n",
      "Iteration: 662 \t Total Loss:645.67889 \tTest_accuracy: 0.1704\n",
      "Iteration: 663 \t Total Loss:639.90131 \tTest_accuracy: 0.1704\n",
      "Iteration: 664 \t Total Loss:640.00702 \tTest_accuracy: 0.1704\n",
      "Iteration: 665 \t Total Loss:646.61426 \tTest_accuracy: 0.1704\n",
      "Iteration: 666 \t Total Loss:636.71454 \tTest_accuracy: 0.1704\n",
      "Iteration: 667 \t Total Loss:650.54974 \tTest_accuracy: 0.1704\n",
      "Iteration: 668 \t Total Loss:648.25244 \tTest_accuracy: 0.1704\n",
      "Iteration: 669 \t Total Loss:648.59320 \tTest_accuracy: 0.1704\n",
      "Iteration: 670 \t Total Loss:643.00470 \tTest_accuracy: 0.1704\n",
      "Iteration: 671 \t Total Loss:648.50836 \tTest_accuracy: 0.1704\n",
      "Iteration: 672 \t Total Loss:637.80658 \tTest_accuracy: 0.1704\n",
      "Iteration: 673 \t Total Loss:652.28046 \tTest_accuracy: 0.1704\n",
      "Iteration: 674 \t Total Loss:654.60236 \tTest_accuracy: 0.1704\n",
      "Iteration: 675 \t Total Loss:646.27899 \tTest_accuracy: 0.1704\n",
      "Iteration: 676 \t Total Loss:657.28546 \tTest_accuracy: 0.1704\n",
      "Iteration: 677 \t Total Loss:657.00641 \tTest_accuracy: 0.1704\n",
      "Iteration: 678 \t Total Loss:658.13660 \tTest_accuracy: 0.1704\n",
      "Iteration: 679 \t Total Loss:655.07019 \tTest_accuracy: 0.1704\n",
      "Iteration: 680 \t Total Loss:653.58173 \tTest_accuracy: 0.1704\n",
      "Iteration: 681 \t Total Loss:643.37030 \tTest_accuracy: 0.1704\n",
      "Iteration: 682 \t Total Loss:653.92694 \tTest_accuracy: 0.1704\n",
      "Iteration: 683 \t Total Loss:637.16827 \tTest_accuracy: 0.1704\n",
      "Iteration: 684 \t Total Loss:639.41443 \tTest_accuracy: 0.1704\n",
      "Iteration: 685 \t Total Loss:642.95392 \tTest_accuracy: 0.1704\n",
      "Iteration: 686 \t Total Loss:632.44745 \tTest_accuracy: 0.1704\n",
      "Iteration: 687 \t Total Loss:650.95117 \tTest_accuracy: 0.1704\n",
      "Iteration: 688 \t Total Loss:636.13385 \tTest_accuracy: 0.1704\n",
      "Iteration: 689 \t Total Loss:643.07776 \tTest_accuracy: 0.1704\n",
      "Iteration: 690 \t Total Loss:650.82098 \tTest_accuracy: 0.1704\n",
      "Iteration: 691 \t Total Loss:641.43634 \tTest_accuracy: 0.1704\n",
      "Iteration: 692 \t Total Loss:647.12634 \tTest_accuracy: 0.1704\n",
      "Iteration: 693 \t Total Loss:658.65253 \tTest_accuracy: 0.1704\n",
      "Iteration: 694 \t Total Loss:647.99078 \tTest_accuracy: 0.1704\n",
      "Iteration: 695 \t Total Loss:662.72296 \tTest_accuracy: 0.1704\n",
      "Iteration: 696 \t Total Loss:636.42139 \tTest_accuracy: 0.1704\n",
      "Iteration: 697 \t Total Loss:645.30292 \tTest_accuracy: 0.1704\n",
      "Iteration: 698 \t Total Loss:645.93671 \tTest_accuracy: 0.1704\n",
      "Iteration: 699 \t Total Loss:633.12244 \tTest_accuracy: 0.1704\n",
      "Iteration: 700 \t Total Loss:648.72815 \tTest_accuracy: 0.1704\n",
      "Iteration: 701 \t Total Loss:639.36377 \tTest_accuracy: 0.1704\n",
      "Iteration: 702 \t Total Loss:643.20319 \tTest_accuracy: 0.1704\n",
      "Iteration: 703 \t Total Loss:639.82367 \tTest_accuracy: 0.1704\n",
      "Iteration: 704 \t Total Loss:643.92578 \tTest_accuracy: 0.1704\n",
      "Iteration: 705 \t Total Loss:640.85583 \tTest_accuracy: 0.1704\n",
      "Iteration: 706 \t Total Loss:644.80963 \tTest_accuracy: 0.1704\n",
      "Iteration: 707 \t Total Loss:648.26019 \tTest_accuracy: 0.1704\n",
      "Iteration: 708 \t Total Loss:639.44550 \tTest_accuracy: 0.1704\n",
      "Iteration: 709 \t Total Loss:647.61530 \tTest_accuracy: 0.1704\n",
      "Iteration: 710 \t Total Loss:649.36133 \tTest_accuracy: 0.1704\n",
      "Iteration: 711 \t Total Loss:650.75842 \tTest_accuracy: 0.1704\n",
      "Iteration: 712 \t Total Loss:639.07764 \tTest_accuracy: 0.1704\n",
      "Iteration: 713 \t Total Loss:643.87946 \tTest_accuracy: 0.1704\n",
      "Iteration: 714 \t Total Loss:636.31891 \tTest_accuracy: 0.1704\n",
      "Iteration: 715 \t Total Loss:648.93225 \tTest_accuracy: 0.1704\n",
      "Iteration: 716 \t Total Loss:651.65753 \tTest_accuracy: 0.1704\n",
      "Iteration: 717 \t Total Loss:641.98413 \tTest_accuracy: 0.1704\n",
      "Iteration: 718 \t Total Loss:646.25189 \tTest_accuracy: 0.1704\n",
      "Iteration: 719 \t Total Loss:650.62079 \tTest_accuracy: 0.1704\n",
      "Iteration: 720 \t Total Loss:638.03430 \tTest_accuracy: 0.1704\n",
      "Iteration: 721 \t Total Loss:642.06750 \tTest_accuracy: 0.1704\n",
      "Iteration: 722 \t Total Loss:650.30719 \tTest_accuracy: 0.1704\n",
      "Iteration: 723 \t Total Loss:643.17328 \tTest_accuracy: 0.1704\n",
      "Iteration: 724 \t Total Loss:633.15826 \tTest_accuracy: 0.1704\n",
      "Iteration: 725 \t Total Loss:662.72040 \tTest_accuracy: 0.1704\n",
      "Iteration: 726 \t Total Loss:641.41357 \tTest_accuracy: 0.1704\n",
      "Iteration: 727 \t Total Loss:650.67743 \tTest_accuracy: 0.1704\n",
      "Iteration: 728 \t Total Loss:642.18433 \tTest_accuracy: 0.1704\n",
      "Iteration: 729 \t Total Loss:641.49457 \tTest_accuracy: 0.1704\n",
      "Iteration: 730 \t Total Loss:661.16486 \tTest_accuracy: 0.1704\n",
      "Iteration: 731 \t Total Loss:654.22925 \tTest_accuracy: 0.1704\n",
      "Iteration: 732 \t Total Loss:638.50909 \tTest_accuracy: 0.1704\n",
      "Iteration: 733 \t Total Loss:636.13892 \tTest_accuracy: 0.1704\n",
      "Iteration: 734 \t Total Loss:654.14081 \tTest_accuracy: 0.1704\n",
      "Iteration: 735 \t Total Loss:636.11334 \tTest_accuracy: 0.1704\n",
      "Iteration: 736 \t Total Loss:644.87140 \tTest_accuracy: 0.1704\n",
      "Iteration: 737 \t Total Loss:653.95551 \tTest_accuracy: 0.1704\n",
      "Iteration: 738 \t Total Loss:634.92859 \tTest_accuracy: 0.1704\n",
      "Iteration: 739 \t Total Loss:636.67975 \tTest_accuracy: 0.1704\n",
      "Iteration: 740 \t Total Loss:642.53821 \tTest_accuracy: 0.1704\n",
      "Iteration: 741 \t Total Loss:651.57007 \tTest_accuracy: 0.1704\n",
      "Iteration: 742 \t Total Loss:644.23456 \tTest_accuracy: 0.1704\n",
      "Iteration: 743 \t Total Loss:636.57904 \tTest_accuracy: 0.1704\n",
      "Iteration: 744 \t Total Loss:646.52203 \tTest_accuracy: 0.1704\n",
      "Iteration: 745 \t Total Loss:659.00323 \tTest_accuracy: 0.1704\n",
      "Iteration: 746 \t Total Loss:637.76532 \tTest_accuracy: 0.1704\n",
      "Iteration: 747 \t Total Loss:642.54340 \tTest_accuracy: 0.1704\n",
      "Iteration: 748 \t Total Loss:646.00616 \tTest_accuracy: 0.1704\n",
      "Iteration: 749 \t Total Loss:637.49921 \tTest_accuracy: 0.1704\n",
      "Iteration: 750 \t Total Loss:646.69135 \tTest_accuracy: 0.1704\n",
      "Iteration: 751 \t Total Loss:642.33197 \tTest_accuracy: 0.1704\n",
      "Iteration: 752 \t Total Loss:647.17188 \tTest_accuracy: 0.1704\n",
      "Iteration: 753 \t Total Loss:650.51593 \tTest_accuracy: 0.1704\n",
      "Iteration: 754 \t Total Loss:657.53418 \tTest_accuracy: 0.1704\n",
      "Iteration: 755 \t Total Loss:653.13470 \tTest_accuracy: 0.1704\n",
      "Iteration: 756 \t Total Loss:636.79480 \tTest_accuracy: 0.1704\n",
      "Iteration: 757 \t Total Loss:645.02545 \tTest_accuracy: 0.1704\n",
      "Iteration: 758 \t Total Loss:643.12964 \tTest_accuracy: 0.1704\n",
      "Iteration: 759 \t Total Loss:647.99127 \tTest_accuracy: 0.1704\n",
      "Iteration: 760 \t Total Loss:647.82050 \tTest_accuracy: 0.1704\n",
      "Iteration: 761 \t Total Loss:656.01642 \tTest_accuracy: 0.1704\n",
      "Iteration: 762 \t Total Loss:645.28571 \tTest_accuracy: 0.1704\n",
      "Iteration: 763 \t Total Loss:651.10162 \tTest_accuracy: 0.1704\n",
      "Iteration: 764 \t Total Loss:643.51984 \tTest_accuracy: 0.1704\n",
      "Iteration: 765 \t Total Loss:638.61279 \tTest_accuracy: 0.1704\n",
      "Iteration: 766 \t Total Loss:644.34772 \tTest_accuracy: 0.1704\n",
      "Iteration: 767 \t Total Loss:642.55145 \tTest_accuracy: 0.1704\n",
      "Iteration: 768 \t Total Loss:657.61066 \tTest_accuracy: 0.1704\n",
      "Iteration: 769 \t Total Loss:650.76215 \tTest_accuracy: 0.1704\n",
      "Iteration: 770 \t Total Loss:631.11566 \tTest_accuracy: 0.1704\n",
      "Iteration: 771 \t Total Loss:642.92407 \tTest_accuracy: 0.1704\n",
      "Iteration: 772 \t Total Loss:638.40997 \tTest_accuracy: 0.1704\n",
      "Iteration: 773 \t Total Loss:640.19769 \tTest_accuracy: 0.1704\n",
      "Iteration: 774 \t Total Loss:654.80353 \tTest_accuracy: 0.1704\n",
      "Iteration: 775 \t Total Loss:652.96509 \tTest_accuracy: 0.1704\n",
      "Iteration: 776 \t Total Loss:660.86017 \tTest_accuracy: 0.1704\n",
      "Iteration: 777 \t Total Loss:650.58575 \tTest_accuracy: 0.1704\n",
      "Iteration: 778 \t Total Loss:640.71082 \tTest_accuracy: 0.1704\n",
      "Iteration: 779 \t Total Loss:662.57428 \tTest_accuracy: 0.1704\n",
      "Iteration: 780 \t Total Loss:646.63678 \tTest_accuracy: 0.1704\n",
      "Iteration: 781 \t Total Loss:635.49933 \tTest_accuracy: 0.1704\n",
      "Iteration: 782 \t Total Loss:657.14581 \tTest_accuracy: 0.1704\n",
      "Iteration: 783 \t Total Loss:652.39532 \tTest_accuracy: 0.1704\n",
      "Iteration: 784 \t Total Loss:639.37482 \tTest_accuracy: 0.1704\n",
      "Iteration: 785 \t Total Loss:658.00995 \tTest_accuracy: 0.1704\n",
      "Iteration: 786 \t Total Loss:636.99054 \tTest_accuracy: 0.1704\n",
      "Iteration: 787 \t Total Loss:641.91937 \tTest_accuracy: 0.1704\n",
      "Iteration: 788 \t Total Loss:657.72308 \tTest_accuracy: 0.1704\n",
      "Iteration: 789 \t Total Loss:644.14136 \tTest_accuracy: 0.1704\n",
      "Iteration: 790 \t Total Loss:640.00214 \tTest_accuracy: 0.1704\n",
      "Iteration: 791 \t Total Loss:648.15942 \tTest_accuracy: 0.1704\n",
      "Iteration: 792 \t Total Loss:642.02863 \tTest_accuracy: 0.1704\n",
      "Iteration: 793 \t Total Loss:630.94519 \tTest_accuracy: 0.1704\n",
      "Iteration: 794 \t Total Loss:658.66901 \tTest_accuracy: 0.1704\n",
      "Iteration: 795 \t Total Loss:630.30243 \tTest_accuracy: 0.1704\n",
      "Iteration: 796 \t Total Loss:639.88702 \tTest_accuracy: 0.1704\n",
      "Iteration: 797 \t Total Loss:648.31696 \tTest_accuracy: 0.1704\n",
      "Iteration: 798 \t Total Loss:640.77710 \tTest_accuracy: 0.1704\n",
      "Iteration: 799 \t Total Loss:649.65521 \tTest_accuracy: 0.1704\n",
      "Iteration: 800 \t Total Loss:649.20294 \tTest_accuracy: 0.1704\n",
      "Iteration: 801 \t Total Loss:656.34479 \tTest_accuracy: 0.1704\n",
      "Iteration: 802 \t Total Loss:635.16510 \tTest_accuracy: 0.1704\n",
      "Iteration: 803 \t Total Loss:645.85712 \tTest_accuracy: 0.1704\n",
      "Iteration: 804 \t Total Loss:644.66193 \tTest_accuracy: 0.1704\n",
      "Iteration: 805 \t Total Loss:646.12878 \tTest_accuracy: 0.1704\n",
      "Iteration: 806 \t Total Loss:658.67688 \tTest_accuracy: 0.1704\n",
      "Iteration: 807 \t Total Loss:639.74951 \tTest_accuracy: 0.1704\n",
      "Iteration: 808 \t Total Loss:643.57574 \tTest_accuracy: 0.1704\n",
      "Iteration: 809 \t Total Loss:646.66736 \tTest_accuracy: 0.1704\n",
      "Iteration: 810 \t Total Loss:635.53754 \tTest_accuracy: 0.1704\n",
      "Iteration: 811 \t Total Loss:648.43414 \tTest_accuracy: 0.1704\n",
      "Iteration: 812 \t Total Loss:638.35638 \tTest_accuracy: 0.1704\n",
      "Iteration: 813 \t Total Loss:643.83990 \tTest_accuracy: 0.1704\n",
      "Iteration: 814 \t Total Loss:647.76147 \tTest_accuracy: 0.1704\n",
      "Iteration: 815 \t Total Loss:654.57635 \tTest_accuracy: 0.1704\n",
      "Iteration: 816 \t Total Loss:647.41486 \tTest_accuracy: 0.1704\n",
      "Iteration: 817 \t Total Loss:640.67206 \tTest_accuracy: 0.1704\n",
      "Iteration: 818 \t Total Loss:632.53156 \tTest_accuracy: 0.1704\n",
      "Iteration: 819 \t Total Loss:643.44574 \tTest_accuracy: 0.1704\n",
      "Iteration: 820 \t Total Loss:652.31757 \tTest_accuracy: 0.1704\n",
      "Iteration: 821 \t Total Loss:648.63257 \tTest_accuracy: 0.1704\n",
      "Iteration: 822 \t Total Loss:653.97076 \tTest_accuracy: 0.1704\n",
      "Iteration: 823 \t Total Loss:638.66180 \tTest_accuracy: 0.1704\n",
      "Iteration: 824 \t Total Loss:650.48621 \tTest_accuracy: 0.1704\n",
      "Iteration: 825 \t Total Loss:632.87189 \tTest_accuracy: 0.1704\n",
      "Iteration: 826 \t Total Loss:636.16663 \tTest_accuracy: 0.1704\n",
      "Iteration: 827 \t Total Loss:645.84821 \tTest_accuracy: 0.1704\n",
      "Iteration: 828 \t Total Loss:652.20117 \tTest_accuracy: 0.1704\n",
      "Iteration: 829 \t Total Loss:643.21692 \tTest_accuracy: 0.1704\n",
      "Iteration: 830 \t Total Loss:643.06873 \tTest_accuracy: 0.1704\n",
      "Iteration: 831 \t Total Loss:639.14368 \tTest_accuracy: 0.1704\n",
      "Iteration: 832 \t Total Loss:658.11011 \tTest_accuracy: 0.1704\n",
      "Iteration: 833 \t Total Loss:643.15912 \tTest_accuracy: 0.1704\n",
      "Iteration: 834 \t Total Loss:646.51874 \tTest_accuracy: 0.1704\n",
      "Iteration: 835 \t Total Loss:649.86200 \tTest_accuracy: 0.1704\n",
      "Iteration: 836 \t Total Loss:639.47858 \tTest_accuracy: 0.1704\n",
      "Iteration: 837 \t Total Loss:638.35492 \tTest_accuracy: 0.1704\n",
      "Iteration: 838 \t Total Loss:647.37854 \tTest_accuracy: 0.1704\n",
      "Iteration: 839 \t Total Loss:646.10083 \tTest_accuracy: 0.1704\n",
      "Iteration: 840 \t Total Loss:643.67108 \tTest_accuracy: 0.1704\n",
      "Iteration: 841 \t Total Loss:643.49402 \tTest_accuracy: 0.1704\n",
      "Iteration: 842 \t Total Loss:644.05170 \tTest_accuracy: 0.1704\n",
      "Iteration: 843 \t Total Loss:641.88123 \tTest_accuracy: 0.1704\n",
      "Iteration: 844 \t Total Loss:648.56842 \tTest_accuracy: 0.1704\n",
      "Iteration: 845 \t Total Loss:644.68616 \tTest_accuracy: 0.1704\n",
      "Iteration: 846 \t Total Loss:657.70135 \tTest_accuracy: 0.1704\n",
      "Iteration: 847 \t Total Loss:653.63397 \tTest_accuracy: 0.1704\n",
      "Iteration: 848 \t Total Loss:651.10419 \tTest_accuracy: 0.1704\n",
      "Iteration: 849 \t Total Loss:641.15717 \tTest_accuracy: 0.1704\n",
      "Iteration: 850 \t Total Loss:646.67383 \tTest_accuracy: 0.1704\n",
      "Iteration: 851 \t Total Loss:657.78571 \tTest_accuracy: 0.1704\n",
      "Iteration: 852 \t Total Loss:649.00946 \tTest_accuracy: 0.1704\n",
      "Iteration: 853 \t Total Loss:646.37531 \tTest_accuracy: 0.1704\n",
      "Iteration: 854 \t Total Loss:651.47571 \tTest_accuracy: 0.1704\n",
      "Iteration: 855 \t Total Loss:647.24530 \tTest_accuracy: 0.1704\n",
      "Iteration: 856 \t Total Loss:653.63544 \tTest_accuracy: 0.1704\n",
      "Iteration: 857 \t Total Loss:637.78290 \tTest_accuracy: 0.1704\n",
      "Iteration: 858 \t Total Loss:646.16754 \tTest_accuracy: 0.1704\n",
      "Iteration: 859 \t Total Loss:638.20551 \tTest_accuracy: 0.1704\n",
      "Iteration: 860 \t Total Loss:649.50018 \tTest_accuracy: 0.1704\n",
      "Iteration: 861 \t Total Loss:637.59113 \tTest_accuracy: 0.1704\n",
      "Iteration: 862 \t Total Loss:638.78064 \tTest_accuracy: 0.1704\n",
      "Iteration: 863 \t Total Loss:641.55225 \tTest_accuracy: 0.1704\n",
      "Iteration: 864 \t Total Loss:641.26849 \tTest_accuracy: 0.1704\n",
      "Iteration: 865 \t Total Loss:649.80780 \tTest_accuracy: 0.1704\n",
      "Iteration: 866 \t Total Loss:656.74677 \tTest_accuracy: 0.1704\n",
      "Iteration: 867 \t Total Loss:643.88171 \tTest_accuracy: 0.1704\n",
      "Iteration: 868 \t Total Loss:639.53436 \tTest_accuracy: 0.1704\n",
      "Iteration: 869 \t Total Loss:647.16766 \tTest_accuracy: 0.1704\n",
      "Iteration: 870 \t Total Loss:639.86322 \tTest_accuracy: 0.1704\n",
      "Iteration: 871 \t Total Loss:642.77484 \tTest_accuracy: 0.1704\n",
      "Iteration: 872 \t Total Loss:642.16382 \tTest_accuracy: 0.1704\n",
      "Iteration: 873 \t Total Loss:657.07208 \tTest_accuracy: 0.1704\n",
      "Iteration: 874 \t Total Loss:642.48334 \tTest_accuracy: 0.1704\n",
      "Iteration: 875 \t Total Loss:650.67755 \tTest_accuracy: 0.1704\n",
      "Iteration: 876 \t Total Loss:636.99243 \tTest_accuracy: 0.1704\n",
      "Iteration: 877 \t Total Loss:645.96063 \tTest_accuracy: 0.1704\n",
      "Iteration: 878 \t Total Loss:644.53839 \tTest_accuracy: 0.1704\n",
      "Iteration: 879 \t Total Loss:643.10138 \tTest_accuracy: 0.1704\n",
      "Iteration: 880 \t Total Loss:641.09601 \tTest_accuracy: 0.1704\n",
      "Iteration: 881 \t Total Loss:653.23730 \tTest_accuracy: 0.1704\n",
      "Iteration: 882 \t Total Loss:636.98859 \tTest_accuracy: 0.1704\n",
      "Iteration: 883 \t Total Loss:650.25659 \tTest_accuracy: 0.1704\n",
      "Iteration: 884 \t Total Loss:641.85059 \tTest_accuracy: 0.1704\n",
      "Iteration: 885 \t Total Loss:640.56317 \tTest_accuracy: 0.1704\n",
      "Iteration: 886 \t Total Loss:635.65149 \tTest_accuracy: 0.1704\n",
      "Iteration: 887 \t Total Loss:645.80243 \tTest_accuracy: 0.1704\n",
      "Iteration: 888 \t Total Loss:644.19513 \tTest_accuracy: 0.1704\n",
      "Iteration: 889 \t Total Loss:654.55939 \tTest_accuracy: 0.1704\n",
      "Iteration: 890 \t Total Loss:641.87933 \tTest_accuracy: 0.1704\n",
      "Iteration: 891 \t Total Loss:645.83734 \tTest_accuracy: 0.1704\n",
      "Iteration: 892 \t Total Loss:650.55536 \tTest_accuracy: 0.1704\n",
      "Iteration: 893 \t Total Loss:644.40198 \tTest_accuracy: 0.1704\n",
      "Iteration: 894 \t Total Loss:648.24884 \tTest_accuracy: 0.1704\n",
      "Iteration: 895 \t Total Loss:651.42145 \tTest_accuracy: 0.1704\n",
      "Iteration: 896 \t Total Loss:645.70508 \tTest_accuracy: 0.1704\n",
      "Iteration: 897 \t Total Loss:647.35461 \tTest_accuracy: 0.1704\n",
      "Iteration: 898 \t Total Loss:639.25397 \tTest_accuracy: 0.1704\n",
      "Iteration: 899 \t Total Loss:655.16589 \tTest_accuracy: 0.1704\n",
      "Iteration: 900 \t Total Loss:637.47839 \tTest_accuracy: 0.1704\n",
      "Iteration: 901 \t Total Loss:642.02484 \tTest_accuracy: 0.1704\n",
      "Iteration: 902 \t Total Loss:647.45990 \tTest_accuracy: 0.1704\n",
      "Iteration: 903 \t Total Loss:645.13153 \tTest_accuracy: 0.1704\n",
      "Iteration: 904 \t Total Loss:656.05621 \tTest_accuracy: 0.1704\n",
      "Iteration: 905 \t Total Loss:648.66071 \tTest_accuracy: 0.1704\n",
      "Iteration: 906 \t Total Loss:639.85089 \tTest_accuracy: 0.1704\n",
      "Iteration: 907 \t Total Loss:653.11578 \tTest_accuracy: 0.1704\n",
      "Iteration: 908 \t Total Loss:649.74188 \tTest_accuracy: 0.1704\n",
      "Iteration: 909 \t Total Loss:644.00238 \tTest_accuracy: 0.1704\n",
      "Iteration: 910 \t Total Loss:653.61249 \tTest_accuracy: 0.1704\n",
      "Iteration: 911 \t Total Loss:636.95551 \tTest_accuracy: 0.1704\n",
      "Iteration: 912 \t Total Loss:648.03241 \tTest_accuracy: 0.1704\n",
      "Iteration: 913 \t Total Loss:642.14325 \tTest_accuracy: 0.1704\n",
      "Iteration: 914 \t Total Loss:638.43817 \tTest_accuracy: 0.1704\n",
      "Iteration: 915 \t Total Loss:662.68158 \tTest_accuracy: 0.1704\n",
      "Iteration: 916 \t Total Loss:649.40985 \tTest_accuracy: 0.1704\n",
      "Iteration: 917 \t Total Loss:650.20898 \tTest_accuracy: 0.1704\n",
      "Iteration: 918 \t Total Loss:655.68073 \tTest_accuracy: 0.1704\n",
      "Iteration: 919 \t Total Loss:650.94781 \tTest_accuracy: 0.1704\n",
      "Iteration: 920 \t Total Loss:659.50641 \tTest_accuracy: 0.1704\n",
      "Iteration: 921 \t Total Loss:638.82245 \tTest_accuracy: 0.1704\n",
      "Iteration: 922 \t Total Loss:641.89520 \tTest_accuracy: 0.1704\n",
      "Iteration: 923 \t Total Loss:652.32910 \tTest_accuracy: 0.1704\n",
      "Iteration: 924 \t Total Loss:640.78204 \tTest_accuracy: 0.1704\n",
      "Iteration: 925 \t Total Loss:645.48083 \tTest_accuracy: 0.1704\n",
      "Iteration: 926 \t Total Loss:638.94812 \tTest_accuracy: 0.1704\n",
      "Iteration: 927 \t Total Loss:654.75421 \tTest_accuracy: 0.1704\n",
      "Iteration: 928 \t Total Loss:656.58020 \tTest_accuracy: 0.1704\n",
      "Iteration: 929 \t Total Loss:660.01208 \tTest_accuracy: 0.1704\n",
      "Iteration: 930 \t Total Loss:638.10748 \tTest_accuracy: 0.1704\n",
      "Iteration: 931 \t Total Loss:643.09924 \tTest_accuracy: 0.1704\n",
      "Iteration: 932 \t Total Loss:657.79663 \tTest_accuracy: 0.1704\n",
      "Iteration: 933 \t Total Loss:642.52594 \tTest_accuracy: 0.1704\n",
      "Iteration: 934 \t Total Loss:655.70221 \tTest_accuracy: 0.1704\n",
      "Iteration: 935 \t Total Loss:649.94092 \tTest_accuracy: 0.1704\n",
      "Iteration: 936 \t Total Loss:639.64862 \tTest_accuracy: 0.1704\n",
      "Iteration: 937 \t Total Loss:642.23944 \tTest_accuracy: 0.1704\n",
      "Iteration: 938 \t Total Loss:650.61731 \tTest_accuracy: 0.1704\n",
      "Iteration: 939 \t Total Loss:641.84064 \tTest_accuracy: 0.1704\n",
      "Iteration: 940 \t Total Loss:648.30914 \tTest_accuracy: 0.1704\n",
      "Iteration: 941 \t Total Loss:645.04791 \tTest_accuracy: 0.1704\n",
      "Iteration: 942 \t Total Loss:642.40906 \tTest_accuracy: 0.1704\n",
      "Iteration: 943 \t Total Loss:640.58734 \tTest_accuracy: 0.1704\n",
      "Iteration: 944 \t Total Loss:649.30402 \tTest_accuracy: 0.1704\n",
      "Iteration: 945 \t Total Loss:638.44922 \tTest_accuracy: 0.1704\n",
      "Iteration: 946 \t Total Loss:637.44434 \tTest_accuracy: 0.1704\n",
      "Iteration: 947 \t Total Loss:636.04950 \tTest_accuracy: 0.1704\n",
      "Iteration: 948 \t Total Loss:655.50104 \tTest_accuracy: 0.1704\n",
      "Iteration: 949 \t Total Loss:643.42065 \tTest_accuracy: 0.1704\n",
      "Iteration: 950 \t Total Loss:654.78357 \tTest_accuracy: 0.1704\n",
      "Iteration: 951 \t Total Loss:635.79895 \tTest_accuracy: 0.1704\n",
      "Iteration: 952 \t Total Loss:645.53973 \tTest_accuracy: 0.1704\n",
      "Iteration: 953 \t Total Loss:637.29578 \tTest_accuracy: 0.1704\n",
      "Iteration: 954 \t Total Loss:647.78186 \tTest_accuracy: 0.1704\n",
      "Iteration: 955 \t Total Loss:653.96106 \tTest_accuracy: 0.1704\n",
      "Iteration: 956 \t Total Loss:641.72931 \tTest_accuracy: 0.1704\n",
      "Iteration: 957 \t Total Loss:654.52423 \tTest_accuracy: 0.1704\n",
      "Iteration: 958 \t Total Loss:634.07959 \tTest_accuracy: 0.1704\n",
      "Iteration: 959 \t Total Loss:656.73682 \tTest_accuracy: 0.1704\n",
      "Iteration: 960 \t Total Loss:651.83966 \tTest_accuracy: 0.1704\n",
      "Iteration: 961 \t Total Loss:648.24817 \tTest_accuracy: 0.1704\n",
      "Iteration: 962 \t Total Loss:637.93158 \tTest_accuracy: 0.1704\n",
      "Iteration: 963 \t Total Loss:641.48822 \tTest_accuracy: 0.1704\n",
      "Iteration: 964 \t Total Loss:638.98724 \tTest_accuracy: 0.1704\n",
      "Iteration: 965 \t Total Loss:648.28094 \tTest_accuracy: 0.1704\n",
      "Iteration: 966 \t Total Loss:637.69800 \tTest_accuracy: 0.1704\n",
      "Iteration: 967 \t Total Loss:644.46167 \tTest_accuracy: 0.1704\n",
      "Iteration: 968 \t Total Loss:638.98529 \tTest_accuracy: 0.1704\n",
      "Iteration: 969 \t Total Loss:653.17065 \tTest_accuracy: 0.1704\n",
      "Iteration: 970 \t Total Loss:639.51031 \tTest_accuracy: 0.1704\n",
      "Iteration: 971 \t Total Loss:649.47327 \tTest_accuracy: 0.1704\n",
      "Iteration: 972 \t Total Loss:658.76324 \tTest_accuracy: 0.1704\n",
      "Iteration: 973 \t Total Loss:641.25513 \tTest_accuracy: 0.1704\n",
      "Iteration: 974 \t Total Loss:643.79999 \tTest_accuracy: 0.1704\n",
      "Iteration: 975 \t Total Loss:640.12939 \tTest_accuracy: 0.1704\n",
      "Iteration: 976 \t Total Loss:640.96649 \tTest_accuracy: 0.1704\n",
      "Iteration: 977 \t Total Loss:641.67072 \tTest_accuracy: 0.1704\n",
      "Iteration: 978 \t Total Loss:646.11749 \tTest_accuracy: 0.1704\n",
      "Iteration: 979 \t Total Loss:640.26691 \tTest_accuracy: 0.1704\n",
      "Iteration: 980 \t Total Loss:632.75928 \tTest_accuracy: 0.1704\n",
      "Iteration: 981 \t Total Loss:646.43787 \tTest_accuracy: 0.1704\n",
      "Iteration: 982 \t Total Loss:650.58868 \tTest_accuracy: 0.1704\n",
      "Iteration: 983 \t Total Loss:640.26129 \tTest_accuracy: 0.1704\n",
      "Iteration: 984 \t Total Loss:643.90906 \tTest_accuracy: 0.1704\n",
      "Iteration: 985 \t Total Loss:644.87128 \tTest_accuracy: 0.1704\n",
      "Iteration: 986 \t Total Loss:640.99432 \tTest_accuracy: 0.1704\n",
      "Iteration: 987 \t Total Loss:662.99786 \tTest_accuracy: 0.1704\n",
      "Iteration: 988 \t Total Loss:643.85181 \tTest_accuracy: 0.1704\n",
      "Iteration: 989 \t Total Loss:652.21869 \tTest_accuracy: 0.1704\n",
      "Iteration: 990 \t Total Loss:650.02899 \tTest_accuracy: 0.1704\n",
      "Iteration: 991 \t Total Loss:639.24164 \tTest_accuracy: 0.1704\n",
      "Iteration: 992 \t Total Loss:655.44031 \tTest_accuracy: 0.1704\n",
      "Iteration: 993 \t Total Loss:652.99194 \tTest_accuracy: 0.1704\n",
      "Iteration: 994 \t Total Loss:640.88483 \tTest_accuracy: 0.1704\n",
      "Iteration: 995 \t Total Loss:640.98242 \tTest_accuracy: 0.1704\n",
      "Iteration: 996 \t Total Loss:632.61133 \tTest_accuracy: 0.1704\n",
      "Iteration: 997 \t Total Loss:633.37775 \tTest_accuracy: 0.1704\n",
      "Iteration: 998 \t Total Loss:648.32849 \tTest_accuracy: 0.1704\n",
      "Iteration: 999 \t Total Loss:643.38080 \tTest_accuracy: 0.1704\n",
      "Iteration: 1000 \t Total Loss:655.90033 \tTest_accuracy: 0.1704\n",
      "Iteration: 1001 \t Total Loss:640.22736 \tTest_accuracy: 0.1704\n",
      "Iteration: 1002 \t Total Loss:637.61365 \tTest_accuracy: 0.1704\n",
      "Iteration: 1003 \t Total Loss:656.54718 \tTest_accuracy: 0.1704\n",
      "Iteration: 1004 \t Total Loss:643.93335 \tTest_accuracy: 0.1704\n",
      "Iteration: 1005 \t Total Loss:647.42853 \tTest_accuracy: 0.1704\n",
      "Iteration: 1006 \t Total Loss:652.60315 \tTest_accuracy: 0.1704\n",
      "Iteration: 1007 \t Total Loss:639.55829 \tTest_accuracy: 0.1704\n",
      "Iteration: 1008 \t Total Loss:638.94312 \tTest_accuracy: 0.1704\n",
      "Iteration: 1009 \t Total Loss:652.88483 \tTest_accuracy: 0.1704\n",
      "Iteration: 1010 \t Total Loss:662.99854 \tTest_accuracy: 0.1704\n",
      "Iteration: 1011 \t Total Loss:640.76251 \tTest_accuracy: 0.1704\n",
      "Iteration: 1012 \t Total Loss:648.33685 \tTest_accuracy: 0.1704\n",
      "Iteration: 1013 \t Total Loss:641.80774 \tTest_accuracy: 0.1704\n",
      "Iteration: 1014 \t Total Loss:654.50671 \tTest_accuracy: 0.1704\n",
      "Iteration: 1015 \t Total Loss:656.17462 \tTest_accuracy: 0.1704\n",
      "Iteration: 1016 \t Total Loss:645.58386 \tTest_accuracy: 0.1704\n",
      "Iteration: 1017 \t Total Loss:652.50677 \tTest_accuracy: 0.1704\n",
      "Iteration: 1018 \t Total Loss:644.52167 \tTest_accuracy: 0.1704\n",
      "Iteration: 1019 \t Total Loss:647.92389 \tTest_accuracy: 0.1704\n",
      "Iteration: 1020 \t Total Loss:652.05347 \tTest_accuracy: 0.1704\n",
      "Iteration: 1021 \t Total Loss:639.43427 \tTest_accuracy: 0.1704\n",
      "Iteration: 1022 \t Total Loss:645.12054 \tTest_accuracy: 0.1704\n",
      "Iteration: 1023 \t Total Loss:638.64020 \tTest_accuracy: 0.1704\n",
      "Iteration: 1024 \t Total Loss:639.90222 \tTest_accuracy: 0.1704\n",
      "Iteration: 1025 \t Total Loss:646.54785 \tTest_accuracy: 0.1704\n",
      "Iteration: 1026 \t Total Loss:654.66486 \tTest_accuracy: 0.1704\n",
      "Iteration: 1027 \t Total Loss:638.19305 \tTest_accuracy: 0.1704\n",
      "Iteration: 1028 \t Total Loss:647.28070 \tTest_accuracy: 0.1704\n",
      "Iteration: 1029 \t Total Loss:655.42316 \tTest_accuracy: 0.1704\n",
      "Iteration: 1030 \t Total Loss:655.41040 \tTest_accuracy: 0.1704\n",
      "Iteration: 1031 \t Total Loss:647.87811 \tTest_accuracy: 0.1704\n",
      "Iteration: 1032 \t Total Loss:641.54669 \tTest_accuracy: 0.1704\n",
      "Iteration: 1033 \t Total Loss:636.78766 \tTest_accuracy: 0.1704\n",
      "Iteration: 1034 \t Total Loss:647.44830 \tTest_accuracy: 0.1704\n",
      "Iteration: 1035 \t Total Loss:645.23492 \tTest_accuracy: 0.1704\n",
      "Iteration: 1036 \t Total Loss:646.06519 \tTest_accuracy: 0.1704\n",
      "Iteration: 1037 \t Total Loss:662.17688 \tTest_accuracy: 0.1704\n",
      "Iteration: 1038 \t Total Loss:642.90948 \tTest_accuracy: 0.1704\n",
      "Iteration: 1039 \t Total Loss:632.34192 \tTest_accuracy: 0.1704\n",
      "Iteration: 1040 \t Total Loss:643.84833 \tTest_accuracy: 0.1704\n",
      "Iteration: 1041 \t Total Loss:650.57526 \tTest_accuracy: 0.1704\n",
      "Iteration: 1042 \t Total Loss:651.90167 \tTest_accuracy: 0.1704\n",
      "Iteration: 1043 \t Total Loss:641.26807 \tTest_accuracy: 0.1704\n",
      "Iteration: 1044 \t Total Loss:648.16388 \tTest_accuracy: 0.1704\n",
      "Iteration: 1045 \t Total Loss:653.59961 \tTest_accuracy: 0.1704\n",
      "Iteration: 1046 \t Total Loss:640.45404 \tTest_accuracy: 0.1704\n",
      "Iteration: 1047 \t Total Loss:649.16180 \tTest_accuracy: 0.1704\n",
      "Iteration: 1048 \t Total Loss:645.51276 \tTest_accuracy: 0.1704\n",
      "Iteration: 1049 \t Total Loss:642.09326 \tTest_accuracy: 0.1704\n",
      "Iteration: 1050 \t Total Loss:648.96289 \tTest_accuracy: 0.1704\n",
      "Iteration: 1051 \t Total Loss:637.77997 \tTest_accuracy: 0.1704\n",
      "Iteration: 1052 \t Total Loss:642.51556 \tTest_accuracy: 0.1704\n",
      "Iteration: 1053 \t Total Loss:655.62482 \tTest_accuracy: 0.1704\n",
      "Iteration: 1054 \t Total Loss:651.94135 \tTest_accuracy: 0.1704\n",
      "Iteration: 1055 \t Total Loss:637.08038 \tTest_accuracy: 0.1704\n",
      "Iteration: 1056 \t Total Loss:655.98578 \tTest_accuracy: 0.1704\n",
      "Iteration: 1057 \t Total Loss:641.16364 \tTest_accuracy: 0.1704\n",
      "Iteration: 1058 \t Total Loss:658.51227 \tTest_accuracy: 0.1704\n",
      "Iteration: 1059 \t Total Loss:648.34003 \tTest_accuracy: 0.1704\n",
      "Iteration: 1060 \t Total Loss:636.29413 \tTest_accuracy: 0.1704\n",
      "Iteration: 1061 \t Total Loss:649.86365 \tTest_accuracy: 0.1704\n",
      "Iteration: 1062 \t Total Loss:637.62183 \tTest_accuracy: 0.1704\n",
      "Iteration: 1063 \t Total Loss:635.35443 \tTest_accuracy: 0.1704\n",
      "Iteration: 1064 \t Total Loss:650.07233 \tTest_accuracy: 0.1704\n",
      "Iteration: 1065 \t Total Loss:642.47028 \tTest_accuracy: 0.1704\n",
      "Iteration: 1066 \t Total Loss:638.73328 \tTest_accuracy: 0.1704\n",
      "Iteration: 1067 \t Total Loss:639.07593 \tTest_accuracy: 0.1704\n",
      "Iteration: 1068 \t Total Loss:642.12885 \tTest_accuracy: 0.1704\n",
      "Iteration: 1069 \t Total Loss:654.39069 \tTest_accuracy: 0.1704\n",
      "Iteration: 1070 \t Total Loss:644.74969 \tTest_accuracy: 0.1704\n",
      "Iteration: 1071 \t Total Loss:649.57031 \tTest_accuracy: 0.1704\n",
      "Iteration: 1072 \t Total Loss:639.11993 \tTest_accuracy: 0.1704\n",
      "Iteration: 1073 \t Total Loss:645.03131 \tTest_accuracy: 0.1704\n",
      "Iteration: 1074 \t Total Loss:643.31598 \tTest_accuracy: 0.1704\n",
      "Iteration: 1075 \t Total Loss:652.44183 \tTest_accuracy: 0.1704\n",
      "Iteration: 1076 \t Total Loss:642.25018 \tTest_accuracy: 0.1704\n",
      "Iteration: 1077 \t Total Loss:633.52673 \tTest_accuracy: 0.1704\n",
      "Iteration: 1078 \t Total Loss:645.69824 \tTest_accuracy: 0.1704\n",
      "Iteration: 1079 \t Total Loss:645.10852 \tTest_accuracy: 0.1704\n",
      "Iteration: 1080 \t Total Loss:650.03522 \tTest_accuracy: 0.1704\n",
      "Iteration: 1081 \t Total Loss:637.09167 \tTest_accuracy: 0.1704\n",
      "Iteration: 1082 \t Total Loss:642.24982 \tTest_accuracy: 0.1704\n",
      "Iteration: 1083 \t Total Loss:658.66644 \tTest_accuracy: 0.1704\n",
      "Iteration: 1084 \t Total Loss:645.64417 \tTest_accuracy: 0.1704\n",
      "Iteration: 1085 \t Total Loss:645.98004 \tTest_accuracy: 0.1704\n",
      "Iteration: 1086 \t Total Loss:639.21436 \tTest_accuracy: 0.1704\n",
      "Iteration: 1087 \t Total Loss:635.81586 \tTest_accuracy: 0.1704\n",
      "Iteration: 1088 \t Total Loss:652.06201 \tTest_accuracy: 0.1704\n",
      "Iteration: 1089 \t Total Loss:650.76556 \tTest_accuracy: 0.1704\n",
      "Iteration: 1090 \t Total Loss:638.08380 \tTest_accuracy: 0.1704\n",
      "Iteration: 1091 \t Total Loss:643.91827 \tTest_accuracy: 0.1704\n",
      "Iteration: 1092 \t Total Loss:641.33051 \tTest_accuracy: 0.1704\n",
      "Iteration: 1093 \t Total Loss:648.93829 \tTest_accuracy: 0.1704\n",
      "Iteration: 1094 \t Total Loss:649.21924 \tTest_accuracy: 0.1704\n",
      "Iteration: 1095 \t Total Loss:634.05267 \tTest_accuracy: 0.1704\n",
      "Iteration: 1096 \t Total Loss:633.80945 \tTest_accuracy: 0.1704\n",
      "Iteration: 1097 \t Total Loss:645.98328 \tTest_accuracy: 0.1704\n",
      "Iteration: 1098 \t Total Loss:655.15399 \tTest_accuracy: 0.1704\n",
      "Iteration: 1099 \t Total Loss:638.05884 \tTest_accuracy: 0.1704\n",
      "Iteration: 1100 \t Total Loss:654.35748 \tTest_accuracy: 0.1704\n",
      "Iteration: 1101 \t Total Loss:644.06934 \tTest_accuracy: 0.1704\n",
      "Iteration: 1102 \t Total Loss:656.94214 \tTest_accuracy: 0.1704\n",
      "Iteration: 1103 \t Total Loss:662.19366 \tTest_accuracy: 0.1704\n",
      "Iteration: 1104 \t Total Loss:648.81409 \tTest_accuracy: 0.1704\n",
      "Iteration: 1105 \t Total Loss:644.12219 \tTest_accuracy: 0.1704\n",
      "Iteration: 1106 \t Total Loss:642.22296 \tTest_accuracy: 0.1704\n",
      "Iteration: 1107 \t Total Loss:643.17017 \tTest_accuracy: 0.1704\n",
      "Iteration: 1108 \t Total Loss:648.28754 \tTest_accuracy: 0.1704\n",
      "Iteration: 1109 \t Total Loss:639.47705 \tTest_accuracy: 0.1704\n",
      "Iteration: 1110 \t Total Loss:648.20947 \tTest_accuracy: 0.1704\n",
      "Iteration: 1111 \t Total Loss:643.53778 \tTest_accuracy: 0.1704\n",
      "Iteration: 1112 \t Total Loss:650.06451 \tTest_accuracy: 0.1704\n",
      "Iteration: 1113 \t Total Loss:656.75818 \tTest_accuracy: 0.1704\n",
      "Iteration: 1114 \t Total Loss:640.64703 \tTest_accuracy: 0.1704\n",
      "Iteration: 1115 \t Total Loss:641.70691 \tTest_accuracy: 0.1704\n",
      "Iteration: 1116 \t Total Loss:640.10992 \tTest_accuracy: 0.1704\n",
      "Iteration: 1117 \t Total Loss:650.59180 \tTest_accuracy: 0.1704\n",
      "Iteration: 1118 \t Total Loss:637.22833 \tTest_accuracy: 0.1704\n",
      "Iteration: 1119 \t Total Loss:646.60254 \tTest_accuracy: 0.1704\n",
      "Iteration: 1120 \t Total Loss:644.17072 \tTest_accuracy: 0.1704\n",
      "Iteration: 1121 \t Total Loss:646.75458 \tTest_accuracy: 0.1704\n",
      "Iteration: 1122 \t Total Loss:647.58124 \tTest_accuracy: 0.1704\n",
      "Iteration: 1123 \t Total Loss:637.85742 \tTest_accuracy: 0.1704\n",
      "Iteration: 1124 \t Total Loss:659.41931 \tTest_accuracy: 0.1704\n",
      "Iteration: 1125 \t Total Loss:649.04071 \tTest_accuracy: 0.1704\n",
      "Iteration: 1126 \t Total Loss:644.70685 \tTest_accuracy: 0.1704\n",
      "Iteration: 1127 \t Total Loss:642.36530 \tTest_accuracy: 0.1704\n",
      "Iteration: 1128 \t Total Loss:633.29559 \tTest_accuracy: 0.1704\n",
      "Iteration: 1129 \t Total Loss:650.68689 \tTest_accuracy: 0.1704\n",
      "Iteration: 1130 \t Total Loss:636.48181 \tTest_accuracy: 0.1704\n",
      "Iteration: 1131 \t Total Loss:658.67914 \tTest_accuracy: 0.1704\n",
      "Iteration: 1132 \t Total Loss:640.94653 \tTest_accuracy: 0.1704\n",
      "Iteration: 1133 \t Total Loss:645.62994 \tTest_accuracy: 0.1704\n",
      "Iteration: 1134 \t Total Loss:649.38702 \tTest_accuracy: 0.1704\n",
      "Iteration: 1135 \t Total Loss:638.49420 \tTest_accuracy: 0.1704\n",
      "Iteration: 1136 \t Total Loss:640.24408 \tTest_accuracy: 0.1704\n",
      "Iteration: 1137 \t Total Loss:638.54889 \tTest_accuracy: 0.1704\n",
      "Iteration: 1138 \t Total Loss:633.96606 \tTest_accuracy: 0.1704\n",
      "Iteration: 1139 \t Total Loss:648.95209 \tTest_accuracy: 0.1704\n",
      "Iteration: 1140 \t Total Loss:643.02533 \tTest_accuracy: 0.1704\n",
      "Iteration: 1141 \t Total Loss:657.42688 \tTest_accuracy: 0.1704\n",
      "Iteration: 1142 \t Total Loss:662.15198 \tTest_accuracy: 0.1704\n",
      "Iteration: 1143 \t Total Loss:638.54620 \tTest_accuracy: 0.1704\n",
      "Iteration: 1144 \t Total Loss:645.54437 \tTest_accuracy: 0.1704\n",
      "Iteration: 1145 \t Total Loss:635.54993 \tTest_accuracy: 0.1704\n",
      "Iteration: 1146 \t Total Loss:662.48706 \tTest_accuracy: 0.1704\n",
      "Iteration: 1147 \t Total Loss:636.19855 \tTest_accuracy: 0.1704\n",
      "Iteration: 1148 \t Total Loss:650.30725 \tTest_accuracy: 0.1704\n",
      "Iteration: 1149 \t Total Loss:651.74823 \tTest_accuracy: 0.1704\n",
      "Iteration: 1150 \t Total Loss:638.88483 \tTest_accuracy: 0.1704\n",
      "Iteration: 1151 \t Total Loss:645.56110 \tTest_accuracy: 0.1704\n",
      "Iteration: 1152 \t Total Loss:651.91205 \tTest_accuracy: 0.1704\n",
      "Iteration: 1153 \t Total Loss:635.10150 \tTest_accuracy: 0.1704\n",
      "Iteration: 1154 \t Total Loss:634.30945 \tTest_accuracy: 0.1704\n",
      "Iteration: 1155 \t Total Loss:642.38184 \tTest_accuracy: 0.1704\n",
      "Iteration: 1156 \t Total Loss:633.80469 \tTest_accuracy: 0.1704\n",
      "Iteration: 1157 \t Total Loss:640.39819 \tTest_accuracy: 0.1704\n",
      "Iteration: 1158 \t Total Loss:649.30646 \tTest_accuracy: 0.1704\n",
      "Iteration: 1159 \t Total Loss:636.19135 \tTest_accuracy: 0.1704\n",
      "Iteration: 1160 \t Total Loss:641.01923 \tTest_accuracy: 0.1704\n",
      "Iteration: 1161 \t Total Loss:638.61761 \tTest_accuracy: 0.1704\n",
      "Iteration: 1162 \t Total Loss:654.74005 \tTest_accuracy: 0.1704\n",
      "Iteration: 1163 \t Total Loss:651.95966 \tTest_accuracy: 0.1704\n",
      "Iteration: 1164 \t Total Loss:639.03333 \tTest_accuracy: 0.1704\n",
      "Iteration: 1165 \t Total Loss:646.25671 \tTest_accuracy: 0.1704\n",
      "Iteration: 1166 \t Total Loss:656.25311 \tTest_accuracy: 0.1704\n",
      "Iteration: 1167 \t Total Loss:642.81122 \tTest_accuracy: 0.1704\n",
      "Iteration: 1168 \t Total Loss:649.41101 \tTest_accuracy: 0.1704\n",
      "Iteration: 1169 \t Total Loss:652.38666 \tTest_accuracy: 0.1704\n",
      "Iteration: 1170 \t Total Loss:659.68481 \tTest_accuracy: 0.1704\n",
      "Iteration: 1171 \t Total Loss:662.35175 \tTest_accuracy: 0.1704\n",
      "Iteration: 1172 \t Total Loss:649.34399 \tTest_accuracy: 0.1704\n",
      "Iteration: 1173 \t Total Loss:646.83441 \tTest_accuracy: 0.1704\n",
      "Iteration: 1174 \t Total Loss:647.57617 \tTest_accuracy: 0.1704\n",
      "Iteration: 1175 \t Total Loss:641.54578 \tTest_accuracy: 0.1704\n",
      "Iteration: 1176 \t Total Loss:646.96387 \tTest_accuracy: 0.1704\n",
      "Iteration: 1177 \t Total Loss:644.41205 \tTest_accuracy: 0.1704\n",
      "Iteration: 1178 \t Total Loss:649.21417 \tTest_accuracy: 0.1704\n",
      "Iteration: 1179 \t Total Loss:647.04816 \tTest_accuracy: 0.1704\n",
      "Iteration: 1180 \t Total Loss:636.57501 \tTest_accuracy: 0.1704\n",
      "Iteration: 1181 \t Total Loss:636.15594 \tTest_accuracy: 0.1704\n",
      "Iteration: 1182 \t Total Loss:644.38458 \tTest_accuracy: 0.1704\n",
      "Iteration: 1183 \t Total Loss:654.78021 \tTest_accuracy: 0.1704\n",
      "Iteration: 1184 \t Total Loss:636.97247 \tTest_accuracy: 0.1704\n",
      "Iteration: 1185 \t Total Loss:650.86127 \tTest_accuracy: 0.1704\n",
      "Iteration: 1186 \t Total Loss:650.34192 \tTest_accuracy: 0.1704\n",
      "Iteration: 1187 \t Total Loss:640.17108 \tTest_accuracy: 0.1704\n",
      "Iteration: 1188 \t Total Loss:641.70758 \tTest_accuracy: 0.1704\n",
      "Iteration: 1189 \t Total Loss:647.93549 \tTest_accuracy: 0.1704\n",
      "Iteration: 1190 \t Total Loss:647.14130 \tTest_accuracy: 0.1704\n",
      "Iteration: 1191 \t Total Loss:650.88226 \tTest_accuracy: 0.1704\n",
      "Iteration: 1192 \t Total Loss:658.41943 \tTest_accuracy: 0.1704\n",
      "Iteration: 1193 \t Total Loss:648.35516 \tTest_accuracy: 0.1704\n",
      "Iteration: 1194 \t Total Loss:647.98602 \tTest_accuracy: 0.1704\n",
      "Iteration: 1195 \t Total Loss:642.15271 \tTest_accuracy: 0.1704\n",
      "Iteration: 1196 \t Total Loss:652.42603 \tTest_accuracy: 0.1704\n",
      "Iteration: 1197 \t Total Loss:662.57532 \tTest_accuracy: 0.1704\n",
      "Iteration: 1198 \t Total Loss:665.82172 \tTest_accuracy: 0.1704\n",
      "Iteration: 1199 \t Total Loss:642.95892 \tTest_accuracy: 0.1704\n",
      "Iteration: 1200 \t Total Loss:650.81561 \tTest_accuracy: 0.1704\n",
      "Iteration: 1201 \t Total Loss:652.59784 \tTest_accuracy: 0.1704\n",
      "Iteration: 1202 \t Total Loss:635.98816 \tTest_accuracy: 0.1704\n",
      "Iteration: 1203 \t Total Loss:637.81787 \tTest_accuracy: 0.1704\n",
      "Iteration: 1204 \t Total Loss:648.47577 \tTest_accuracy: 0.1704\n",
      "Iteration: 1205 \t Total Loss:638.62097 \tTest_accuracy: 0.1704\n",
      "Iteration: 1206 \t Total Loss:645.94598 \tTest_accuracy: 0.1704\n",
      "Iteration: 1207 \t Total Loss:638.40118 \tTest_accuracy: 0.1704\n",
      "Iteration: 1208 \t Total Loss:646.72955 \tTest_accuracy: 0.1704\n",
      "Iteration: 1209 \t Total Loss:651.41949 \tTest_accuracy: 0.1704\n",
      "Iteration: 1210 \t Total Loss:645.21747 \tTest_accuracy: 0.1704\n",
      "Iteration: 1211 \t Total Loss:652.49963 \tTest_accuracy: 0.1704\n",
      "Iteration: 1212 \t Total Loss:652.90955 \tTest_accuracy: 0.1704\n",
      "Iteration: 1213 \t Total Loss:650.40662 \tTest_accuracy: 0.1704\n",
      "Iteration: 1214 \t Total Loss:638.75452 \tTest_accuracy: 0.1704\n",
      "Iteration: 1215 \t Total Loss:645.90936 \tTest_accuracy: 0.1704\n",
      "Iteration: 1216 \t Total Loss:635.22040 \tTest_accuracy: 0.1704\n",
      "Iteration: 1217 \t Total Loss:630.84985 \tTest_accuracy: 0.1704\n",
      "Iteration: 1218 \t Total Loss:656.29260 \tTest_accuracy: 0.1704\n",
      "Iteration: 1219 \t Total Loss:647.37286 \tTest_accuracy: 0.1704\n",
      "Iteration: 1220 \t Total Loss:636.06903 \tTest_accuracy: 0.1704\n",
      "Iteration: 1221 \t Total Loss:643.17877 \tTest_accuracy: 0.1704\n",
      "Iteration: 1222 \t Total Loss:639.82477 \tTest_accuracy: 0.1704\n",
      "Iteration: 1223 \t Total Loss:654.26288 \tTest_accuracy: 0.1704\n",
      "Iteration: 1224 \t Total Loss:645.02252 \tTest_accuracy: 0.1704\n",
      "Iteration: 1225 \t Total Loss:645.60980 \tTest_accuracy: 0.1704\n",
      "Iteration: 1226 \t Total Loss:643.86377 \tTest_accuracy: 0.1704\n",
      "Iteration: 1227 \t Total Loss:649.86969 \tTest_accuracy: 0.1704\n",
      "Iteration: 1228 \t Total Loss:652.17169 \tTest_accuracy: 0.1704\n",
      "Iteration: 1229 \t Total Loss:640.70245 \tTest_accuracy: 0.1704\n",
      "Iteration: 1230 \t Total Loss:649.95978 \tTest_accuracy: 0.1704\n",
      "Iteration: 1231 \t Total Loss:656.69525 \tTest_accuracy: 0.1704\n",
      "Iteration: 1232 \t Total Loss:634.55103 \tTest_accuracy: 0.1704\n",
      "Iteration: 1233 \t Total Loss:650.83673 \tTest_accuracy: 0.1704\n",
      "Iteration: 1234 \t Total Loss:648.44354 \tTest_accuracy: 0.1704\n",
      "Iteration: 1235 \t Total Loss:639.34131 \tTest_accuracy: 0.1704\n",
      "Iteration: 1236 \t Total Loss:642.58807 \tTest_accuracy: 0.1704\n",
      "Iteration: 1237 \t Total Loss:633.26740 \tTest_accuracy: 0.1704\n",
      "Iteration: 1238 \t Total Loss:645.37341 \tTest_accuracy: 0.1704\n",
      "Iteration: 1239 \t Total Loss:641.59515 \tTest_accuracy: 0.1704\n",
      "Iteration: 1240 \t Total Loss:639.72803 \tTest_accuracy: 0.1704\n",
      "Iteration: 1241 \t Total Loss:636.62811 \tTest_accuracy: 0.1704\n",
      "Iteration: 1242 \t Total Loss:650.12415 \tTest_accuracy: 0.1704\n",
      "Iteration: 1243 \t Total Loss:659.65594 \tTest_accuracy: 0.1704\n",
      "Iteration: 1244 \t Total Loss:636.42328 \tTest_accuracy: 0.1704\n",
      "Iteration: 1245 \t Total Loss:653.49982 \tTest_accuracy: 0.1704\n",
      "Iteration: 1246 \t Total Loss:646.82501 \tTest_accuracy: 0.1704\n",
      "Iteration: 1247 \t Total Loss:643.66107 \tTest_accuracy: 0.1704\n",
      "Iteration: 1248 \t Total Loss:643.57538 \tTest_accuracy: 0.1704\n",
      "Iteration: 1249 \t Total Loss:660.39008 \tTest_accuracy: 0.1704\n",
      "Iteration: 1250 \t Total Loss:645.41791 \tTest_accuracy: 0.1704\n",
      "Iteration: 1251 \t Total Loss:648.29590 \tTest_accuracy: 0.1704\n",
      "Iteration: 1252 \t Total Loss:651.71777 \tTest_accuracy: 0.1704\n",
      "Iteration: 1253 \t Total Loss:643.12445 \tTest_accuracy: 0.1704\n",
      "Iteration: 1254 \t Total Loss:641.90558 \tTest_accuracy: 0.1704\n",
      "Iteration: 1255 \t Total Loss:659.49438 \tTest_accuracy: 0.1704\n",
      "Iteration: 1256 \t Total Loss:643.40533 \tTest_accuracy: 0.1704\n",
      "Iteration: 1257 \t Total Loss:648.06085 \tTest_accuracy: 0.1704\n",
      "Iteration: 1258 \t Total Loss:644.36383 \tTest_accuracy: 0.1704\n",
      "Iteration: 1259 \t Total Loss:638.18549 \tTest_accuracy: 0.1704\n",
      "Iteration: 1260 \t Total Loss:645.38165 \tTest_accuracy: 0.1704\n",
      "Iteration: 1261 \t Total Loss:646.92615 \tTest_accuracy: 0.1704\n",
      "Iteration: 1262 \t Total Loss:645.09021 \tTest_accuracy: 0.1704\n",
      "Iteration: 1263 \t Total Loss:635.07172 \tTest_accuracy: 0.1704\n",
      "Iteration: 1264 \t Total Loss:641.46802 \tTest_accuracy: 0.1704\n",
      "Iteration: 1265 \t Total Loss:647.44135 \tTest_accuracy: 0.1704\n",
      "Iteration: 1266 \t Total Loss:637.34308 \tTest_accuracy: 0.1704\n",
      "Iteration: 1267 \t Total Loss:651.34564 \tTest_accuracy: 0.1704\n",
      "Iteration: 1268 \t Total Loss:640.95087 \tTest_accuracy: 0.1704\n",
      "Iteration: 1269 \t Total Loss:649.61542 \tTest_accuracy: 0.1704\n",
      "Iteration: 1270 \t Total Loss:653.48212 \tTest_accuracy: 0.1704\n",
      "Iteration: 1271 \t Total Loss:647.51965 \tTest_accuracy: 0.1704\n",
      "Iteration: 1272 \t Total Loss:652.84711 \tTest_accuracy: 0.1704\n",
      "Iteration: 1273 \t Total Loss:636.07526 \tTest_accuracy: 0.1704\n",
      "Iteration: 1274 \t Total Loss:636.51123 \tTest_accuracy: 0.1704\n",
      "Iteration: 1275 \t Total Loss:643.83374 \tTest_accuracy: 0.1704\n",
      "Iteration: 1276 \t Total Loss:645.18036 \tTest_accuracy: 0.1704\n",
      "Iteration: 1277 \t Total Loss:640.19598 \tTest_accuracy: 0.1704\n",
      "Iteration: 1278 \t Total Loss:654.08771 \tTest_accuracy: 0.1704\n",
      "Iteration: 1279 \t Total Loss:648.45972 \tTest_accuracy: 0.1704\n",
      "Iteration: 1280 \t Total Loss:635.60236 \tTest_accuracy: 0.1704\n",
      "Iteration: 1281 \t Total Loss:656.03381 \tTest_accuracy: 0.1704\n",
      "Iteration: 1282 \t Total Loss:651.44006 \tTest_accuracy: 0.1704\n",
      "Iteration: 1283 \t Total Loss:636.93976 \tTest_accuracy: 0.1704\n",
      "Iteration: 1284 \t Total Loss:653.88574 \tTest_accuracy: 0.1704\n",
      "Iteration: 1285 \t Total Loss:638.94904 \tTest_accuracy: 0.1704\n",
      "Iteration: 1286 \t Total Loss:656.81104 \tTest_accuracy: 0.1704\n",
      "Iteration: 1287 \t Total Loss:639.35992 \tTest_accuracy: 0.1704\n",
      "Iteration: 1288 \t Total Loss:642.59650 \tTest_accuracy: 0.1704\n",
      "Iteration: 1289 \t Total Loss:633.12860 \tTest_accuracy: 0.1704\n",
      "Iteration: 1290 \t Total Loss:658.36206 \tTest_accuracy: 0.1704\n",
      "Iteration: 1291 \t Total Loss:641.38275 \tTest_accuracy: 0.1704\n",
      "Iteration: 1292 \t Total Loss:651.65588 \tTest_accuracy: 0.1704\n",
      "Iteration: 1293 \t Total Loss:640.75592 \tTest_accuracy: 0.1704\n",
      "Iteration: 1294 \t Total Loss:646.42657 \tTest_accuracy: 0.1704\n",
      "Iteration: 1295 \t Total Loss:661.24542 \tTest_accuracy: 0.1704\n",
      "Iteration: 1296 \t Total Loss:645.36945 \tTest_accuracy: 0.1704\n",
      "Iteration: 1297 \t Total Loss:656.85663 \tTest_accuracy: 0.1704\n",
      "Iteration: 1298 \t Total Loss:645.36780 \tTest_accuracy: 0.1704\n",
      "Iteration: 1299 \t Total Loss:648.87952 \tTest_accuracy: 0.1704\n",
      "Iteration: 1300 \t Total Loss:643.29431 \tTest_accuracy: 0.1704\n",
      "Iteration: 1301 \t Total Loss:633.40881 \tTest_accuracy: 0.1704\n",
      "Iteration: 1302 \t Total Loss:636.11328 \tTest_accuracy: 0.1704\n",
      "Iteration: 1303 \t Total Loss:656.89850 \tTest_accuracy: 0.1704\n",
      "Iteration: 1304 \t Total Loss:650.91620 \tTest_accuracy: 0.1704\n",
      "Iteration: 1305 \t Total Loss:658.15082 \tTest_accuracy: 0.1704\n",
      "Iteration: 1306 \t Total Loss:637.14838 \tTest_accuracy: 0.1704\n",
      "Iteration: 1307 \t Total Loss:646.95367 \tTest_accuracy: 0.1704\n",
      "Iteration: 1308 \t Total Loss:637.17175 \tTest_accuracy: 0.1704\n",
      "Iteration: 1309 \t Total Loss:654.93781 \tTest_accuracy: 0.1704\n",
      "Iteration: 1310 \t Total Loss:647.32874 \tTest_accuracy: 0.1704\n",
      "Iteration: 1311 \t Total Loss:650.19598 \tTest_accuracy: 0.1704\n",
      "Iteration: 1312 \t Total Loss:651.10864 \tTest_accuracy: 0.1704\n",
      "Iteration: 1313 \t Total Loss:643.93860 \tTest_accuracy: 0.1704\n",
      "Iteration: 1314 \t Total Loss:645.71283 \tTest_accuracy: 0.1704\n",
      "Iteration: 1315 \t Total Loss:660.07355 \tTest_accuracy: 0.1704\n",
      "Iteration: 1316 \t Total Loss:641.38794 \tTest_accuracy: 0.1704\n",
      "Iteration: 1317 \t Total Loss:644.60284 \tTest_accuracy: 0.1704\n",
      "Iteration: 1318 \t Total Loss:660.93597 \tTest_accuracy: 0.1704\n",
      "Iteration: 1319 \t Total Loss:637.84589 \tTest_accuracy: 0.1704\n",
      "Iteration: 1320 \t Total Loss:635.47601 \tTest_accuracy: 0.1704\n",
      "Iteration: 1321 \t Total Loss:647.06158 \tTest_accuracy: 0.1704\n",
      "Iteration: 1322 \t Total Loss:646.73651 \tTest_accuracy: 0.1704\n",
      "Iteration: 1323 \t Total Loss:646.63007 \tTest_accuracy: 0.1704\n",
      "Iteration: 1324 \t Total Loss:656.12653 \tTest_accuracy: 0.1704\n",
      "Iteration: 1325 \t Total Loss:650.03571 \tTest_accuracy: 0.1704\n",
      "Iteration: 1326 \t Total Loss:644.04913 \tTest_accuracy: 0.1704\n",
      "Iteration: 1327 \t Total Loss:649.99542 \tTest_accuracy: 0.1704\n",
      "Iteration: 1328 \t Total Loss:662.95404 \tTest_accuracy: 0.1704\n",
      "Iteration: 1329 \t Total Loss:654.32562 \tTest_accuracy: 0.1704\n",
      "Iteration: 1330 \t Total Loss:646.76215 \tTest_accuracy: 0.1704\n",
      "Iteration: 1331 \t Total Loss:636.84430 \tTest_accuracy: 0.1704\n",
      "Iteration: 1332 \t Total Loss:638.79108 \tTest_accuracy: 0.1704\n",
      "Iteration: 1333 \t Total Loss:639.41882 \tTest_accuracy: 0.1704\n",
      "Iteration: 1334 \t Total Loss:651.88818 \tTest_accuracy: 0.1704\n",
      "Iteration: 1335 \t Total Loss:634.16907 \tTest_accuracy: 0.1704\n",
      "Iteration: 1336 \t Total Loss:643.05322 \tTest_accuracy: 0.1704\n",
      "Iteration: 1337 \t Total Loss:639.40790 \tTest_accuracy: 0.1704\n",
      "Iteration: 1338 \t Total Loss:643.64777 \tTest_accuracy: 0.1704\n",
      "Iteration: 1339 \t Total Loss:640.95062 \tTest_accuracy: 0.1704\n",
      "Iteration: 1340 \t Total Loss:639.00891 \tTest_accuracy: 0.1704\n",
      "Iteration: 1341 \t Total Loss:645.76337 \tTest_accuracy: 0.1704\n",
      "Iteration: 1342 \t Total Loss:633.19281 \tTest_accuracy: 0.1704\n",
      "Iteration: 1343 \t Total Loss:638.97150 \tTest_accuracy: 0.1704\n",
      "Iteration: 1344 \t Total Loss:649.25330 \tTest_accuracy: 0.1704\n",
      "Iteration: 1345 \t Total Loss:648.41284 \tTest_accuracy: 0.1704\n",
      "Iteration: 1346 \t Total Loss:638.86420 \tTest_accuracy: 0.1704\n",
      "Iteration: 1347 \t Total Loss:638.99475 \tTest_accuracy: 0.1704\n",
      "Iteration: 1348 \t Total Loss:657.04254 \tTest_accuracy: 0.1704\n",
      "Iteration: 1349 \t Total Loss:637.11969 \tTest_accuracy: 0.1704\n",
      "Iteration: 1350 \t Total Loss:646.59662 \tTest_accuracy: 0.1704\n",
      "Iteration: 1351 \t Total Loss:643.62933 \tTest_accuracy: 0.1704\n",
      "Iteration: 1352 \t Total Loss:640.44873 \tTest_accuracy: 0.1704\n",
      "Iteration: 1353 \t Total Loss:639.91791 \tTest_accuracy: 0.1704\n",
      "Iteration: 1354 \t Total Loss:638.99335 \tTest_accuracy: 0.1704\n",
      "Iteration: 1355 \t Total Loss:634.37970 \tTest_accuracy: 0.1704\n",
      "Iteration: 1356 \t Total Loss:644.72546 \tTest_accuracy: 0.1704\n",
      "Iteration: 1357 \t Total Loss:645.95294 \tTest_accuracy: 0.1704\n",
      "Iteration: 1358 \t Total Loss:644.71173 \tTest_accuracy: 0.1704\n",
      "Iteration: 1359 \t Total Loss:637.85956 \tTest_accuracy: 0.1704\n",
      "Iteration: 1360 \t Total Loss:643.01099 \tTest_accuracy: 0.1704\n",
      "Iteration: 1361 \t Total Loss:639.60034 \tTest_accuracy: 0.1704\n",
      "Iteration: 1362 \t Total Loss:647.00824 \tTest_accuracy: 0.1704\n",
      "Iteration: 1363 \t Total Loss:662.48413 \tTest_accuracy: 0.1704\n",
      "Iteration: 1364 \t Total Loss:651.08136 \tTest_accuracy: 0.1704\n",
      "Iteration: 1365 \t Total Loss:645.24133 \tTest_accuracy: 0.1704\n",
      "Iteration: 1366 \t Total Loss:653.67297 \tTest_accuracy: 0.1704\n",
      "Iteration: 1367 \t Total Loss:637.21515 \tTest_accuracy: 0.1704\n",
      "Iteration: 1368 \t Total Loss:651.88873 \tTest_accuracy: 0.1704\n",
      "Iteration: 1369 \t Total Loss:648.78754 \tTest_accuracy: 0.1704\n",
      "Iteration: 1370 \t Total Loss:644.85736 \tTest_accuracy: 0.1704\n",
      "Iteration: 1371 \t Total Loss:641.86053 \tTest_accuracy: 0.1704\n",
      "Iteration: 1372 \t Total Loss:640.43427 \tTest_accuracy: 0.1704\n",
      "Iteration: 1373 \t Total Loss:655.33307 \tTest_accuracy: 0.1704\n",
      "Iteration: 1374 \t Total Loss:646.13885 \tTest_accuracy: 0.1704\n",
      "Iteration: 1375 \t Total Loss:644.80078 \tTest_accuracy: 0.1704\n",
      "Iteration: 1376 \t Total Loss:638.65125 \tTest_accuracy: 0.1704\n",
      "Iteration: 1377 \t Total Loss:654.67511 \tTest_accuracy: 0.1704\n",
      "Iteration: 1378 \t Total Loss:645.72955 \tTest_accuracy: 0.1704\n",
      "Iteration: 1379 \t Total Loss:648.19281 \tTest_accuracy: 0.1704\n",
      "Iteration: 1380 \t Total Loss:651.90466 \tTest_accuracy: 0.1704\n",
      "Iteration: 1381 \t Total Loss:648.40656 \tTest_accuracy: 0.1704\n",
      "Iteration: 1382 \t Total Loss:651.17279 \tTest_accuracy: 0.1704\n",
      "Iteration: 1383 \t Total Loss:653.05853 \tTest_accuracy: 0.1704\n",
      "Iteration: 1384 \t Total Loss:641.68048 \tTest_accuracy: 0.1704\n",
      "Iteration: 1385 \t Total Loss:658.28125 \tTest_accuracy: 0.1704\n",
      "Iteration: 1386 \t Total Loss:643.08502 \tTest_accuracy: 0.1704\n",
      "Iteration: 1387 \t Total Loss:662.01898 \tTest_accuracy: 0.1704\n",
      "Iteration: 1388 \t Total Loss:653.05658 \tTest_accuracy: 0.1704\n",
      "Iteration: 1389 \t Total Loss:649.02740 \tTest_accuracy: 0.1704\n",
      "Iteration: 1390 \t Total Loss:652.14545 \tTest_accuracy: 0.1704\n",
      "Iteration: 1391 \t Total Loss:653.34271 \tTest_accuracy: 0.1704\n",
      "Iteration: 1392 \t Total Loss:634.45093 \tTest_accuracy: 0.1704\n",
      "Iteration: 1393 \t Total Loss:645.69928 \tTest_accuracy: 0.1704\n",
      "Iteration: 1394 \t Total Loss:657.41510 \tTest_accuracy: 0.1704\n",
      "Iteration: 1395 \t Total Loss:656.97650 \tTest_accuracy: 0.1704\n",
      "Iteration: 1396 \t Total Loss:646.32605 \tTest_accuracy: 0.1704\n",
      "Iteration: 1397 \t Total Loss:640.99554 \tTest_accuracy: 0.1704\n",
      "Iteration: 1398 \t Total Loss:658.69434 \tTest_accuracy: 0.1704\n",
      "Iteration: 1399 \t Total Loss:650.25311 \tTest_accuracy: 0.1704\n",
      "Iteration: 1400 \t Total Loss:642.41046 \tTest_accuracy: 0.1704\n",
      "Iteration: 1401 \t Total Loss:650.39221 \tTest_accuracy: 0.1704\n",
      "Iteration: 1402 \t Total Loss:640.84491 \tTest_accuracy: 0.1704\n",
      "Iteration: 1403 \t Total Loss:634.70306 \tTest_accuracy: 0.1704\n",
      "Iteration: 1404 \t Total Loss:648.35980 \tTest_accuracy: 0.1704\n",
      "Iteration: 1405 \t Total Loss:649.55011 \tTest_accuracy: 0.1704\n",
      "Iteration: 1406 \t Total Loss:636.26410 \tTest_accuracy: 0.1704\n",
      "Iteration: 1407 \t Total Loss:641.10138 \tTest_accuracy: 0.1704\n",
      "Iteration: 1408 \t Total Loss:655.76019 \tTest_accuracy: 0.1704\n",
      "Iteration: 1409 \t Total Loss:652.80359 \tTest_accuracy: 0.1704\n",
      "Iteration: 1410 \t Total Loss:640.79535 \tTest_accuracy: 0.1704\n",
      "Iteration: 1411 \t Total Loss:644.74139 \tTest_accuracy: 0.1704\n",
      "Iteration: 1412 \t Total Loss:658.16449 \tTest_accuracy: 0.1704\n",
      "Iteration: 1413 \t Total Loss:654.53949 \tTest_accuracy: 0.1704\n",
      "Iteration: 1414 \t Total Loss:638.16016 \tTest_accuracy: 0.1704\n",
      "Iteration: 1415 \t Total Loss:649.16370 \tTest_accuracy: 0.1704\n",
      "Iteration: 1416 \t Total Loss:663.31647 \tTest_accuracy: 0.1704\n",
      "Iteration: 1417 \t Total Loss:648.54382 \tTest_accuracy: 0.1704\n",
      "Iteration: 1418 \t Total Loss:650.00171 \tTest_accuracy: 0.1704\n",
      "Iteration: 1419 \t Total Loss:645.00897 \tTest_accuracy: 0.1704\n",
      "Iteration: 1420 \t Total Loss:646.76752 \tTest_accuracy: 0.1704\n",
      "Iteration: 1421 \t Total Loss:641.15131 \tTest_accuracy: 0.1704\n",
      "Iteration: 1422 \t Total Loss:643.93011 \tTest_accuracy: 0.1704\n",
      "Iteration: 1423 \t Total Loss:645.51465 \tTest_accuracy: 0.1704\n",
      "Iteration: 1424 \t Total Loss:650.49854 \tTest_accuracy: 0.1704\n",
      "Iteration: 1425 \t Total Loss:646.41687 \tTest_accuracy: 0.1704\n",
      "Iteration: 1426 \t Total Loss:636.82483 \tTest_accuracy: 0.1704\n",
      "Iteration: 1427 \t Total Loss:640.96423 \tTest_accuracy: 0.1704\n",
      "Iteration: 1428 \t Total Loss:661.20306 \tTest_accuracy: 0.1704\n",
      "Iteration: 1429 \t Total Loss:639.98962 \tTest_accuracy: 0.1704\n",
      "Iteration: 1430 \t Total Loss:655.90454 \tTest_accuracy: 0.1704\n",
      "Iteration: 1431 \t Total Loss:633.87360 \tTest_accuracy: 0.1704\n",
      "Iteration: 1432 \t Total Loss:646.34576 \tTest_accuracy: 0.1704\n",
      "Iteration: 1433 \t Total Loss:640.89752 \tTest_accuracy: 0.1704\n",
      "Iteration: 1434 \t Total Loss:643.72241 \tTest_accuracy: 0.1704\n",
      "Iteration: 1435 \t Total Loss:647.06793 \tTest_accuracy: 0.1704\n",
      "Iteration: 1436 \t Total Loss:644.23761 \tTest_accuracy: 0.1704\n",
      "Iteration: 1437 \t Total Loss:635.89893 \tTest_accuracy: 0.1704\n",
      "Iteration: 1438 \t Total Loss:643.90845 \tTest_accuracy: 0.1704\n",
      "Iteration: 1439 \t Total Loss:658.40741 \tTest_accuracy: 0.1704\n",
      "Iteration: 1440 \t Total Loss:639.91998 \tTest_accuracy: 0.1704\n",
      "Iteration: 1441 \t Total Loss:645.46185 \tTest_accuracy: 0.1704\n",
      "Iteration: 1442 \t Total Loss:650.52643 \tTest_accuracy: 0.1704\n",
      "Iteration: 1443 \t Total Loss:653.21338 \tTest_accuracy: 0.1704\n",
      "Iteration: 1444 \t Total Loss:634.53333 \tTest_accuracy: 0.1704\n",
      "Iteration: 1445 \t Total Loss:640.26984 \tTest_accuracy: 0.1704\n",
      "Iteration: 1446 \t Total Loss:656.26355 \tTest_accuracy: 0.1704\n",
      "Iteration: 1447 \t Total Loss:648.91400 \tTest_accuracy: 0.1704\n",
      "Iteration: 1448 \t Total Loss:633.14270 \tTest_accuracy: 0.1704\n",
      "Iteration: 1449 \t Total Loss:653.63593 \tTest_accuracy: 0.1704\n",
      "Iteration: 1450 \t Total Loss:651.45233 \tTest_accuracy: 0.1704\n",
      "Iteration: 1451 \t Total Loss:641.71338 \tTest_accuracy: 0.1704\n",
      "Iteration: 1452 \t Total Loss:643.12286 \tTest_accuracy: 0.1704\n",
      "Iteration: 1453 \t Total Loss:649.68433 \tTest_accuracy: 0.1704\n",
      "Iteration: 1454 \t Total Loss:643.76270 \tTest_accuracy: 0.1704\n",
      "Iteration: 1455 \t Total Loss:643.14264 \tTest_accuracy: 0.1704\n",
      "Iteration: 1456 \t Total Loss:655.91010 \tTest_accuracy: 0.1704\n",
      "Iteration: 1457 \t Total Loss:637.79529 \tTest_accuracy: 0.1704\n",
      "Iteration: 1458 \t Total Loss:649.84259 \tTest_accuracy: 0.1704\n",
      "Iteration: 1459 \t Total Loss:645.48096 \tTest_accuracy: 0.1704\n",
      "Iteration: 1460 \t Total Loss:643.05042 \tTest_accuracy: 0.1704\n",
      "Iteration: 1461 \t Total Loss:644.20416 \tTest_accuracy: 0.1704\n",
      "Iteration: 1462 \t Total Loss:649.44147 \tTest_accuracy: 0.1704\n",
      "Iteration: 1463 \t Total Loss:641.79645 \tTest_accuracy: 0.1704\n",
      "Iteration: 1464 \t Total Loss:635.98114 \tTest_accuracy: 0.1704\n",
      "Iteration: 1465 \t Total Loss:642.80792 \tTest_accuracy: 0.1704\n",
      "Iteration: 1466 \t Total Loss:637.13885 \tTest_accuracy: 0.1704\n",
      "Iteration: 1467 \t Total Loss:642.45703 \tTest_accuracy: 0.1704\n",
      "Iteration: 1468 \t Total Loss:648.64703 \tTest_accuracy: 0.1704\n",
      "Iteration: 1469 \t Total Loss:651.71106 \tTest_accuracy: 0.1704\n",
      "Iteration: 1470 \t Total Loss:637.47461 \tTest_accuracy: 0.1704\n",
      "Iteration: 1471 \t Total Loss:653.66595 \tTest_accuracy: 0.1704\n",
      "Iteration: 1472 \t Total Loss:644.25848 \tTest_accuracy: 0.1704\n",
      "Iteration: 1473 \t Total Loss:646.20007 \tTest_accuracy: 0.1704\n",
      "Iteration: 1474 \t Total Loss:645.84747 \tTest_accuracy: 0.1704\n",
      "Iteration: 1475 \t Total Loss:645.09302 \tTest_accuracy: 0.1704\n",
      "Iteration: 1476 \t Total Loss:645.81403 \tTest_accuracy: 0.1704\n",
      "Iteration: 1477 \t Total Loss:642.49921 \tTest_accuracy: 0.1704\n",
      "Iteration: 1478 \t Total Loss:644.72821 \tTest_accuracy: 0.1704\n",
      "Iteration: 1479 \t Total Loss:655.56750 \tTest_accuracy: 0.1704\n",
      "Iteration: 1480 \t Total Loss:656.68671 \tTest_accuracy: 0.1704\n",
      "Iteration: 1481 \t Total Loss:635.78442 \tTest_accuracy: 0.1704\n",
      "Iteration: 1482 \t Total Loss:654.36835 \tTest_accuracy: 0.1704\n",
      "Iteration: 1483 \t Total Loss:640.84808 \tTest_accuracy: 0.1704\n",
      "Iteration: 1484 \t Total Loss:636.31702 \tTest_accuracy: 0.1704\n",
      "Iteration: 1485 \t Total Loss:658.04657 \tTest_accuracy: 0.1704\n",
      "Iteration: 1486 \t Total Loss:636.55768 \tTest_accuracy: 0.1704\n",
      "Iteration: 1487 \t Total Loss:639.97711 \tTest_accuracy: 0.1704\n",
      "Iteration: 1488 \t Total Loss:647.69513 \tTest_accuracy: 0.1704\n",
      "Iteration: 1489 \t Total Loss:643.22186 \tTest_accuracy: 0.1704\n",
      "Iteration: 1490 \t Total Loss:653.23682 \tTest_accuracy: 0.1704\n",
      "Iteration: 1491 \t Total Loss:645.26453 \tTest_accuracy: 0.1704\n",
      "Iteration: 1492 \t Total Loss:650.52972 \tTest_accuracy: 0.1704\n",
      "Iteration: 1493 \t Total Loss:640.56268 \tTest_accuracy: 0.1704\n",
      "Iteration: 1494 \t Total Loss:643.83600 \tTest_accuracy: 0.1704\n",
      "Iteration: 1495 \t Total Loss:653.20032 \tTest_accuracy: 0.1704\n",
      "Iteration: 1496 \t Total Loss:641.74603 \tTest_accuracy: 0.1704\n",
      "Iteration: 1497 \t Total Loss:643.08569 \tTest_accuracy: 0.1704\n",
      "Iteration: 1498 \t Total Loss:644.16437 \tTest_accuracy: 0.1704\n",
      "Iteration: 1499 \t Total Loss:663.84094 \tTest_accuracy: 0.1704\n",
      "Iteration: 1500 \t Total Loss:649.44543 \tTest_accuracy: 0.1704\n",
      "Iteration: 1501 \t Total Loss:636.68658 \tTest_accuracy: 0.1704\n",
      "Iteration: 1502 \t Total Loss:648.12488 \tTest_accuracy: 0.1704\n",
      "Iteration: 1503 \t Total Loss:649.53192 \tTest_accuracy: 0.1704\n",
      "Iteration: 1504 \t Total Loss:637.46503 \tTest_accuracy: 0.1704\n",
      "Iteration: 1505 \t Total Loss:654.40411 \tTest_accuracy: 0.1704\n",
      "Iteration: 1506 \t Total Loss:649.11877 \tTest_accuracy: 0.1704\n",
      "Iteration: 1507 \t Total Loss:642.70160 \tTest_accuracy: 0.1704\n",
      "Iteration: 1508 \t Total Loss:656.80487 \tTest_accuracy: 0.1704\n",
      "Iteration: 1509 \t Total Loss:655.54742 \tTest_accuracy: 0.1704\n",
      "Iteration: 1510 \t Total Loss:646.12958 \tTest_accuracy: 0.1704\n",
      "Iteration: 1511 \t Total Loss:636.89972 \tTest_accuracy: 0.1704\n",
      "Iteration: 1512 \t Total Loss:656.05560 \tTest_accuracy: 0.1704\n",
      "Iteration: 1513 \t Total Loss:643.66309 \tTest_accuracy: 0.1704\n",
      "Iteration: 1514 \t Total Loss:649.26947 \tTest_accuracy: 0.1704\n",
      "Iteration: 1515 \t Total Loss:651.84448 \tTest_accuracy: 0.1704\n",
      "Iteration: 1516 \t Total Loss:639.68250 \tTest_accuracy: 0.1704\n",
      "Iteration: 1517 \t Total Loss:643.51129 \tTest_accuracy: 0.1704\n",
      "Iteration: 1518 \t Total Loss:646.94318 \tTest_accuracy: 0.1704\n",
      "Iteration: 1519 \t Total Loss:645.63367 \tTest_accuracy: 0.1704\n",
      "Iteration: 1520 \t Total Loss:638.29413 \tTest_accuracy: 0.1704\n",
      "Iteration: 1521 \t Total Loss:653.61346 \tTest_accuracy: 0.1704\n",
      "Iteration: 1522 \t Total Loss:638.61151 \tTest_accuracy: 0.1704\n",
      "Iteration: 1523 \t Total Loss:644.29156 \tTest_accuracy: 0.1704\n",
      "Iteration: 1524 \t Total Loss:639.19446 \tTest_accuracy: 0.1704\n",
      "Iteration: 1525 \t Total Loss:649.02106 \tTest_accuracy: 0.1704\n",
      "Iteration: 1526 \t Total Loss:639.06964 \tTest_accuracy: 0.1704\n",
      "Iteration: 1527 \t Total Loss:644.81354 \tTest_accuracy: 0.1704\n",
      "Iteration: 1528 \t Total Loss:639.13531 \tTest_accuracy: 0.1704\n",
      "Iteration: 1529 \t Total Loss:644.98700 \tTest_accuracy: 0.1704\n",
      "Iteration: 1530 \t Total Loss:637.24982 \tTest_accuracy: 0.1704\n",
      "Iteration: 1531 \t Total Loss:637.02045 \tTest_accuracy: 0.1704\n",
      "Iteration: 1532 \t Total Loss:645.05200 \tTest_accuracy: 0.1704\n",
      "Iteration: 1533 \t Total Loss:649.83997 \tTest_accuracy: 0.1704\n",
      "Iteration: 1534 \t Total Loss:639.77606 \tTest_accuracy: 0.1704\n",
      "Iteration: 1535 \t Total Loss:651.79443 \tTest_accuracy: 0.1704\n",
      "Iteration: 1536 \t Total Loss:647.44177 \tTest_accuracy: 0.1704\n",
      "Iteration: 1537 \t Total Loss:638.69806 \tTest_accuracy: 0.1704\n",
      "Iteration: 1538 \t Total Loss:650.91522 \tTest_accuracy: 0.1704\n",
      "Iteration: 1539 \t Total Loss:652.64642 \tTest_accuracy: 0.1704\n",
      "Iteration: 1540 \t Total Loss:651.73767 \tTest_accuracy: 0.1704\n",
      "Iteration: 1541 \t Total Loss:635.52563 \tTest_accuracy: 0.1704\n",
      "Iteration: 1542 \t Total Loss:644.45990 \tTest_accuracy: 0.1704\n",
      "Iteration: 1543 \t Total Loss:653.67999 \tTest_accuracy: 0.1704\n",
      "Iteration: 1544 \t Total Loss:639.42395 \tTest_accuracy: 0.1704\n",
      "Iteration: 1545 \t Total Loss:653.34351 \tTest_accuracy: 0.1704\n",
      "Iteration: 1546 \t Total Loss:645.16077 \tTest_accuracy: 0.1704\n",
      "Iteration: 1547 \t Total Loss:643.42340 \tTest_accuracy: 0.1704\n",
      "Iteration: 1548 \t Total Loss:646.19086 \tTest_accuracy: 0.1704\n",
      "Iteration: 1549 \t Total Loss:635.81580 \tTest_accuracy: 0.1704\n",
      "Iteration: 1550 \t Total Loss:643.08148 \tTest_accuracy: 0.1704\n",
      "Iteration: 1551 \t Total Loss:645.98926 \tTest_accuracy: 0.1704\n",
      "Iteration: 1552 \t Total Loss:638.92133 \tTest_accuracy: 0.1704\n",
      "Iteration: 1553 \t Total Loss:649.16351 \tTest_accuracy: 0.1704\n",
      "Iteration: 1554 \t Total Loss:647.55219 \tTest_accuracy: 0.1704\n",
      "Iteration: 1555 \t Total Loss:651.81451 \tTest_accuracy: 0.1704\n",
      "Iteration: 1556 \t Total Loss:648.24506 \tTest_accuracy: 0.1704\n",
      "Iteration: 1557 \t Total Loss:648.57642 \tTest_accuracy: 0.1704\n",
      "Iteration: 1558 \t Total Loss:643.60168 \tTest_accuracy: 0.1704\n",
      "Iteration: 1559 \t Total Loss:648.91632 \tTest_accuracy: 0.1704\n",
      "Iteration: 1560 \t Total Loss:639.36786 \tTest_accuracy: 0.1704\n",
      "Iteration: 1561 \t Total Loss:651.70807 \tTest_accuracy: 0.1704\n",
      "Iteration: 1562 \t Total Loss:644.17249 \tTest_accuracy: 0.1704\n",
      "Iteration: 1563 \t Total Loss:658.19324 \tTest_accuracy: 0.1704\n",
      "Iteration: 1564 \t Total Loss:645.87885 \tTest_accuracy: 0.1704\n",
      "Iteration: 1565 \t Total Loss:653.89514 \tTest_accuracy: 0.1704\n",
      "Iteration: 1566 \t Total Loss:641.15253 \tTest_accuracy: 0.1704\n",
      "Iteration: 1567 \t Total Loss:639.29987 \tTest_accuracy: 0.1704\n",
      "Iteration: 1568 \t Total Loss:643.49243 \tTest_accuracy: 0.1704\n",
      "Iteration: 1569 \t Total Loss:651.06635 \tTest_accuracy: 0.1704\n",
      "Iteration: 1570 \t Total Loss:653.42877 \tTest_accuracy: 0.1704\n",
      "Iteration: 1571 \t Total Loss:638.45349 \tTest_accuracy: 0.1704\n",
      "Iteration: 1572 \t Total Loss:645.44110 \tTest_accuracy: 0.1704\n",
      "Iteration: 1573 \t Total Loss:655.10883 \tTest_accuracy: 0.1704\n",
      "Iteration: 1574 \t Total Loss:647.91193 \tTest_accuracy: 0.1704\n",
      "Iteration: 1575 \t Total Loss:636.06342 \tTest_accuracy: 0.1704\n",
      "Iteration: 1576 \t Total Loss:645.03033 \tTest_accuracy: 0.1704\n",
      "Iteration: 1577 \t Total Loss:641.08099 \tTest_accuracy: 0.1704\n",
      "Iteration: 1578 \t Total Loss:641.81915 \tTest_accuracy: 0.1704\n",
      "Iteration: 1579 \t Total Loss:648.52887 \tTest_accuracy: 0.1704\n",
      "Iteration: 1580 \t Total Loss:636.52972 \tTest_accuracy: 0.1704\n",
      "Iteration: 1581 \t Total Loss:640.51758 \tTest_accuracy: 0.1704\n",
      "Iteration: 1582 \t Total Loss:643.96155 \tTest_accuracy: 0.1704\n",
      "Iteration: 1583 \t Total Loss:643.77814 \tTest_accuracy: 0.1704\n",
      "Iteration: 1584 \t Total Loss:645.74384 \tTest_accuracy: 0.1704\n",
      "Iteration: 1585 \t Total Loss:642.92108 \tTest_accuracy: 0.1704\n",
      "Iteration: 1586 \t Total Loss:639.59961 \tTest_accuracy: 0.1704\n",
      "Iteration: 1587 \t Total Loss:639.08295 \tTest_accuracy: 0.1704\n",
      "Iteration: 1588 \t Total Loss:641.97357 \tTest_accuracy: 0.1704\n",
      "Iteration: 1589 \t Total Loss:648.04034 \tTest_accuracy: 0.1704\n",
      "Iteration: 1590 \t Total Loss:642.94989 \tTest_accuracy: 0.1704\n",
      "Iteration: 1591 \t Total Loss:644.28363 \tTest_accuracy: 0.1704\n",
      "Iteration: 1592 \t Total Loss:646.53473 \tTest_accuracy: 0.1704\n",
      "Iteration: 1593 \t Total Loss:638.09674 \tTest_accuracy: 0.1704\n",
      "Iteration: 1594 \t Total Loss:655.22034 \tTest_accuracy: 0.1704\n",
      "Iteration: 1595 \t Total Loss:648.42914 \tTest_accuracy: 0.1704\n",
      "Iteration: 1596 \t Total Loss:653.37561 \tTest_accuracy: 0.1704\n",
      "Iteration: 1597 \t Total Loss:648.70282 \tTest_accuracy: 0.1704\n",
      "Iteration: 1598 \t Total Loss:657.35419 \tTest_accuracy: 0.1704\n",
      "Iteration: 1599 \t Total Loss:658.35638 \tTest_accuracy: 0.1704\n",
      "Iteration: 1600 \t Total Loss:631.07135 \tTest_accuracy: 0.1704\n",
      "Iteration: 1601 \t Total Loss:642.85809 \tTest_accuracy: 0.1704\n",
      "Iteration: 1602 \t Total Loss:637.43109 \tTest_accuracy: 0.1704\n",
      "Iteration: 1603 \t Total Loss:658.25079 \tTest_accuracy: 0.1704\n",
      "Iteration: 1604 \t Total Loss:638.41699 \tTest_accuracy: 0.1704\n",
      "Iteration: 1605 \t Total Loss:634.27112 \tTest_accuracy: 0.1704\n",
      "Iteration: 1606 \t Total Loss:636.78204 \tTest_accuracy: 0.1704\n",
      "Iteration: 1607 \t Total Loss:649.10229 \tTest_accuracy: 0.1704\n",
      "Iteration: 1608 \t Total Loss:645.32007 \tTest_accuracy: 0.1704\n",
      "Iteration: 1609 \t Total Loss:637.73218 \tTest_accuracy: 0.1704\n",
      "Iteration: 1610 \t Total Loss:656.37445 \tTest_accuracy: 0.1704\n",
      "Iteration: 1611 \t Total Loss:647.72644 \tTest_accuracy: 0.1704\n",
      "Iteration: 1612 \t Total Loss:651.69476 \tTest_accuracy: 0.1704\n",
      "Iteration: 1613 \t Total Loss:642.08270 \tTest_accuracy: 0.1704\n",
      "Iteration: 1614 \t Total Loss:648.82880 \tTest_accuracy: 0.1704\n",
      "Iteration: 1615 \t Total Loss:650.64514 \tTest_accuracy: 0.1704\n",
      "Iteration: 1616 \t Total Loss:647.73456 \tTest_accuracy: 0.1704\n",
      "Iteration: 1617 \t Total Loss:655.23993 \tTest_accuracy: 0.1704\n",
      "Iteration: 1618 \t Total Loss:658.76575 \tTest_accuracy: 0.1704\n",
      "Iteration: 1619 \t Total Loss:648.24945 \tTest_accuracy: 0.1704\n",
      "Iteration: 1620 \t Total Loss:649.49316 \tTest_accuracy: 0.1704\n",
      "Iteration: 1621 \t Total Loss:641.61127 \tTest_accuracy: 0.1704\n",
      "Iteration: 1622 \t Total Loss:638.86194 \tTest_accuracy: 0.1704\n",
      "Iteration: 1623 \t Total Loss:661.79584 \tTest_accuracy: 0.1704\n",
      "Iteration: 1624 \t Total Loss:652.82397 \tTest_accuracy: 0.1704\n",
      "Iteration: 1625 \t Total Loss:642.84845 \tTest_accuracy: 0.1704\n",
      "Iteration: 1626 \t Total Loss:645.38397 \tTest_accuracy: 0.1704\n",
      "Iteration: 1627 \t Total Loss:650.41699 \tTest_accuracy: 0.1704\n",
      "Iteration: 1628 \t Total Loss:657.35284 \tTest_accuracy: 0.1704\n",
      "Iteration: 1629 \t Total Loss:648.88293 \tTest_accuracy: 0.1704\n",
      "Iteration: 1630 \t Total Loss:650.38385 \tTest_accuracy: 0.1704\n",
      "Iteration: 1631 \t Total Loss:643.89313 \tTest_accuracy: 0.1704\n",
      "Iteration: 1632 \t Total Loss:644.28192 \tTest_accuracy: 0.1704\n",
      "Iteration: 1633 \t Total Loss:639.96198 \tTest_accuracy: 0.1704\n",
      "Iteration: 1634 \t Total Loss:649.06158 \tTest_accuracy: 0.1704\n",
      "Iteration: 1635 \t Total Loss:652.68799 \tTest_accuracy: 0.1704\n",
      "Iteration: 1636 \t Total Loss:659.40338 \tTest_accuracy: 0.1704\n",
      "Iteration: 1637 \t Total Loss:641.83563 \tTest_accuracy: 0.1704\n",
      "Iteration: 1638 \t Total Loss:641.74817 \tTest_accuracy: 0.1704\n",
      "Iteration: 1639 \t Total Loss:639.70294 \tTest_accuracy: 0.1704\n",
      "Iteration: 1640 \t Total Loss:636.33160 \tTest_accuracy: 0.1704\n",
      "Iteration: 1641 \t Total Loss:651.24213 \tTest_accuracy: 0.1704\n",
      "Iteration: 1642 \t Total Loss:641.78650 \tTest_accuracy: 0.1704\n",
      "Iteration: 1643 \t Total Loss:649.30096 \tTest_accuracy: 0.1704\n",
      "Iteration: 1644 \t Total Loss:658.63116 \tTest_accuracy: 0.1704\n",
      "Iteration: 1645 \t Total Loss:636.16486 \tTest_accuracy: 0.1704\n",
      "Iteration: 1646 \t Total Loss:641.70050 \tTest_accuracy: 0.1704\n",
      "Iteration: 1647 \t Total Loss:639.44165 \tTest_accuracy: 0.1704\n",
      "Iteration: 1648 \t Total Loss:657.25354 \tTest_accuracy: 0.1704\n",
      "Iteration: 1649 \t Total Loss:654.90808 \tTest_accuracy: 0.1704\n",
      "Iteration: 1650 \t Total Loss:649.33093 \tTest_accuracy: 0.1704\n",
      "Iteration: 1651 \t Total Loss:652.17035 \tTest_accuracy: 0.1704\n",
      "Iteration: 1652 \t Total Loss:637.15863 \tTest_accuracy: 0.1704\n",
      "Iteration: 1653 \t Total Loss:642.57544 \tTest_accuracy: 0.1704\n",
      "Iteration: 1654 \t Total Loss:652.15900 \tTest_accuracy: 0.1704\n",
      "Iteration: 1655 \t Total Loss:653.48187 \tTest_accuracy: 0.1704\n",
      "Iteration: 1656 \t Total Loss:651.34344 \tTest_accuracy: 0.1704\n",
      "Iteration: 1657 \t Total Loss:634.00153 \tTest_accuracy: 0.1704\n",
      "Iteration: 1658 \t Total Loss:647.11230 \tTest_accuracy: 0.1704\n",
      "Iteration: 1659 \t Total Loss:645.08624 \tTest_accuracy: 0.1704\n",
      "Iteration: 1660 \t Total Loss:644.04376 \tTest_accuracy: 0.1704\n",
      "Iteration: 1661 \t Total Loss:643.82599 \tTest_accuracy: 0.1704\n",
      "Iteration: 1662 \t Total Loss:646.70795 \tTest_accuracy: 0.1704\n",
      "Iteration: 1663 \t Total Loss:651.14240 \tTest_accuracy: 0.1704\n",
      "Iteration: 1664 \t Total Loss:652.08636 \tTest_accuracy: 0.1704\n",
      "Iteration: 1665 \t Total Loss:643.84650 \tTest_accuracy: 0.1704\n",
      "Iteration: 1666 \t Total Loss:638.32501 \tTest_accuracy: 0.1704\n",
      "Iteration: 1667 \t Total Loss:641.89740 \tTest_accuracy: 0.1704\n",
      "Iteration: 1668 \t Total Loss:647.66498 \tTest_accuracy: 0.1704\n",
      "Iteration: 1669 \t Total Loss:637.84961 \tTest_accuracy: 0.1704\n",
      "Iteration: 1670 \t Total Loss:654.54688 \tTest_accuracy: 0.1704\n",
      "Iteration: 1671 \t Total Loss:649.11426 \tTest_accuracy: 0.1704\n",
      "Iteration: 1672 \t Total Loss:652.98578 \tTest_accuracy: 0.1704\n",
      "Iteration: 1673 \t Total Loss:645.01996 \tTest_accuracy: 0.1704\n",
      "Iteration: 1674 \t Total Loss:655.20758 \tTest_accuracy: 0.1704\n",
      "Iteration: 1675 \t Total Loss:648.86133 \tTest_accuracy: 0.1704\n",
      "Iteration: 1676 \t Total Loss:648.37653 \tTest_accuracy: 0.1704\n",
      "Iteration: 1677 \t Total Loss:642.67828 \tTest_accuracy: 0.1704\n",
      "Iteration: 1678 \t Total Loss:643.76105 \tTest_accuracy: 0.1704\n",
      "Iteration: 1679 \t Total Loss:645.79169 \tTest_accuracy: 0.1704\n",
      "Iteration: 1680 \t Total Loss:652.70123 \tTest_accuracy: 0.1704\n",
      "Iteration: 1681 \t Total Loss:644.52289 \tTest_accuracy: 0.1704\n",
      "Iteration: 1682 \t Total Loss:636.60980 \tTest_accuracy: 0.1704\n",
      "Iteration: 1683 \t Total Loss:640.63580 \tTest_accuracy: 0.1704\n",
      "Iteration: 1684 \t Total Loss:657.08246 \tTest_accuracy: 0.1704\n",
      "Iteration: 1685 \t Total Loss:641.39838 \tTest_accuracy: 0.1704\n",
      "Iteration: 1686 \t Total Loss:636.67438 \tTest_accuracy: 0.1704\n",
      "Iteration: 1687 \t Total Loss:657.04449 \tTest_accuracy: 0.1704\n",
      "Iteration: 1688 \t Total Loss:654.42743 \tTest_accuracy: 0.1704\n",
      "Iteration: 1689 \t Total Loss:644.94220 \tTest_accuracy: 0.1704\n",
      "Iteration: 1690 \t Total Loss:633.63605 \tTest_accuracy: 0.1704\n",
      "Iteration: 1691 \t Total Loss:664.18927 \tTest_accuracy: 0.1704\n",
      "Iteration: 1692 \t Total Loss:634.72565 \tTest_accuracy: 0.1704\n",
      "Iteration: 1693 \t Total Loss:644.98175 \tTest_accuracy: 0.1704\n",
      "Iteration: 1694 \t Total Loss:641.17535 \tTest_accuracy: 0.1704\n",
      "Iteration: 1695 \t Total Loss:641.56860 \tTest_accuracy: 0.1704\n",
      "Iteration: 1696 \t Total Loss:650.36829 \tTest_accuracy: 0.1704\n",
      "Iteration: 1697 \t Total Loss:644.45483 \tTest_accuracy: 0.1704\n",
      "Iteration: 1698 \t Total Loss:651.84564 \tTest_accuracy: 0.1704\n",
      "Iteration: 1699 \t Total Loss:654.52142 \tTest_accuracy: 0.1704\n",
      "Iteration: 1700 \t Total Loss:657.44452 \tTest_accuracy: 0.1704\n",
      "Iteration: 1701 \t Total Loss:636.51837 \tTest_accuracy: 0.1704\n",
      "Iteration: 1702 \t Total Loss:651.90656 \tTest_accuracy: 0.1704\n",
      "Iteration: 1703 \t Total Loss:654.27588 \tTest_accuracy: 0.1704\n",
      "Iteration: 1704 \t Total Loss:658.94806 \tTest_accuracy: 0.1704\n",
      "Iteration: 1705 \t Total Loss:636.64069 \tTest_accuracy: 0.1704\n",
      "Iteration: 1706 \t Total Loss:638.10205 \tTest_accuracy: 0.1704\n",
      "Iteration: 1707 \t Total Loss:662.27350 \tTest_accuracy: 0.1704\n",
      "Iteration: 1708 \t Total Loss:632.16217 \tTest_accuracy: 0.1704\n",
      "Iteration: 1709 \t Total Loss:649.01105 \tTest_accuracy: 0.1704\n",
      "Iteration: 1710 \t Total Loss:657.93488 \tTest_accuracy: 0.1704\n",
      "Iteration: 1711 \t Total Loss:660.10223 \tTest_accuracy: 0.1704\n",
      "Iteration: 1712 \t Total Loss:643.23663 \tTest_accuracy: 0.1704\n",
      "Iteration: 1713 \t Total Loss:643.80902 \tTest_accuracy: 0.1704\n",
      "Iteration: 1714 \t Total Loss:644.83215 \tTest_accuracy: 0.1704\n",
      "Iteration: 1715 \t Total Loss:659.65851 \tTest_accuracy: 0.1704\n",
      "Iteration: 1716 \t Total Loss:652.57294 \tTest_accuracy: 0.1704\n",
      "Iteration: 1717 \t Total Loss:638.56299 \tTest_accuracy: 0.1704\n",
      "Iteration: 1718 \t Total Loss:636.09290 \tTest_accuracy: 0.1704\n",
      "Iteration: 1719 \t Total Loss:650.95074 \tTest_accuracy: 0.1704\n",
      "Iteration: 1720 \t Total Loss:654.11292 \tTest_accuracy: 0.1704\n",
      "Iteration: 1721 \t Total Loss:638.04315 \tTest_accuracy: 0.1704\n",
      "Iteration: 1722 \t Total Loss:639.99969 \tTest_accuracy: 0.1704\n",
      "Iteration: 1723 \t Total Loss:642.95105 \tTest_accuracy: 0.1704\n",
      "Iteration: 1724 \t Total Loss:639.31537 \tTest_accuracy: 0.1704\n",
      "Iteration: 1725 \t Total Loss:648.95026 \tTest_accuracy: 0.1704\n",
      "Iteration: 1726 \t Total Loss:649.57410 \tTest_accuracy: 0.1704\n",
      "Iteration: 1727 \t Total Loss:641.72754 \tTest_accuracy: 0.1704\n",
      "Iteration: 1728 \t Total Loss:652.56354 \tTest_accuracy: 0.1704\n",
      "Iteration: 1729 \t Total Loss:649.33014 \tTest_accuracy: 0.1704\n",
      "Iteration: 1730 \t Total Loss:646.65240 \tTest_accuracy: 0.1704\n",
      "Iteration: 1731 \t Total Loss:641.42889 \tTest_accuracy: 0.1704\n",
      "Iteration: 1732 \t Total Loss:656.33801 \tTest_accuracy: 0.1704\n",
      "Iteration: 1733 \t Total Loss:652.59546 \tTest_accuracy: 0.1704\n",
      "Iteration: 1734 \t Total Loss:649.57471 \tTest_accuracy: 0.1704\n",
      "Iteration: 1735 \t Total Loss:651.27356 \tTest_accuracy: 0.1704\n",
      "Iteration: 1736 \t Total Loss:637.05701 \tTest_accuracy: 0.1704\n",
      "Iteration: 1737 \t Total Loss:656.41681 \tTest_accuracy: 0.1704\n",
      "Iteration: 1738 \t Total Loss:647.52820 \tTest_accuracy: 0.1704\n",
      "Iteration: 1739 \t Total Loss:637.26178 \tTest_accuracy: 0.1704\n",
      "Iteration: 1740 \t Total Loss:653.82190 \tTest_accuracy: 0.1704\n",
      "Iteration: 1741 \t Total Loss:646.82349 \tTest_accuracy: 0.1704\n",
      "Iteration: 1742 \t Total Loss:649.25958 \tTest_accuracy: 0.1704\n",
      "Iteration: 1743 \t Total Loss:635.85266 \tTest_accuracy: 0.1704\n",
      "Iteration: 1744 \t Total Loss:645.30206 \tTest_accuracy: 0.1704\n",
      "Iteration: 1745 \t Total Loss:639.09241 \tTest_accuracy: 0.1704\n",
      "Iteration: 1746 \t Total Loss:642.69635 \tTest_accuracy: 0.1704\n",
      "Iteration: 1747 \t Total Loss:643.16010 \tTest_accuracy: 0.1704\n",
      "Iteration: 1748 \t Total Loss:640.62592 \tTest_accuracy: 0.1704\n",
      "Iteration: 1749 \t Total Loss:647.37561 \tTest_accuracy: 0.1704\n",
      "Iteration: 1750 \t Total Loss:645.12274 \tTest_accuracy: 0.1704\n",
      "Iteration: 1751 \t Total Loss:654.95697 \tTest_accuracy: 0.1704\n",
      "Iteration: 1752 \t Total Loss:634.43158 \tTest_accuracy: 0.1704\n",
      "Iteration: 1753 \t Total Loss:638.10400 \tTest_accuracy: 0.1704\n",
      "Iteration: 1754 \t Total Loss:646.67487 \tTest_accuracy: 0.1704\n",
      "Iteration: 1755 \t Total Loss:648.61377 \tTest_accuracy: 0.1704\n",
      "Iteration: 1756 \t Total Loss:645.42987 \tTest_accuracy: 0.1704\n",
      "Iteration: 1757 \t Total Loss:646.00323 \tTest_accuracy: 0.1704\n",
      "Iteration: 1758 \t Total Loss:646.53387 \tTest_accuracy: 0.1704\n",
      "Iteration: 1759 \t Total Loss:640.66443 \tTest_accuracy: 0.1704\n",
      "Iteration: 1760 \t Total Loss:647.23004 \tTest_accuracy: 0.1704\n",
      "Iteration: 1761 \t Total Loss:643.70538 \tTest_accuracy: 0.1704\n",
      "Iteration: 1762 \t Total Loss:640.18170 \tTest_accuracy: 0.1704\n",
      "Iteration: 1763 \t Total Loss:636.02673 \tTest_accuracy: 0.1704\n",
      "Iteration: 1764 \t Total Loss:641.15613 \tTest_accuracy: 0.1704\n",
      "Iteration: 1765 \t Total Loss:661.68994 \tTest_accuracy: 0.1704\n",
      "Iteration: 1766 \t Total Loss:644.85040 \tTest_accuracy: 0.1704\n",
      "Iteration: 1767 \t Total Loss:652.80450 \tTest_accuracy: 0.1704\n",
      "Iteration: 1768 \t Total Loss:637.19104 \tTest_accuracy: 0.1704\n",
      "Iteration: 1769 \t Total Loss:643.06067 \tTest_accuracy: 0.1704\n",
      "Iteration: 1770 \t Total Loss:640.92853 \tTest_accuracy: 0.1704\n",
      "Iteration: 1771 \t Total Loss:639.83112 \tTest_accuracy: 0.1704\n",
      "Iteration: 1772 \t Total Loss:645.95050 \tTest_accuracy: 0.1704\n",
      "Iteration: 1773 \t Total Loss:647.29596 \tTest_accuracy: 0.1704\n",
      "Iteration: 1774 \t Total Loss:641.98541 \tTest_accuracy: 0.1704\n",
      "Iteration: 1775 \t Total Loss:654.31207 \tTest_accuracy: 0.1704\n",
      "Iteration: 1776 \t Total Loss:656.69049 \tTest_accuracy: 0.1704\n",
      "Iteration: 1777 \t Total Loss:636.40009 \tTest_accuracy: 0.1704\n",
      "Iteration: 1778 \t Total Loss:656.37061 \tTest_accuracy: 0.1704\n",
      "Iteration: 1779 \t Total Loss:638.06818 \tTest_accuracy: 0.1704\n",
      "Iteration: 1780 \t Total Loss:655.38733 \tTest_accuracy: 0.1704\n",
      "Iteration: 1781 \t Total Loss:652.22595 \tTest_accuracy: 0.1704\n",
      "Iteration: 1782 \t Total Loss:646.53223 \tTest_accuracy: 0.1704\n",
      "Iteration: 1783 \t Total Loss:648.74994 \tTest_accuracy: 0.1704\n",
      "Iteration: 1784 \t Total Loss:645.54333 \tTest_accuracy: 0.1704\n",
      "Iteration: 1785 \t Total Loss:636.15100 \tTest_accuracy: 0.1704\n",
      "Iteration: 1786 \t Total Loss:644.32568 \tTest_accuracy: 0.1704\n",
      "Iteration: 1787 \t Total Loss:648.79773 \tTest_accuracy: 0.1704\n",
      "Iteration: 1788 \t Total Loss:648.10577 \tTest_accuracy: 0.1704\n",
      "Iteration: 1789 \t Total Loss:643.63855 \tTest_accuracy: 0.1704\n",
      "Iteration: 1790 \t Total Loss:651.60394 \tTest_accuracy: 0.1704\n",
      "Iteration: 1791 \t Total Loss:638.47064 \tTest_accuracy: 0.1704\n",
      "Iteration: 1792 \t Total Loss:642.59906 \tTest_accuracy: 0.1704\n",
      "Iteration: 1793 \t Total Loss:635.80029 \tTest_accuracy: 0.1704\n",
      "Iteration: 1794 \t Total Loss:654.62384 \tTest_accuracy: 0.1704\n",
      "Iteration: 1795 \t Total Loss:632.47101 \tTest_accuracy: 0.1704\n",
      "Iteration: 1796 \t Total Loss:642.84222 \tTest_accuracy: 0.1704\n",
      "Iteration: 1797 \t Total Loss:646.64886 \tTest_accuracy: 0.1704\n",
      "Iteration: 1798 \t Total Loss:651.79987 \tTest_accuracy: 0.1704\n",
      "Iteration: 1799 \t Total Loss:657.80835 \tTest_accuracy: 0.1704\n",
      "Iteration: 1800 \t Total Loss:643.78381 \tTest_accuracy: 0.1704\n",
      "Iteration: 1801 \t Total Loss:661.00238 \tTest_accuracy: 0.1704\n",
      "Iteration: 1802 \t Total Loss:650.00354 \tTest_accuracy: 0.1704\n",
      "Iteration: 1803 \t Total Loss:644.56781 \tTest_accuracy: 0.1704\n",
      "Iteration: 1804 \t Total Loss:634.32507 \tTest_accuracy: 0.1704\n",
      "Iteration: 1805 \t Total Loss:652.79535 \tTest_accuracy: 0.1704\n",
      "Iteration: 1806 \t Total Loss:642.31940 \tTest_accuracy: 0.1704\n",
      "Iteration: 1807 \t Total Loss:641.11066 \tTest_accuracy: 0.1704\n",
      "Iteration: 1808 \t Total Loss:637.70428 \tTest_accuracy: 0.1704\n",
      "Iteration: 1809 \t Total Loss:640.52728 \tTest_accuracy: 0.1704\n",
      "Iteration: 1810 \t Total Loss:636.18915 \tTest_accuracy: 0.1704\n",
      "Iteration: 1811 \t Total Loss:636.08148 \tTest_accuracy: 0.1704\n",
      "Iteration: 1812 \t Total Loss:636.41302 \tTest_accuracy: 0.1704\n",
      "Iteration: 1813 \t Total Loss:647.06860 \tTest_accuracy: 0.1704\n",
      "Iteration: 1814 \t Total Loss:648.77283 \tTest_accuracy: 0.1704\n",
      "Iteration: 1815 \t Total Loss:659.11139 \tTest_accuracy: 0.1704\n",
      "Iteration: 1816 \t Total Loss:636.06628 \tTest_accuracy: 0.1704\n",
      "Iteration: 1817 \t Total Loss:655.21405 \tTest_accuracy: 0.1704\n",
      "Iteration: 1818 \t Total Loss:643.58472 \tTest_accuracy: 0.1704\n",
      "Iteration: 1819 \t Total Loss:639.77728 \tTest_accuracy: 0.1704\n",
      "Iteration: 1820 \t Total Loss:647.70386 \tTest_accuracy: 0.1704\n",
      "Iteration: 1821 \t Total Loss:636.06024 \tTest_accuracy: 0.1704\n",
      "Iteration: 1822 \t Total Loss:639.83075 \tTest_accuracy: 0.1704\n",
      "Iteration: 1823 \t Total Loss:640.72430 \tTest_accuracy: 0.1704\n",
      "Iteration: 1824 \t Total Loss:661.06750 \tTest_accuracy: 0.1704\n",
      "Iteration: 1825 \t Total Loss:656.80341 \tTest_accuracy: 0.1704\n",
      "Iteration: 1826 \t Total Loss:634.47888 \tTest_accuracy: 0.1704\n",
      "Iteration: 1827 \t Total Loss:656.80518 \tTest_accuracy: 0.1704\n",
      "Iteration: 1828 \t Total Loss:641.28290 \tTest_accuracy: 0.1704\n",
      "Iteration: 1829 \t Total Loss:640.01111 \tTest_accuracy: 0.1704\n",
      "Iteration: 1830 \t Total Loss:638.56403 \tTest_accuracy: 0.1704\n",
      "Iteration: 1831 \t Total Loss:652.94305 \tTest_accuracy: 0.1704\n",
      "Iteration: 1832 \t Total Loss:649.70239 \tTest_accuracy: 0.1704\n",
      "Iteration: 1833 \t Total Loss:644.12177 \tTest_accuracy: 0.1704\n",
      "Iteration: 1834 \t Total Loss:639.77631 \tTest_accuracy: 0.1704\n",
      "Iteration: 1835 \t Total Loss:652.91046 \tTest_accuracy: 0.1704\n",
      "Iteration: 1836 \t Total Loss:648.52386 \tTest_accuracy: 0.1704\n",
      "Iteration: 1837 \t Total Loss:648.23962 \tTest_accuracy: 0.1704\n",
      "Iteration: 1838 \t Total Loss:639.19177 \tTest_accuracy: 0.1704\n",
      "Iteration: 1839 \t Total Loss:639.12018 \tTest_accuracy: 0.1704\n",
      "Iteration: 1840 \t Total Loss:646.48688 \tTest_accuracy: 0.1704\n",
      "Iteration: 1841 \t Total Loss:646.63971 \tTest_accuracy: 0.1704\n",
      "Iteration: 1842 \t Total Loss:642.82953 \tTest_accuracy: 0.1704\n",
      "Iteration: 1843 \t Total Loss:648.31238 \tTest_accuracy: 0.1704\n",
      "Iteration: 1844 \t Total Loss:644.76202 \tTest_accuracy: 0.1704\n",
      "Iteration: 1845 \t Total Loss:641.00104 \tTest_accuracy: 0.1704\n",
      "Iteration: 1846 \t Total Loss:643.82135 \tTest_accuracy: 0.1704\n",
      "Iteration: 1847 \t Total Loss:653.55798 \tTest_accuracy: 0.1704\n",
      "Iteration: 1848 \t Total Loss:644.79877 \tTest_accuracy: 0.1704\n",
      "Iteration: 1849 \t Total Loss:638.58368 \tTest_accuracy: 0.1704\n",
      "Iteration: 1850 \t Total Loss:651.52863 \tTest_accuracy: 0.1704\n",
      "Iteration: 1851 \t Total Loss:640.18585 \tTest_accuracy: 0.1704\n",
      "Iteration: 1852 \t Total Loss:639.84418 \tTest_accuracy: 0.1704\n",
      "Iteration: 1853 \t Total Loss:639.20972 \tTest_accuracy: 0.1704\n",
      "Iteration: 1854 \t Total Loss:642.72168 \tTest_accuracy: 0.1704\n",
      "Iteration: 1855 \t Total Loss:653.42365 \tTest_accuracy: 0.1704\n",
      "Iteration: 1856 \t Total Loss:634.36908 \tTest_accuracy: 0.1704\n",
      "Iteration: 1857 \t Total Loss:654.63129 \tTest_accuracy: 0.1704\n",
      "Iteration: 1858 \t Total Loss:636.62018 \tTest_accuracy: 0.1704\n",
      "Iteration: 1859 \t Total Loss:644.05518 \tTest_accuracy: 0.1704\n",
      "Iteration: 1860 \t Total Loss:649.41705 \tTest_accuracy: 0.1704\n",
      "Iteration: 1861 \t Total Loss:644.40851 \tTest_accuracy: 0.1704\n",
      "Iteration: 1862 \t Total Loss:651.41937 \tTest_accuracy: 0.1704\n",
      "Iteration: 1863 \t Total Loss:649.53986 \tTest_accuracy: 0.1704\n",
      "Iteration: 1864 \t Total Loss:640.69269 \tTest_accuracy: 0.1704\n",
      "Iteration: 1865 \t Total Loss:641.02197 \tTest_accuracy: 0.1704\n",
      "Iteration: 1866 \t Total Loss:642.11285 \tTest_accuracy: 0.1704\n",
      "Iteration: 1867 \t Total Loss:637.99762 \tTest_accuracy: 0.1704\n",
      "Iteration: 1868 \t Total Loss:642.63501 \tTest_accuracy: 0.1704\n",
      "Iteration: 1869 \t Total Loss:648.71112 \tTest_accuracy: 0.1704\n",
      "Iteration: 1870 \t Total Loss:640.93164 \tTest_accuracy: 0.1704\n",
      "Iteration: 1871 \t Total Loss:630.61676 \tTest_accuracy: 0.1704\n",
      "Iteration: 1872 \t Total Loss:641.87323 \tTest_accuracy: 0.1704\n",
      "Iteration: 1873 \t Total Loss:648.33771 \tTest_accuracy: 0.1704\n",
      "Iteration: 1874 \t Total Loss:636.60883 \tTest_accuracy: 0.1704\n",
      "Iteration: 1875 \t Total Loss:645.80212 \tTest_accuracy: 0.1704\n",
      "Iteration: 1876 \t Total Loss:636.41278 \tTest_accuracy: 0.1704\n",
      "Iteration: 1877 \t Total Loss:648.84888 \tTest_accuracy: 0.1704\n",
      "Iteration: 1878 \t Total Loss:642.21393 \tTest_accuracy: 0.1704\n",
      "Iteration: 1879 \t Total Loss:651.18640 \tTest_accuracy: 0.1704\n",
      "Iteration: 1880 \t Total Loss:636.78864 \tTest_accuracy: 0.1704\n",
      "Iteration: 1881 \t Total Loss:647.65424 \tTest_accuracy: 0.1704\n",
      "Iteration: 1882 \t Total Loss:640.26715 \tTest_accuracy: 0.1704\n",
      "Iteration: 1883 \t Total Loss:633.47467 \tTest_accuracy: 0.1704\n",
      "Iteration: 1884 \t Total Loss:653.53241 \tTest_accuracy: 0.1704\n",
      "Iteration: 1885 \t Total Loss:639.99536 \tTest_accuracy: 0.1704\n",
      "Iteration: 1886 \t Total Loss:646.63745 \tTest_accuracy: 0.1704\n",
      "Iteration: 1887 \t Total Loss:636.20581 \tTest_accuracy: 0.1704\n",
      "Iteration: 1888 \t Total Loss:652.61908 \tTest_accuracy: 0.1704\n",
      "Iteration: 1889 \t Total Loss:649.59137 \tTest_accuracy: 0.1704\n",
      "Iteration: 1890 \t Total Loss:658.87335 \tTest_accuracy: 0.1704\n",
      "Iteration: 1891 \t Total Loss:639.52631 \tTest_accuracy: 0.1704\n",
      "Iteration: 1892 \t Total Loss:633.53192 \tTest_accuracy: 0.1704\n",
      "Iteration: 1893 \t Total Loss:648.35126 \tTest_accuracy: 0.1704\n",
      "Iteration: 1894 \t Total Loss:651.13641 \tTest_accuracy: 0.1704\n",
      "Iteration: 1895 \t Total Loss:649.57831 \tTest_accuracy: 0.1704\n",
      "Iteration: 1896 \t Total Loss:640.78864 \tTest_accuracy: 0.1704\n",
      "Iteration: 1897 \t Total Loss:637.35999 \tTest_accuracy: 0.1704\n",
      "Iteration: 1898 \t Total Loss:643.73834 \tTest_accuracy: 0.1704\n",
      "Iteration: 1899 \t Total Loss:646.49872 \tTest_accuracy: 0.1704\n",
      "Iteration: 1900 \t Total Loss:648.57245 \tTest_accuracy: 0.1704\n",
      "Iteration: 1901 \t Total Loss:647.11951 \tTest_accuracy: 0.1704\n",
      "Iteration: 1902 \t Total Loss:637.28223 \tTest_accuracy: 0.1704\n",
      "Iteration: 1903 \t Total Loss:659.88910 \tTest_accuracy: 0.1704\n",
      "Iteration: 1904 \t Total Loss:639.76825 \tTest_accuracy: 0.1704\n",
      "Iteration: 1905 \t Total Loss:639.69293 \tTest_accuracy: 0.1704\n",
      "Iteration: 1906 \t Total Loss:650.98114 \tTest_accuracy: 0.1704\n",
      "Iteration: 1907 \t Total Loss:639.16461 \tTest_accuracy: 0.1704\n",
      "Iteration: 1908 \t Total Loss:645.51929 \tTest_accuracy: 0.1704\n",
      "Iteration: 1909 \t Total Loss:651.87860 \tTest_accuracy: 0.1704\n",
      "Iteration: 1910 \t Total Loss:649.32208 \tTest_accuracy: 0.1704\n",
      "Iteration: 1911 \t Total Loss:648.38190 \tTest_accuracy: 0.1704\n",
      "Iteration: 1912 \t Total Loss:635.98383 \tTest_accuracy: 0.1704\n",
      "Iteration: 1913 \t Total Loss:644.26044 \tTest_accuracy: 0.1704\n",
      "Iteration: 1914 \t Total Loss:642.66589 \tTest_accuracy: 0.1704\n",
      "Iteration: 1915 \t Total Loss:641.54120 \tTest_accuracy: 0.1704\n",
      "Iteration: 1916 \t Total Loss:646.55103 \tTest_accuracy: 0.1704\n",
      "Iteration: 1917 \t Total Loss:640.77728 \tTest_accuracy: 0.1704\n",
      "Iteration: 1918 \t Total Loss:651.79431 \tTest_accuracy: 0.1704\n",
      "Iteration: 1919 \t Total Loss:661.42633 \tTest_accuracy: 0.1704\n",
      "Iteration: 1920 \t Total Loss:639.20142 \tTest_accuracy: 0.1704\n",
      "Iteration: 1921 \t Total Loss:642.22662 \tTest_accuracy: 0.1704\n",
      "Iteration: 1922 \t Total Loss:643.17645 \tTest_accuracy: 0.1704\n",
      "Iteration: 1923 \t Total Loss:646.77350 \tTest_accuracy: 0.1704\n",
      "Iteration: 1924 \t Total Loss:647.70734 \tTest_accuracy: 0.1704\n",
      "Iteration: 1925 \t Total Loss:645.22235 \tTest_accuracy: 0.1704\n",
      "Iteration: 1926 \t Total Loss:658.32422 \tTest_accuracy: 0.1704\n",
      "Iteration: 1927 \t Total Loss:655.29327 \tTest_accuracy: 0.1704\n",
      "Iteration: 1928 \t Total Loss:653.84442 \tTest_accuracy: 0.1704\n",
      "Iteration: 1929 \t Total Loss:638.67615 \tTest_accuracy: 0.1704\n",
      "Iteration: 1930 \t Total Loss:636.76288 \tTest_accuracy: 0.1704\n",
      "Iteration: 1931 \t Total Loss:641.73553 \tTest_accuracy: 0.1704\n",
      "Iteration: 1932 \t Total Loss:639.38812 \tTest_accuracy: 0.1704\n",
      "Iteration: 1933 \t Total Loss:653.01874 \tTest_accuracy: 0.1704\n",
      "Iteration: 1934 \t Total Loss:640.08929 \tTest_accuracy: 0.1704\n",
      "Iteration: 1935 \t Total Loss:664.29254 \tTest_accuracy: 0.1704\n",
      "Iteration: 1936 \t Total Loss:644.52802 \tTest_accuracy: 0.1704\n",
      "Iteration: 1937 \t Total Loss:647.25732 \tTest_accuracy: 0.1704\n",
      "Iteration: 1938 \t Total Loss:636.45972 \tTest_accuracy: 0.1704\n",
      "Iteration: 1939 \t Total Loss:645.15521 \tTest_accuracy: 0.1704\n",
      "Iteration: 1940 \t Total Loss:645.12585 \tTest_accuracy: 0.1704\n",
      "Iteration: 1941 \t Total Loss:641.96100 \tTest_accuracy: 0.1704\n",
      "Iteration: 1942 \t Total Loss:653.03754 \tTest_accuracy: 0.1704\n",
      "Iteration: 1943 \t Total Loss:637.55566 \tTest_accuracy: 0.1704\n",
      "Iteration: 1944 \t Total Loss:652.94928 \tTest_accuracy: 0.1704\n",
      "Iteration: 1945 \t Total Loss:645.33398 \tTest_accuracy: 0.1704\n",
      "Iteration: 1946 \t Total Loss:643.73254 \tTest_accuracy: 0.1704\n",
      "Iteration: 1947 \t Total Loss:646.05865 \tTest_accuracy: 0.1704\n",
      "Iteration: 1948 \t Total Loss:645.92627 \tTest_accuracy: 0.1704\n",
      "Iteration: 1949 \t Total Loss:648.96143 \tTest_accuracy: 0.1704\n",
      "Iteration: 1950 \t Total Loss:647.69830 \tTest_accuracy: 0.1704\n",
      "Iteration: 1951 \t Total Loss:635.23181 \tTest_accuracy: 0.1704\n",
      "Iteration: 1952 \t Total Loss:639.69226 \tTest_accuracy: 0.1704\n",
      "Iteration: 1953 \t Total Loss:638.85168 \tTest_accuracy: 0.1704\n",
      "Iteration: 1954 \t Total Loss:648.67780 \tTest_accuracy: 0.1704\n",
      "Iteration: 1955 \t Total Loss:637.82184 \tTest_accuracy: 0.1704\n",
      "Iteration: 1956 \t Total Loss:653.24780 \tTest_accuracy: 0.1704\n",
      "Iteration: 1957 \t Total Loss:655.54840 \tTest_accuracy: 0.1704\n",
      "Iteration: 1958 \t Total Loss:639.90741 \tTest_accuracy: 0.1704\n",
      "Iteration: 1959 \t Total Loss:654.63129 \tTest_accuracy: 0.1704\n",
      "Iteration: 1960 \t Total Loss:641.15179 \tTest_accuracy: 0.1704\n",
      "Iteration: 1961 \t Total Loss:651.99811 \tTest_accuracy: 0.1704\n",
      "Iteration: 1962 \t Total Loss:639.84430 \tTest_accuracy: 0.1704\n",
      "Iteration: 1963 \t Total Loss:643.63751 \tTest_accuracy: 0.1704\n",
      "Iteration: 1964 \t Total Loss:660.74872 \tTest_accuracy: 0.1704\n",
      "Iteration: 1965 \t Total Loss:641.54828 \tTest_accuracy: 0.1704\n",
      "Iteration: 1966 \t Total Loss:641.15802 \tTest_accuracy: 0.1704\n",
      "Iteration: 1967 \t Total Loss:648.52826 \tTest_accuracy: 0.1704\n",
      "Iteration: 1968 \t Total Loss:646.86145 \tTest_accuracy: 0.1704\n",
      "Iteration: 1969 \t Total Loss:653.10944 \tTest_accuracy: 0.1704\n",
      "Iteration: 1970 \t Total Loss:637.88440 \tTest_accuracy: 0.1704\n",
      "Iteration: 1971 \t Total Loss:661.05731 \tTest_accuracy: 0.1704\n",
      "Iteration: 1972 \t Total Loss:640.15778 \tTest_accuracy: 0.1704\n",
      "Iteration: 1973 \t Total Loss:636.09119 \tTest_accuracy: 0.1704\n",
      "Iteration: 1974 \t Total Loss:638.85052 \tTest_accuracy: 0.1704\n",
      "Iteration: 1975 \t Total Loss:643.40863 \tTest_accuracy: 0.1704\n",
      "Iteration: 1976 \t Total Loss:663.38104 \tTest_accuracy: 0.1704\n",
      "Iteration: 1977 \t Total Loss:655.04791 \tTest_accuracy: 0.1704\n",
      "Iteration: 1978 \t Total Loss:654.56696 \tTest_accuracy: 0.1704\n",
      "Iteration: 1979 \t Total Loss:658.23102 \tTest_accuracy: 0.1704\n",
      "Iteration: 1980 \t Total Loss:646.03448 \tTest_accuracy: 0.1704\n",
      "Iteration: 1981 \t Total Loss:644.44958 \tTest_accuracy: 0.1704\n",
      "Iteration: 1982 \t Total Loss:641.00128 \tTest_accuracy: 0.1704\n",
      "Iteration: 1983 \t Total Loss:639.51898 \tTest_accuracy: 0.1704\n",
      "Iteration: 1984 \t Total Loss:638.27301 \tTest_accuracy: 0.1704\n",
      "Iteration: 1985 \t Total Loss:633.92725 \tTest_accuracy: 0.1704\n",
      "Iteration: 1986 \t Total Loss:645.69525 \tTest_accuracy: 0.1704\n",
      "Iteration: 1987 \t Total Loss:645.99176 \tTest_accuracy: 0.1704\n",
      "Iteration: 1988 \t Total Loss:652.42236 \tTest_accuracy: 0.1704\n",
      "Iteration: 1989 \t Total Loss:636.61029 \tTest_accuracy: 0.1704\n",
      "Iteration: 1990 \t Total Loss:650.82159 \tTest_accuracy: 0.1704\n",
      "Iteration: 1991 \t Total Loss:650.94037 \tTest_accuracy: 0.1704\n",
      "Iteration: 1992 \t Total Loss:634.08398 \tTest_accuracy: 0.1704\n",
      "Iteration: 1993 \t Total Loss:643.64069 \tTest_accuracy: 0.1704\n",
      "Iteration: 1994 \t Total Loss:641.27112 \tTest_accuracy: 0.1704\n",
      "Iteration: 1995 \t Total Loss:658.10785 \tTest_accuracy: 0.1704\n",
      "Iteration: 1996 \t Total Loss:647.63971 \tTest_accuracy: 0.1704\n",
      "Iteration: 1997 \t Total Loss:645.01019 \tTest_accuracy: 0.1704\n",
      "Iteration: 1998 \t Total Loss:639.40253 \tTest_accuracy: 0.1704\n",
      "Iteration: 1999 \t Total Loss:649.33331 \tTest_accuracy: 0.1704\n",
      "Iteration: 2000 \t Total Loss:645.64301 \tTest_accuracy: 0.1704\n",
      "Iteration: 2001 \t Total Loss:659.05298 \tTest_accuracy: 0.1704\n",
      "Iteration: 2002 \t Total Loss:634.85217 \tTest_accuracy: 0.1704\n",
      "Iteration: 2003 \t Total Loss:647.29895 \tTest_accuracy: 0.1704\n",
      "Iteration: 2004 \t Total Loss:643.39545 \tTest_accuracy: 0.1704\n",
      "Iteration: 2005 \t Total Loss:638.45850 \tTest_accuracy: 0.1704\n",
      "Iteration: 2006 \t Total Loss:647.50342 \tTest_accuracy: 0.1704\n",
      "Iteration: 2007 \t Total Loss:650.46582 \tTest_accuracy: 0.1704\n",
      "Iteration: 2008 \t Total Loss:651.04559 \tTest_accuracy: 0.1704\n",
      "Iteration: 2009 \t Total Loss:631.84412 \tTest_accuracy: 0.1704\n",
      "Iteration: 2010 \t Total Loss:647.99371 \tTest_accuracy: 0.1704\n",
      "Iteration: 2011 \t Total Loss:633.97675 \tTest_accuracy: 0.1704\n",
      "Iteration: 2012 \t Total Loss:664.61456 \tTest_accuracy: 0.1704\n",
      "Iteration: 2013 \t Total Loss:644.25433 \tTest_accuracy: 0.1704\n",
      "Iteration: 2014 \t Total Loss:641.47040 \tTest_accuracy: 0.1704\n",
      "Iteration: 2015 \t Total Loss:659.57526 \tTest_accuracy: 0.1704\n",
      "Iteration: 2016 \t Total Loss:657.14941 \tTest_accuracy: 0.1704\n",
      "Iteration: 2017 \t Total Loss:646.34216 \tTest_accuracy: 0.1704\n",
      "Iteration: 2018 \t Total Loss:642.71979 \tTest_accuracy: 0.1704\n",
      "Iteration: 2019 \t Total Loss:638.05756 \tTest_accuracy: 0.1704\n",
      "Iteration: 2020 \t Total Loss:642.66956 \tTest_accuracy: 0.1704\n",
      "Iteration: 2021 \t Total Loss:640.50500 \tTest_accuracy: 0.1704\n",
      "Iteration: 2022 \t Total Loss:634.69397 \tTest_accuracy: 0.1704\n",
      "Iteration: 2023 \t Total Loss:641.17395 \tTest_accuracy: 0.1704\n",
      "Iteration: 2024 \t Total Loss:648.71344 \tTest_accuracy: 0.1704\n",
      "Iteration: 2025 \t Total Loss:649.81958 \tTest_accuracy: 0.1704\n",
      "Iteration: 2026 \t Total Loss:656.97406 \tTest_accuracy: 0.1704\n",
      "Iteration: 2027 \t Total Loss:659.83997 \tTest_accuracy: 0.1704\n",
      "Iteration: 2028 \t Total Loss:650.30292 \tTest_accuracy: 0.1704\n",
      "Iteration: 2029 \t Total Loss:644.36646 \tTest_accuracy: 0.1704\n",
      "Iteration: 2030 \t Total Loss:644.33392 \tTest_accuracy: 0.1704\n",
      "Iteration: 2031 \t Total Loss:647.69995 \tTest_accuracy: 0.1704\n",
      "Iteration: 2032 \t Total Loss:641.63812 \tTest_accuracy: 0.1704\n",
      "Iteration: 2033 \t Total Loss:649.04608 \tTest_accuracy: 0.1704\n",
      "Iteration: 2034 \t Total Loss:640.74713 \tTest_accuracy: 0.1704\n",
      "Iteration: 2035 \t Total Loss:650.40411 \tTest_accuracy: 0.1704\n",
      "Iteration: 2036 \t Total Loss:657.83984 \tTest_accuracy: 0.1704\n",
      "Iteration: 2037 \t Total Loss:645.61505 \tTest_accuracy: 0.1704\n",
      "Iteration: 2038 \t Total Loss:648.03998 \tTest_accuracy: 0.1704\n",
      "Iteration: 2039 \t Total Loss:638.21686 \tTest_accuracy: 0.1704\n",
      "Iteration: 2040 \t Total Loss:638.28113 \tTest_accuracy: 0.1704\n",
      "Iteration: 2041 \t Total Loss:637.77692 \tTest_accuracy: 0.1704\n",
      "Iteration: 2042 \t Total Loss:634.69110 \tTest_accuracy: 0.1704\n",
      "Iteration: 2043 \t Total Loss:644.74786 \tTest_accuracy: 0.1704\n",
      "Iteration: 2044 \t Total Loss:650.09357 \tTest_accuracy: 0.1704\n",
      "Iteration: 2045 \t Total Loss:649.70300 \tTest_accuracy: 0.1704\n",
      "Iteration: 2046 \t Total Loss:649.59052 \tTest_accuracy: 0.1704\n",
      "Iteration: 2047 \t Total Loss:646.44641 \tTest_accuracy: 0.1704\n",
      "Iteration: 2048 \t Total Loss:643.75629 \tTest_accuracy: 0.1704\n",
      "Iteration: 2049 \t Total Loss:648.06122 \tTest_accuracy: 0.1704\n",
      "Iteration: 2050 \t Total Loss:652.47437 \tTest_accuracy: 0.1704\n",
      "Iteration: 2051 \t Total Loss:653.83588 \tTest_accuracy: 0.1704\n",
      "Iteration: 2052 \t Total Loss:638.70148 \tTest_accuracy: 0.1704\n",
      "Iteration: 2053 \t Total Loss:639.19696 \tTest_accuracy: 0.1704\n",
      "Iteration: 2054 \t Total Loss:642.57843 \tTest_accuracy: 0.1704\n",
      "Iteration: 2055 \t Total Loss:641.65698 \tTest_accuracy: 0.1704\n",
      "Iteration: 2056 \t Total Loss:641.32977 \tTest_accuracy: 0.1704\n",
      "Iteration: 2057 \t Total Loss:644.30096 \tTest_accuracy: 0.1704\n",
      "Iteration: 2058 \t Total Loss:642.89868 \tTest_accuracy: 0.1704\n",
      "Iteration: 2059 \t Total Loss:647.95959 \tTest_accuracy: 0.1704\n",
      "Iteration: 2060 \t Total Loss:641.01068 \tTest_accuracy: 0.1704\n",
      "Iteration: 2061 \t Total Loss:644.47321 \tTest_accuracy: 0.1704\n",
      "Iteration: 2062 \t Total Loss:647.85602 \tTest_accuracy: 0.1704\n",
      "Iteration: 2063 \t Total Loss:645.42499 \tTest_accuracy: 0.1704\n",
      "Iteration: 2064 \t Total Loss:639.44580 \tTest_accuracy: 0.1704\n",
      "Iteration: 2065 \t Total Loss:654.58881 \tTest_accuracy: 0.1704\n",
      "Iteration: 2066 \t Total Loss:634.03082 \tTest_accuracy: 0.1704\n",
      "Iteration: 2067 \t Total Loss:639.90363 \tTest_accuracy: 0.1704\n",
      "Iteration: 2068 \t Total Loss:643.75128 \tTest_accuracy: 0.1704\n",
      "Iteration: 2069 \t Total Loss:648.30249 \tTest_accuracy: 0.1704\n",
      "Iteration: 2070 \t Total Loss:656.76221 \tTest_accuracy: 0.1704\n",
      "Iteration: 2071 \t Total Loss:654.36072 \tTest_accuracy: 0.1704\n",
      "Iteration: 2072 \t Total Loss:636.44757 \tTest_accuracy: 0.1704\n",
      "Iteration: 2073 \t Total Loss:638.52759 \tTest_accuracy: 0.1704\n",
      "Iteration: 2074 \t Total Loss:649.64539 \tTest_accuracy: 0.1704\n",
      "Iteration: 2075 \t Total Loss:650.46796 \tTest_accuracy: 0.1704\n",
      "Iteration: 2076 \t Total Loss:643.79639 \tTest_accuracy: 0.1704\n",
      "Iteration: 2077 \t Total Loss:647.11127 \tTest_accuracy: 0.1704\n",
      "Iteration: 2078 \t Total Loss:648.44580 \tTest_accuracy: 0.1704\n",
      "Iteration: 2079 \t Total Loss:639.42950 \tTest_accuracy: 0.1704\n",
      "Iteration: 2080 \t Total Loss:640.47400 \tTest_accuracy: 0.1704\n",
      "Iteration: 2081 \t Total Loss:642.07886 \tTest_accuracy: 0.1704\n",
      "Iteration: 2082 \t Total Loss:648.77905 \tTest_accuracy: 0.1704\n",
      "Iteration: 2083 \t Total Loss:662.20148 \tTest_accuracy: 0.1704\n",
      "Iteration: 2084 \t Total Loss:642.35590 \tTest_accuracy: 0.1704\n",
      "Iteration: 2085 \t Total Loss:641.23676 \tTest_accuracy: 0.1704\n",
      "Iteration: 2086 \t Total Loss:649.28436 \tTest_accuracy: 0.1704\n",
      "Iteration: 2087 \t Total Loss:644.74066 \tTest_accuracy: 0.1704\n",
      "Iteration: 2088 \t Total Loss:650.42548 \tTest_accuracy: 0.1704\n",
      "Iteration: 2089 \t Total Loss:640.07520 \tTest_accuracy: 0.1704\n",
      "Iteration: 2090 \t Total Loss:635.20007 \tTest_accuracy: 0.1704\n",
      "Iteration: 2091 \t Total Loss:650.55139 \tTest_accuracy: 0.1704\n",
      "Iteration: 2092 \t Total Loss:662.98444 \tTest_accuracy: 0.1704\n",
      "Iteration: 2093 \t Total Loss:641.31012 \tTest_accuracy: 0.1704\n",
      "Iteration: 2094 \t Total Loss:652.22186 \tTest_accuracy: 0.1704\n",
      "Iteration: 2095 \t Total Loss:640.22516 \tTest_accuracy: 0.1704\n",
      "Iteration: 2096 \t Total Loss:640.16211 \tTest_accuracy: 0.1704\n",
      "Iteration: 2097 \t Total Loss:636.11182 \tTest_accuracy: 0.1704\n",
      "Iteration: 2098 \t Total Loss:652.31946 \tTest_accuracy: 0.1704\n",
      "Iteration: 2099 \t Total Loss:651.63275 \tTest_accuracy: 0.1704\n",
      "Iteration: 2100 \t Total Loss:640.56293 \tTest_accuracy: 0.1704\n",
      "Iteration: 2101 \t Total Loss:635.05444 \tTest_accuracy: 0.1704\n",
      "Iteration: 2102 \t Total Loss:652.67261 \tTest_accuracy: 0.1704\n",
      "Iteration: 2103 \t Total Loss:638.20941 \tTest_accuracy: 0.1704\n",
      "Iteration: 2104 \t Total Loss:644.82324 \tTest_accuracy: 0.1704\n",
      "Iteration: 2105 \t Total Loss:640.38037 \tTest_accuracy: 0.1704\n",
      "Iteration: 2106 \t Total Loss:648.25891 \tTest_accuracy: 0.1704\n",
      "Iteration: 2107 \t Total Loss:644.39532 \tTest_accuracy: 0.1704\n",
      "Iteration: 2108 \t Total Loss:651.59717 \tTest_accuracy: 0.1704\n",
      "Iteration: 2109 \t Total Loss:640.97156 \tTest_accuracy: 0.1704\n",
      "Iteration: 2110 \t Total Loss:645.09412 \tTest_accuracy: 0.1704\n",
      "Iteration: 2111 \t Total Loss:647.53027 \tTest_accuracy: 0.1704\n",
      "Iteration: 2112 \t Total Loss:634.51965 \tTest_accuracy: 0.1704\n",
      "Iteration: 2113 \t Total Loss:649.44342 \tTest_accuracy: 0.1704\n",
      "Iteration: 2114 \t Total Loss:648.69788 \tTest_accuracy: 0.1704\n",
      "Iteration: 2115 \t Total Loss:654.90601 \tTest_accuracy: 0.1704\n",
      "Iteration: 2116 \t Total Loss:656.31372 \tTest_accuracy: 0.1704\n",
      "Iteration: 2117 \t Total Loss:649.04626 \tTest_accuracy: 0.1704\n",
      "Iteration: 2118 \t Total Loss:647.69287 \tTest_accuracy: 0.1704\n",
      "Iteration: 2119 \t Total Loss:643.22131 \tTest_accuracy: 0.1704\n",
      "Iteration: 2120 \t Total Loss:641.43604 \tTest_accuracy: 0.1704\n",
      "Iteration: 2121 \t Total Loss:648.11700 \tTest_accuracy: 0.1704\n",
      "Iteration: 2122 \t Total Loss:647.45624 \tTest_accuracy: 0.1704\n",
      "Iteration: 2123 \t Total Loss:648.29199 \tTest_accuracy: 0.1704\n",
      "Iteration: 2124 \t Total Loss:650.70105 \tTest_accuracy: 0.1704\n",
      "Iteration: 2125 \t Total Loss:640.70898 \tTest_accuracy: 0.1704\n",
      "Iteration: 2126 \t Total Loss:647.06323 \tTest_accuracy: 0.1704\n",
      "Iteration: 2127 \t Total Loss:658.53436 \tTest_accuracy: 0.1704\n",
      "Iteration: 2128 \t Total Loss:637.07892 \tTest_accuracy: 0.1704\n",
      "Iteration: 2129 \t Total Loss:652.28143 \tTest_accuracy: 0.1704\n",
      "Iteration: 2130 \t Total Loss:643.93311 \tTest_accuracy: 0.1704\n",
      "Iteration: 2131 \t Total Loss:651.61511 \tTest_accuracy: 0.1704\n",
      "Iteration: 2132 \t Total Loss:645.86176 \tTest_accuracy: 0.1704\n",
      "Iteration: 2133 \t Total Loss:651.88971 \tTest_accuracy: 0.1704\n",
      "Iteration: 2134 \t Total Loss:637.40790 \tTest_accuracy: 0.1704\n",
      "Iteration: 2135 \t Total Loss:637.17023 \tTest_accuracy: 0.1704\n",
      "Iteration: 2136 \t Total Loss:645.12018 \tTest_accuracy: 0.1704\n",
      "Iteration: 2137 \t Total Loss:647.07800 \tTest_accuracy: 0.1704\n",
      "Iteration: 2138 \t Total Loss:636.12146 \tTest_accuracy: 0.1704\n",
      "Iteration: 2139 \t Total Loss:645.64264 \tTest_accuracy: 0.1704\n",
      "Iteration: 2140 \t Total Loss:651.84485 \tTest_accuracy: 0.1704\n",
      "Iteration: 2141 \t Total Loss:645.28986 \tTest_accuracy: 0.1704\n",
      "Iteration: 2142 \t Total Loss:641.28625 \tTest_accuracy: 0.1704\n",
      "Iteration: 2143 \t Total Loss:646.21039 \tTest_accuracy: 0.1704\n",
      "Iteration: 2144 \t Total Loss:648.73816 \tTest_accuracy: 0.1704\n",
      "Iteration: 2145 \t Total Loss:637.78644 \tTest_accuracy: 0.1704\n",
      "Iteration: 2146 \t Total Loss:637.93695 \tTest_accuracy: 0.1704\n",
      "Iteration: 2147 \t Total Loss:633.40155 \tTest_accuracy: 0.1704\n",
      "Iteration: 2148 \t Total Loss:661.23621 \tTest_accuracy: 0.1704\n",
      "Iteration: 2149 \t Total Loss:649.64062 \tTest_accuracy: 0.1704\n",
      "Iteration: 2150 \t Total Loss:639.44855 \tTest_accuracy: 0.1704\n",
      "Iteration: 2151 \t Total Loss:657.40704 \tTest_accuracy: 0.1704\n",
      "Iteration: 2152 \t Total Loss:644.13995 \tTest_accuracy: 0.1704\n",
      "Iteration: 2153 \t Total Loss:652.28802 \tTest_accuracy: 0.1704\n",
      "Iteration: 2154 \t Total Loss:640.98389 \tTest_accuracy: 0.1704\n",
      "Iteration: 2155 \t Total Loss:660.30737 \tTest_accuracy: 0.1704\n",
      "Iteration: 2156 \t Total Loss:641.90424 \tTest_accuracy: 0.1704\n",
      "Iteration: 2157 \t Total Loss:650.24860 \tTest_accuracy: 0.1704\n",
      "Iteration: 2158 \t Total Loss:661.88434 \tTest_accuracy: 0.1704\n",
      "Iteration: 2159 \t Total Loss:655.49359 \tTest_accuracy: 0.1704\n",
      "Iteration: 2160 \t Total Loss:649.92645 \tTest_accuracy: 0.1704\n",
      "Iteration: 2161 \t Total Loss:642.65839 \tTest_accuracy: 0.1704\n",
      "Iteration: 2162 \t Total Loss:642.87457 \tTest_accuracy: 0.1704\n",
      "Iteration: 2163 \t Total Loss:642.28040 \tTest_accuracy: 0.1704\n",
      "Iteration: 2164 \t Total Loss:649.71661 \tTest_accuracy: 0.1704\n",
      "Iteration: 2165 \t Total Loss:650.21936 \tTest_accuracy: 0.1704\n",
      "Iteration: 2166 \t Total Loss:648.32001 \tTest_accuracy: 0.1704\n",
      "Iteration: 2167 \t Total Loss:645.44000 \tTest_accuracy: 0.1704\n",
      "Iteration: 2168 \t Total Loss:648.53265 \tTest_accuracy: 0.1704\n",
      "Iteration: 2169 \t Total Loss:639.96716 \tTest_accuracy: 0.1704\n",
      "Iteration: 2170 \t Total Loss:642.05170 \tTest_accuracy: 0.1704\n",
      "Iteration: 2171 \t Total Loss:639.73920 \tTest_accuracy: 0.1704\n",
      "Iteration: 2172 \t Total Loss:637.55804 \tTest_accuracy: 0.1704\n",
      "Iteration: 2173 \t Total Loss:650.60626 \tTest_accuracy: 0.1704\n",
      "Iteration: 2174 \t Total Loss:637.94855 \tTest_accuracy: 0.1704\n",
      "Iteration: 2175 \t Total Loss:661.10248 \tTest_accuracy: 0.1704\n",
      "Iteration: 2176 \t Total Loss:655.70575 \tTest_accuracy: 0.1704\n",
      "Iteration: 2177 \t Total Loss:649.27307 \tTest_accuracy: 0.1704\n",
      "Iteration: 2178 \t Total Loss:644.90253 \tTest_accuracy: 0.1704\n",
      "Iteration: 2179 \t Total Loss:646.33270 \tTest_accuracy: 0.1704\n",
      "Iteration: 2180 \t Total Loss:644.88867 \tTest_accuracy: 0.1704\n",
      "Iteration: 2181 \t Total Loss:652.58539 \tTest_accuracy: 0.1704\n",
      "Iteration: 2182 \t Total Loss:671.96051 \tTest_accuracy: 0.1704\n",
      "Iteration: 2183 \t Total Loss:648.60797 \tTest_accuracy: 0.1704\n",
      "Iteration: 2184 \t Total Loss:652.94464 \tTest_accuracy: 0.1704\n",
      "Iteration: 2185 \t Total Loss:645.87640 \tTest_accuracy: 0.1704\n",
      "Iteration: 2186 \t Total Loss:635.46515 \tTest_accuracy: 0.1704\n",
      "Iteration: 2187 \t Total Loss:643.06586 \tTest_accuracy: 0.1704\n",
      "Iteration: 2188 \t Total Loss:647.74591 \tTest_accuracy: 0.1704\n",
      "Iteration: 2189 \t Total Loss:651.37567 \tTest_accuracy: 0.1704\n",
      "Iteration: 2190 \t Total Loss:653.35175 \tTest_accuracy: 0.1704\n",
      "Iteration: 2191 \t Total Loss:642.73285 \tTest_accuracy: 0.1704\n",
      "Iteration: 2192 \t Total Loss:648.74036 \tTest_accuracy: 0.1704\n",
      "Iteration: 2193 \t Total Loss:638.46283 \tTest_accuracy: 0.1704\n",
      "Iteration: 2194 \t Total Loss:651.29425 \tTest_accuracy: 0.1704\n",
      "Iteration: 2195 \t Total Loss:642.16010 \tTest_accuracy: 0.1704\n",
      "Iteration: 2196 \t Total Loss:643.54474 \tTest_accuracy: 0.1704\n",
      "Iteration: 2197 \t Total Loss:645.55664 \tTest_accuracy: 0.1704\n",
      "Iteration: 2198 \t Total Loss:647.60162 \tTest_accuracy: 0.1704\n",
      "Iteration: 2199 \t Total Loss:650.60254 \tTest_accuracy: 0.1704\n",
      "Iteration: 2200 \t Total Loss:637.72852 \tTest_accuracy: 0.1704\n",
      "Iteration: 2201 \t Total Loss:644.32404 \tTest_accuracy: 0.1704\n",
      "Iteration: 2202 \t Total Loss:645.38141 \tTest_accuracy: 0.1704\n",
      "Iteration: 2203 \t Total Loss:636.58014 \tTest_accuracy: 0.1704\n",
      "Iteration: 2204 \t Total Loss:650.05609 \tTest_accuracy: 0.1704\n",
      "Iteration: 2205 \t Total Loss:647.77155 \tTest_accuracy: 0.1704\n",
      "Iteration: 2206 \t Total Loss:646.69830 \tTest_accuracy: 0.1704\n",
      "Iteration: 2207 \t Total Loss:643.62976 \tTest_accuracy: 0.1704\n",
      "Iteration: 2208 \t Total Loss:649.73047 \tTest_accuracy: 0.1704\n",
      "Iteration: 2209 \t Total Loss:645.27606 \tTest_accuracy: 0.1704\n",
      "Iteration: 2210 \t Total Loss:642.29315 \tTest_accuracy: 0.1704\n",
      "Iteration: 2211 \t Total Loss:645.83075 \tTest_accuracy: 0.1704\n",
      "Iteration: 2212 \t Total Loss:644.32886 \tTest_accuracy: 0.1704\n",
      "Iteration: 2213 \t Total Loss:653.03644 \tTest_accuracy: 0.1704\n",
      "Iteration: 2214 \t Total Loss:645.81744 \tTest_accuracy: 0.1704\n",
      "Iteration: 2215 \t Total Loss:644.74017 \tTest_accuracy: 0.1704\n",
      "Iteration: 2216 \t Total Loss:645.07324 \tTest_accuracy: 0.1704\n",
      "Iteration: 2217 \t Total Loss:642.15387 \tTest_accuracy: 0.1704\n",
      "Iteration: 2218 \t Total Loss:643.75519 \tTest_accuracy: 0.1704\n",
      "Iteration: 2219 \t Total Loss:651.45734 \tTest_accuracy: 0.1704\n",
      "Iteration: 2220 \t Total Loss:656.20685 \tTest_accuracy: 0.1704\n",
      "Iteration: 2221 \t Total Loss:649.45764 \tTest_accuracy: 0.1704\n",
      "Iteration: 2222 \t Total Loss:651.64954 \tTest_accuracy: 0.1704\n",
      "Iteration: 2223 \t Total Loss:653.97534 \tTest_accuracy: 0.1704\n",
      "Iteration: 2224 \t Total Loss:640.72723 \tTest_accuracy: 0.1704\n",
      "Iteration: 2225 \t Total Loss:634.70026 \tTest_accuracy: 0.1704\n",
      "Iteration: 2226 \t Total Loss:636.79193 \tTest_accuracy: 0.1704\n",
      "Iteration: 2227 \t Total Loss:647.57452 \tTest_accuracy: 0.1704\n",
      "Iteration: 2228 \t Total Loss:652.14923 \tTest_accuracy: 0.1704\n",
      "Iteration: 2229 \t Total Loss:650.69708 \tTest_accuracy: 0.1704\n",
      "Iteration: 2230 \t Total Loss:629.81232 \tTest_accuracy: 0.1704\n",
      "Iteration: 2231 \t Total Loss:642.68878 \tTest_accuracy: 0.1704\n",
      "Iteration: 2232 \t Total Loss:653.43732 \tTest_accuracy: 0.1704\n",
      "Iteration: 2233 \t Total Loss:648.24884 \tTest_accuracy: 0.1704\n",
      "Iteration: 2234 \t Total Loss:641.06787 \tTest_accuracy: 0.1704\n",
      "Iteration: 2235 \t Total Loss:652.99689 \tTest_accuracy: 0.1704\n",
      "Iteration: 2236 \t Total Loss:654.47766 \tTest_accuracy: 0.1704\n",
      "Iteration: 2237 \t Total Loss:648.07251 \tTest_accuracy: 0.1704\n",
      "Iteration: 2238 \t Total Loss:641.21161 \tTest_accuracy: 0.1704\n",
      "Iteration: 2239 \t Total Loss:642.84515 \tTest_accuracy: 0.1704\n",
      "Iteration: 2240 \t Total Loss:656.54022 \tTest_accuracy: 0.1704\n",
      "Iteration: 2241 \t Total Loss:641.68188 \tTest_accuracy: 0.1704\n",
      "Iteration: 2242 \t Total Loss:634.27472 \tTest_accuracy: 0.1704\n",
      "Iteration: 2243 \t Total Loss:633.21100 \tTest_accuracy: 0.1704\n",
      "Iteration: 2244 \t Total Loss:635.63708 \tTest_accuracy: 0.1704\n",
      "Iteration: 2245 \t Total Loss:648.58588 \tTest_accuracy: 0.1704\n",
      "Iteration: 2246 \t Total Loss:641.66364 \tTest_accuracy: 0.1704\n",
      "Iteration: 2247 \t Total Loss:665.27649 \tTest_accuracy: 0.1704\n",
      "Iteration: 2248 \t Total Loss:655.83752 \tTest_accuracy: 0.1704\n",
      "Iteration: 2249 \t Total Loss:654.93512 \tTest_accuracy: 0.1704\n",
      "Iteration: 2250 \t Total Loss:642.75690 \tTest_accuracy: 0.1704\n",
      "Iteration: 2251 \t Total Loss:647.39777 \tTest_accuracy: 0.1704\n",
      "Iteration: 2252 \t Total Loss:663.49481 \tTest_accuracy: 0.1704\n",
      "Iteration: 2253 \t Total Loss:660.67670 \tTest_accuracy: 0.1704\n",
      "Iteration: 2254 \t Total Loss:647.28198 \tTest_accuracy: 0.1704\n",
      "Iteration: 2255 \t Total Loss:643.41699 \tTest_accuracy: 0.1704\n",
      "Iteration: 2256 \t Total Loss:651.39545 \tTest_accuracy: 0.1704\n",
      "Iteration: 2257 \t Total Loss:642.34619 \tTest_accuracy: 0.1704\n",
      "Iteration: 2258 \t Total Loss:636.01349 \tTest_accuracy: 0.1704\n",
      "Iteration: 2259 \t Total Loss:643.00598 \tTest_accuracy: 0.1704\n",
      "Iteration: 2260 \t Total Loss:653.83246 \tTest_accuracy: 0.1704\n",
      "Iteration: 2261 \t Total Loss:643.08063 \tTest_accuracy: 0.1704\n",
      "Iteration: 2262 \t Total Loss:651.00140 \tTest_accuracy: 0.1704\n",
      "Iteration: 2263 \t Total Loss:637.75909 \tTest_accuracy: 0.1704\n",
      "Iteration: 2264 \t Total Loss:645.69342 \tTest_accuracy: 0.1704\n",
      "Iteration: 2265 \t Total Loss:644.72595 \tTest_accuracy: 0.1704\n",
      "Iteration: 2266 \t Total Loss:650.37476 \tTest_accuracy: 0.1704\n",
      "Iteration: 2267 \t Total Loss:643.46967 \tTest_accuracy: 0.1704\n",
      "Iteration: 2268 \t Total Loss:633.29877 \tTest_accuracy: 0.1704\n",
      "Iteration: 2269 \t Total Loss:640.21423 \tTest_accuracy: 0.1704\n",
      "Iteration: 2270 \t Total Loss:646.09302 \tTest_accuracy: 0.1704\n",
      "Iteration: 2271 \t Total Loss:650.38342 \tTest_accuracy: 0.1704\n",
      "Iteration: 2272 \t Total Loss:634.00616 \tTest_accuracy: 0.1704\n",
      "Iteration: 2273 \t Total Loss:647.61224 \tTest_accuracy: 0.1704\n",
      "Iteration: 2274 \t Total Loss:644.34125 \tTest_accuracy: 0.1704\n",
      "Iteration: 2275 \t Total Loss:646.79047 \tTest_accuracy: 0.1704\n",
      "Iteration: 2276 \t Total Loss:652.71625 \tTest_accuracy: 0.1704\n",
      "Iteration: 2277 \t Total Loss:642.74512 \tTest_accuracy: 0.1704\n",
      "Iteration: 2278 \t Total Loss:637.29828 \tTest_accuracy: 0.1704\n",
      "Iteration: 2279 \t Total Loss:645.18988 \tTest_accuracy: 0.1704\n",
      "Iteration: 2280 \t Total Loss:642.30048 \tTest_accuracy: 0.1704\n",
      "Iteration: 2281 \t Total Loss:645.91718 \tTest_accuracy: 0.1704\n",
      "Iteration: 2282 \t Total Loss:637.76752 \tTest_accuracy: 0.1704\n",
      "Iteration: 2283 \t Total Loss:658.68292 \tTest_accuracy: 0.1704\n",
      "Iteration: 2284 \t Total Loss:639.19006 \tTest_accuracy: 0.1704\n",
      "Iteration: 2285 \t Total Loss:649.22394 \tTest_accuracy: 0.1704\n",
      "Iteration: 2286 \t Total Loss:646.06464 \tTest_accuracy: 0.1704\n",
      "Iteration: 2287 \t Total Loss:650.50940 \tTest_accuracy: 0.1704\n",
      "Iteration: 2288 \t Total Loss:641.83447 \tTest_accuracy: 0.1704\n",
      "Iteration: 2289 \t Total Loss:646.48047 \tTest_accuracy: 0.1704\n",
      "Iteration: 2290 \t Total Loss:644.07007 \tTest_accuracy: 0.1704\n",
      "Iteration: 2291 \t Total Loss:655.14410 \tTest_accuracy: 0.1704\n",
      "Iteration: 2292 \t Total Loss:632.70819 \tTest_accuracy: 0.1704\n",
      "Iteration: 2293 \t Total Loss:653.60626 \tTest_accuracy: 0.1704\n",
      "Iteration: 2294 \t Total Loss:646.28033 \tTest_accuracy: 0.1704\n",
      "Iteration: 2295 \t Total Loss:649.71185 \tTest_accuracy: 0.1704\n",
      "Iteration: 2296 \t Total Loss:651.36444 \tTest_accuracy: 0.1704\n",
      "Iteration: 2297 \t Total Loss:651.10931 \tTest_accuracy: 0.1704\n",
      "Iteration: 2298 \t Total Loss:653.28900 \tTest_accuracy: 0.1704\n",
      "Iteration: 2299 \t Total Loss:634.89795 \tTest_accuracy: 0.1704\n",
      "Iteration: 2300 \t Total Loss:648.37775 \tTest_accuracy: 0.1704\n",
      "Iteration: 2301 \t Total Loss:641.59338 \tTest_accuracy: 0.1704\n",
      "Iteration: 2302 \t Total Loss:661.04010 \tTest_accuracy: 0.1704\n",
      "Iteration: 2303 \t Total Loss:656.59375 \tTest_accuracy: 0.1704\n",
      "Iteration: 2304 \t Total Loss:656.07703 \tTest_accuracy: 0.1704\n",
      "Iteration: 2305 \t Total Loss:655.26324 \tTest_accuracy: 0.1704\n",
      "Iteration: 2306 \t Total Loss:642.99420 \tTest_accuracy: 0.1704\n",
      "Iteration: 2307 \t Total Loss:650.64618 \tTest_accuracy: 0.1704\n",
      "Iteration: 2308 \t Total Loss:644.53015 \tTest_accuracy: 0.1704\n",
      "Iteration: 2309 \t Total Loss:645.75763 \tTest_accuracy: 0.1704\n",
      "Iteration: 2310 \t Total Loss:634.13684 \tTest_accuracy: 0.1704\n",
      "Iteration: 2311 \t Total Loss:644.63080 \tTest_accuracy: 0.1704\n",
      "Iteration: 2312 \t Total Loss:645.10699 \tTest_accuracy: 0.1704\n",
      "Iteration: 2313 \t Total Loss:649.67535 \tTest_accuracy: 0.1704\n",
      "Iteration: 2314 \t Total Loss:639.59027 \tTest_accuracy: 0.1704\n",
      "Iteration: 2315 \t Total Loss:669.37543 \tTest_accuracy: 0.1704\n",
      "Iteration: 2316 \t Total Loss:656.96143 \tTest_accuracy: 0.1704\n",
      "Iteration: 2317 \t Total Loss:647.44342 \tTest_accuracy: 0.1704\n",
      "Iteration: 2318 \t Total Loss:634.93109 \tTest_accuracy: 0.1704\n",
      "Iteration: 2319 \t Total Loss:650.86481 \tTest_accuracy: 0.1704\n",
      "Iteration: 2320 \t Total Loss:650.65765 \tTest_accuracy: 0.1704\n",
      "Iteration: 2321 \t Total Loss:648.10565 \tTest_accuracy: 0.1704\n",
      "Iteration: 2322 \t Total Loss:651.78412 \tTest_accuracy: 0.1704\n",
      "Iteration: 2323 \t Total Loss:653.61456 \tTest_accuracy: 0.1704\n",
      "Iteration: 2324 \t Total Loss:640.40955 \tTest_accuracy: 0.1704\n",
      "Iteration: 2325 \t Total Loss:643.87781 \tTest_accuracy: 0.1704\n",
      "Iteration: 2326 \t Total Loss:629.77692 \tTest_accuracy: 0.1704\n",
      "Iteration: 2327 \t Total Loss:653.47284 \tTest_accuracy: 0.1704\n",
      "Iteration: 2328 \t Total Loss:645.45496 \tTest_accuracy: 0.1704\n",
      "Iteration: 2329 \t Total Loss:639.81122 \tTest_accuracy: 0.1704\n",
      "Iteration: 2330 \t Total Loss:644.98529 \tTest_accuracy: 0.1704\n",
      "Iteration: 2331 \t Total Loss:656.34955 \tTest_accuracy: 0.1704\n",
      "Iteration: 2332 \t Total Loss:636.94122 \tTest_accuracy: 0.1704\n",
      "Iteration: 2333 \t Total Loss:634.76813 \tTest_accuracy: 0.1704\n",
      "Iteration: 2334 \t Total Loss:647.82709 \tTest_accuracy: 0.1704\n",
      "Iteration: 2335 \t Total Loss:639.34528 \tTest_accuracy: 0.1704\n",
      "Iteration: 2336 \t Total Loss:635.85760 \tTest_accuracy: 0.1704\n",
      "Iteration: 2337 \t Total Loss:641.19037 \tTest_accuracy: 0.1704\n",
      "Iteration: 2338 \t Total Loss:653.10126 \tTest_accuracy: 0.1704\n",
      "Iteration: 2339 \t Total Loss:640.90991 \tTest_accuracy: 0.1704\n",
      "Iteration: 2340 \t Total Loss:634.53534 \tTest_accuracy: 0.1704\n",
      "Iteration: 2341 \t Total Loss:649.44897 \tTest_accuracy: 0.1704\n",
      "Iteration: 2342 \t Total Loss:653.45807 \tTest_accuracy: 0.1704\n",
      "Iteration: 2343 \t Total Loss:636.04755 \tTest_accuracy: 0.1704\n",
      "Iteration: 2344 \t Total Loss:642.26886 \tTest_accuracy: 0.1704\n",
      "Iteration: 2345 \t Total Loss:645.08600 \tTest_accuracy: 0.1704\n",
      "Iteration: 2346 \t Total Loss:637.33636 \tTest_accuracy: 0.1704\n",
      "Iteration: 2347 \t Total Loss:642.14362 \tTest_accuracy: 0.1704\n",
      "Iteration: 2348 \t Total Loss:655.79138 \tTest_accuracy: 0.1704\n",
      "Iteration: 2349 \t Total Loss:638.46161 \tTest_accuracy: 0.1704\n",
      "Iteration: 2350 \t Total Loss:640.72272 \tTest_accuracy: 0.1704\n",
      "Iteration: 2351 \t Total Loss:641.51978 \tTest_accuracy: 0.1704\n",
      "Iteration: 2352 \t Total Loss:648.44928 \tTest_accuracy: 0.1704\n",
      "Iteration: 2353 \t Total Loss:639.27112 \tTest_accuracy: 0.1704\n",
      "Iteration: 2354 \t Total Loss:649.26141 \tTest_accuracy: 0.1704\n",
      "Iteration: 2355 \t Total Loss:644.18256 \tTest_accuracy: 0.1704\n",
      "Iteration: 2356 \t Total Loss:649.74756 \tTest_accuracy: 0.1704\n",
      "Iteration: 2357 \t Total Loss:639.01825 \tTest_accuracy: 0.1704\n",
      "Iteration: 2358 \t Total Loss:641.92181 \tTest_accuracy: 0.1704\n",
      "Iteration: 2359 \t Total Loss:644.10504 \tTest_accuracy: 0.1704\n",
      "Iteration: 2360 \t Total Loss:654.10291 \tTest_accuracy: 0.1704\n",
      "Iteration: 2361 \t Total Loss:649.68964 \tTest_accuracy: 0.1704\n",
      "Iteration: 2362 \t Total Loss:651.55182 \tTest_accuracy: 0.1704\n",
      "Iteration: 2363 \t Total Loss:639.98340 \tTest_accuracy: 0.1704\n",
      "Iteration: 2364 \t Total Loss:641.67792 \tTest_accuracy: 0.1704\n",
      "Iteration: 2365 \t Total Loss:639.41956 \tTest_accuracy: 0.1704\n",
      "Iteration: 2366 \t Total Loss:650.05133 \tTest_accuracy: 0.1704\n",
      "Iteration: 2367 \t Total Loss:648.74310 \tTest_accuracy: 0.1704\n",
      "Iteration: 2368 \t Total Loss:647.30408 \tTest_accuracy: 0.1704\n",
      "Iteration: 2369 \t Total Loss:655.24384 \tTest_accuracy: 0.1704\n",
      "Iteration: 2370 \t Total Loss:645.71234 \tTest_accuracy: 0.1704\n",
      "Iteration: 2371 \t Total Loss:641.77991 \tTest_accuracy: 0.1704\n",
      "Iteration: 2372 \t Total Loss:644.15253 \tTest_accuracy: 0.1704\n",
      "Iteration: 2373 \t Total Loss:648.87891 \tTest_accuracy: 0.1704\n",
      "Iteration: 2374 \t Total Loss:653.05511 \tTest_accuracy: 0.1704\n",
      "Iteration: 2375 \t Total Loss:653.29877 \tTest_accuracy: 0.1704\n",
      "Iteration: 2376 \t Total Loss:660.33881 \tTest_accuracy: 0.1704\n",
      "Iteration: 2377 \t Total Loss:651.21356 \tTest_accuracy: 0.1704\n",
      "Iteration: 2378 \t Total Loss:644.33844 \tTest_accuracy: 0.1704\n",
      "Iteration: 2379 \t Total Loss:640.46643 \tTest_accuracy: 0.1704\n",
      "Iteration: 2380 \t Total Loss:643.04730 \tTest_accuracy: 0.1704\n",
      "Iteration: 2381 \t Total Loss:643.75690 \tTest_accuracy: 0.1704\n",
      "Iteration: 2382 \t Total Loss:643.29913 \tTest_accuracy: 0.1704\n",
      "Iteration: 2383 \t Total Loss:652.48474 \tTest_accuracy: 0.1704\n",
      "Iteration: 2384 \t Total Loss:642.99298 \tTest_accuracy: 0.1704\n",
      "Iteration: 2385 \t Total Loss:636.13922 \tTest_accuracy: 0.1704\n",
      "Iteration: 2386 \t Total Loss:634.38483 \tTest_accuracy: 0.1704\n",
      "Iteration: 2387 \t Total Loss:639.16937 \tTest_accuracy: 0.1704\n",
      "Iteration: 2388 \t Total Loss:637.20990 \tTest_accuracy: 0.1704\n",
      "Iteration: 2389 \t Total Loss:649.11859 \tTest_accuracy: 0.1704\n",
      "Iteration: 2390 \t Total Loss:650.76727 \tTest_accuracy: 0.1704\n",
      "Iteration: 2391 \t Total Loss:638.05908 \tTest_accuracy: 0.1704\n",
      "Iteration: 2392 \t Total Loss:641.54102 \tTest_accuracy: 0.1704\n",
      "Iteration: 2393 \t Total Loss:649.36810 \tTest_accuracy: 0.1704\n",
      "Iteration: 2394 \t Total Loss:640.81537 \tTest_accuracy: 0.1704\n",
      "Iteration: 2395 \t Total Loss:638.77679 \tTest_accuracy: 0.1704\n",
      "Iteration: 2396 \t Total Loss:646.63641 \tTest_accuracy: 0.1704\n",
      "Iteration: 2397 \t Total Loss:652.98297 \tTest_accuracy: 0.1704\n",
      "Iteration: 2398 \t Total Loss:638.79987 \tTest_accuracy: 0.1704\n",
      "Iteration: 2399 \t Total Loss:640.06073 \tTest_accuracy: 0.1704\n",
      "Iteration: 2400 \t Total Loss:632.83649 \tTest_accuracy: 0.1704\n",
      "Iteration: 2401 \t Total Loss:649.84222 \tTest_accuracy: 0.1704\n",
      "Iteration: 2402 \t Total Loss:649.72931 \tTest_accuracy: 0.1704\n",
      "Iteration: 2403 \t Total Loss:640.78021 \tTest_accuracy: 0.1704\n",
      "Iteration: 2404 \t Total Loss:657.00616 \tTest_accuracy: 0.1704\n",
      "Iteration: 2405 \t Total Loss:633.72137 \tTest_accuracy: 0.1704\n",
      "Iteration: 2406 \t Total Loss:628.71002 \tTest_accuracy: 0.1704\n",
      "Iteration: 2407 \t Total Loss:642.99835 \tTest_accuracy: 0.1704\n",
      "Iteration: 2408 \t Total Loss:633.43500 \tTest_accuracy: 0.1704\n",
      "Iteration: 2409 \t Total Loss:639.37628 \tTest_accuracy: 0.1704\n",
      "Iteration: 2410 \t Total Loss:646.35004 \tTest_accuracy: 0.1704\n",
      "Iteration: 2411 \t Total Loss:648.73370 \tTest_accuracy: 0.1704\n",
      "Iteration: 2412 \t Total Loss:649.97699 \tTest_accuracy: 0.1704\n",
      "Iteration: 2413 \t Total Loss:658.66431 \tTest_accuracy: 0.1704\n",
      "Iteration: 2414 \t Total Loss:646.45996 \tTest_accuracy: 0.1704\n",
      "Iteration: 2415 \t Total Loss:639.99078 \tTest_accuracy: 0.1704\n",
      "Iteration: 2416 \t Total Loss:656.13983 \tTest_accuracy: 0.1704\n",
      "Iteration: 2417 \t Total Loss:656.95111 \tTest_accuracy: 0.1704\n",
      "Iteration: 2418 \t Total Loss:641.29810 \tTest_accuracy: 0.1704\n",
      "Iteration: 2419 \t Total Loss:637.03668 \tTest_accuracy: 0.1704\n",
      "Iteration: 2420 \t Total Loss:646.08630 \tTest_accuracy: 0.1704\n",
      "Iteration: 2421 \t Total Loss:645.61884 \tTest_accuracy: 0.1704\n",
      "Iteration: 2422 \t Total Loss:659.19843 \tTest_accuracy: 0.1704\n",
      "Iteration: 2423 \t Total Loss:652.45038 \tTest_accuracy: 0.1704\n",
      "Iteration: 2424 \t Total Loss:652.06207 \tTest_accuracy: 0.1704\n",
      "Iteration: 2425 \t Total Loss:654.86029 \tTest_accuracy: 0.1704\n",
      "Iteration: 2426 \t Total Loss:645.99097 \tTest_accuracy: 0.1704\n",
      "Iteration: 2427 \t Total Loss:638.44275 \tTest_accuracy: 0.1704\n",
      "Iteration: 2428 \t Total Loss:638.87726 \tTest_accuracy: 0.1704\n",
      "Iteration: 2429 \t Total Loss:638.92780 \tTest_accuracy: 0.1704\n",
      "Iteration: 2430 \t Total Loss:643.82855 \tTest_accuracy: 0.1704\n",
      "Iteration: 2431 \t Total Loss:642.55743 \tTest_accuracy: 0.1704\n",
      "Iteration: 2432 \t Total Loss:637.48151 \tTest_accuracy: 0.1704\n",
      "Iteration: 2433 \t Total Loss:638.73206 \tTest_accuracy: 0.1704\n",
      "Iteration: 2434 \t Total Loss:643.63104 \tTest_accuracy: 0.1704\n",
      "Iteration: 2435 \t Total Loss:642.24738 \tTest_accuracy: 0.1704\n",
      "Iteration: 2436 \t Total Loss:637.43182 \tTest_accuracy: 0.1704\n",
      "Iteration: 2437 \t Total Loss:641.43768 \tTest_accuracy: 0.1704\n",
      "Iteration: 2438 \t Total Loss:638.73059 \tTest_accuracy: 0.1704\n",
      "Iteration: 2439 \t Total Loss:641.96082 \tTest_accuracy: 0.1704\n",
      "Iteration: 2440 \t Total Loss:644.00555 \tTest_accuracy: 0.1704\n",
      "Iteration: 2441 \t Total Loss:658.39264 \tTest_accuracy: 0.1704\n",
      "Iteration: 2442 \t Total Loss:642.15881 \tTest_accuracy: 0.1704\n",
      "Iteration: 2443 \t Total Loss:641.77167 \tTest_accuracy: 0.1704\n",
      "Iteration: 2444 \t Total Loss:645.14594 \tTest_accuracy: 0.1704\n",
      "Iteration: 2445 \t Total Loss:642.67572 \tTest_accuracy: 0.1704\n",
      "Iteration: 2446 \t Total Loss:642.80426 \tTest_accuracy: 0.1704\n",
      "Iteration: 2447 \t Total Loss:656.96558 \tTest_accuracy: 0.1704\n",
      "Iteration: 2448 \t Total Loss:631.36560 \tTest_accuracy: 0.1704\n",
      "Iteration: 2449 \t Total Loss:643.63605 \tTest_accuracy: 0.1704\n",
      "Iteration: 2450 \t Total Loss:637.53101 \tTest_accuracy: 0.1704\n",
      "Iteration: 2451 \t Total Loss:630.15094 \tTest_accuracy: 0.1704\n",
      "Iteration: 2452 \t Total Loss:654.81940 \tTest_accuracy: 0.1704\n",
      "Iteration: 2453 \t Total Loss:644.77673 \tTest_accuracy: 0.1704\n",
      "Iteration: 2454 \t Total Loss:640.71356 \tTest_accuracy: 0.1704\n",
      "Iteration: 2455 \t Total Loss:645.49652 \tTest_accuracy: 0.1704\n",
      "Iteration: 2456 \t Total Loss:642.54364 \tTest_accuracy: 0.1704\n",
      "Iteration: 2457 \t Total Loss:649.97003 \tTest_accuracy: 0.1704\n",
      "Iteration: 2458 \t Total Loss:650.16669 \tTest_accuracy: 0.1704\n",
      "Iteration: 2459 \t Total Loss:635.85309 \tTest_accuracy: 0.1704\n",
      "Iteration: 2460 \t Total Loss:641.84601 \tTest_accuracy: 0.1704\n",
      "Iteration: 2461 \t Total Loss:643.42572 \tTest_accuracy: 0.1704\n",
      "Iteration: 2462 \t Total Loss:648.81812 \tTest_accuracy: 0.1704\n",
      "Iteration: 2463 \t Total Loss:650.00830 \tTest_accuracy: 0.1704\n",
      "Iteration: 2464 \t Total Loss:642.63666 \tTest_accuracy: 0.1704\n",
      "Iteration: 2465 \t Total Loss:636.36981 \tTest_accuracy: 0.1704\n",
      "Iteration: 2466 \t Total Loss:646.19312 \tTest_accuracy: 0.1704\n",
      "Iteration: 2467 \t Total Loss:655.61542 \tTest_accuracy: 0.1704\n",
      "Iteration: 2468 \t Total Loss:639.00580 \tTest_accuracy: 0.1704\n",
      "Iteration: 2469 \t Total Loss:653.95453 \tTest_accuracy: 0.1704\n",
      "Iteration: 2470 \t Total Loss:651.41949 \tTest_accuracy: 0.1704\n",
      "Iteration: 2471 \t Total Loss:653.44379 \tTest_accuracy: 0.1704\n",
      "Iteration: 2472 \t Total Loss:640.77100 \tTest_accuracy: 0.1704\n",
      "Iteration: 2473 \t Total Loss:641.02289 \tTest_accuracy: 0.1704\n",
      "Iteration: 2474 \t Total Loss:636.00653 \tTest_accuracy: 0.1704\n",
      "Iteration: 2475 \t Total Loss:642.52490 \tTest_accuracy: 0.1704\n",
      "Iteration: 2476 \t Total Loss:639.42218 \tTest_accuracy: 0.1704\n",
      "Iteration: 2477 \t Total Loss:641.44550 \tTest_accuracy: 0.1704\n",
      "Iteration: 2478 \t Total Loss:655.51984 \tTest_accuracy: 0.1704\n",
      "Iteration: 2479 \t Total Loss:655.00183 \tTest_accuracy: 0.1704\n",
      "Iteration: 2480 \t Total Loss:648.76874 \tTest_accuracy: 0.1704\n",
      "Iteration: 2481 \t Total Loss:641.77893 \tTest_accuracy: 0.1704\n",
      "Iteration: 2482 \t Total Loss:637.75653 \tTest_accuracy: 0.1704\n",
      "Iteration: 2483 \t Total Loss:649.13715 \tTest_accuracy: 0.1704\n",
      "Iteration: 2484 \t Total Loss:649.37067 \tTest_accuracy: 0.1704\n",
      "Iteration: 2485 \t Total Loss:635.01990 \tTest_accuracy: 0.1704\n",
      "Iteration: 2486 \t Total Loss:650.75702 \tTest_accuracy: 0.1704\n",
      "Iteration: 2487 \t Total Loss:668.39594 \tTest_accuracy: 0.1704\n",
      "Iteration: 2488 \t Total Loss:640.35016 \tTest_accuracy: 0.1704\n",
      "Iteration: 2489 \t Total Loss:655.12830 \tTest_accuracy: 0.1704\n",
      "Iteration: 2490 \t Total Loss:661.88580 \tTest_accuracy: 0.1704\n",
      "Iteration: 2491 \t Total Loss:647.20941 \tTest_accuracy: 0.1704\n",
      "Iteration: 2492 \t Total Loss:658.57648 \tTest_accuracy: 0.1704\n",
      "Iteration: 2493 \t Total Loss:656.95343 \tTest_accuracy: 0.1704\n",
      "Iteration: 2494 \t Total Loss:644.47809 \tTest_accuracy: 0.1704\n",
      "Iteration: 2495 \t Total Loss:639.79547 \tTest_accuracy: 0.1704\n",
      "Iteration: 2496 \t Total Loss:647.39679 \tTest_accuracy: 0.1704\n",
      "Iteration: 2497 \t Total Loss:644.66254 \tTest_accuracy: 0.1704\n",
      "Iteration: 2498 \t Total Loss:645.15680 \tTest_accuracy: 0.1704\n",
      "Iteration: 2499 \t Total Loss:647.22479 \tTest_accuracy: 0.1704\n",
      "Iteration: 2500 \t Total Loss:637.21979 \tTest_accuracy: 0.1704\n",
      "Iteration: 2501 \t Total Loss:647.21576 \tTest_accuracy: 0.1704\n",
      "Iteration: 2502 \t Total Loss:641.00421 \tTest_accuracy: 0.1704\n",
      "Iteration: 2503 \t Total Loss:646.76874 \tTest_accuracy: 0.1704\n",
      "Iteration: 2504 \t Total Loss:647.73938 \tTest_accuracy: 0.1704\n",
      "Iteration: 2505 \t Total Loss:656.82806 \tTest_accuracy: 0.1704\n",
      "Iteration: 2506 \t Total Loss:637.24609 \tTest_accuracy: 0.1704\n",
      "Iteration: 2507 \t Total Loss:645.47089 \tTest_accuracy: 0.1704\n",
      "Iteration: 2508 \t Total Loss:637.60492 \tTest_accuracy: 0.1704\n",
      "Iteration: 2509 \t Total Loss:637.62640 \tTest_accuracy: 0.1704\n",
      "Iteration: 2510 \t Total Loss:639.90131 \tTest_accuracy: 0.1704\n",
      "Iteration: 2511 \t Total Loss:654.57123 \tTest_accuracy: 0.1704\n",
      "Iteration: 2512 \t Total Loss:649.94006 \tTest_accuracy: 0.1704\n",
      "Iteration: 2513 \t Total Loss:651.81537 \tTest_accuracy: 0.1704\n",
      "Iteration: 2514 \t Total Loss:637.43555 \tTest_accuracy: 0.1704\n",
      "Iteration: 2515 \t Total Loss:649.59357 \tTest_accuracy: 0.1704\n",
      "Iteration: 2516 \t Total Loss:635.93805 \tTest_accuracy: 0.1704\n",
      "Iteration: 2517 \t Total Loss:645.00549 \tTest_accuracy: 0.1704\n",
      "Iteration: 2518 \t Total Loss:636.46875 \tTest_accuracy: 0.1704\n",
      "Iteration: 2519 \t Total Loss:635.95111 \tTest_accuracy: 0.1704\n",
      "Iteration: 2520 \t Total Loss:638.66833 \tTest_accuracy: 0.1704\n",
      "Iteration: 2521 \t Total Loss:651.55377 \tTest_accuracy: 0.1704\n",
      "Iteration: 2522 \t Total Loss:636.13342 \tTest_accuracy: 0.1704\n",
      "Iteration: 2523 \t Total Loss:645.34534 \tTest_accuracy: 0.1704\n",
      "Iteration: 2524 \t Total Loss:648.41193 \tTest_accuracy: 0.1704\n",
      "Iteration: 2525 \t Total Loss:653.83978 \tTest_accuracy: 0.1704\n",
      "Iteration: 2526 \t Total Loss:653.92938 \tTest_accuracy: 0.1704\n",
      "Iteration: 2527 \t Total Loss:651.87335 \tTest_accuracy: 0.1704\n",
      "Iteration: 2528 \t Total Loss:648.38995 \tTest_accuracy: 0.1704\n",
      "Iteration: 2529 \t Total Loss:646.76489 \tTest_accuracy: 0.1704\n",
      "Iteration: 2530 \t Total Loss:659.66278 \tTest_accuracy: 0.1704\n",
      "Iteration: 2531 \t Total Loss:641.25067 \tTest_accuracy: 0.1704\n",
      "Iteration: 2532 \t Total Loss:642.37537 \tTest_accuracy: 0.1704\n",
      "Iteration: 2533 \t Total Loss:641.69843 \tTest_accuracy: 0.1704\n",
      "Iteration: 2534 \t Total Loss:633.90167 \tTest_accuracy: 0.1704\n",
      "Iteration: 2535 \t Total Loss:651.12280 \tTest_accuracy: 0.1704\n",
      "Iteration: 2536 \t Total Loss:650.24164 \tTest_accuracy: 0.1704\n",
      "Iteration: 2537 \t Total Loss:637.99805 \tTest_accuracy: 0.1704\n",
      "Iteration: 2538 \t Total Loss:635.58301 \tTest_accuracy: 0.1704\n",
      "Iteration: 2539 \t Total Loss:654.98676 \tTest_accuracy: 0.1704\n",
      "Iteration: 2540 \t Total Loss:644.81635 \tTest_accuracy: 0.1704\n",
      "Iteration: 2541 \t Total Loss:640.36346 \tTest_accuracy: 0.1704\n",
      "Iteration: 2542 \t Total Loss:636.66907 \tTest_accuracy: 0.1704\n",
      "Iteration: 2543 \t Total Loss:655.22162 \tTest_accuracy: 0.1704\n",
      "Iteration: 2544 \t Total Loss:643.03937 \tTest_accuracy: 0.1704\n",
      "Iteration: 2545 \t Total Loss:648.39221 \tTest_accuracy: 0.1704\n",
      "Iteration: 2546 \t Total Loss:652.95905 \tTest_accuracy: 0.1704\n",
      "Iteration: 2547 \t Total Loss:648.16571 \tTest_accuracy: 0.1704\n",
      "Iteration: 2548 \t Total Loss:639.17072 \tTest_accuracy: 0.1704\n",
      "Iteration: 2549 \t Total Loss:636.86407 \tTest_accuracy: 0.1704\n",
      "Iteration: 2550 \t Total Loss:635.54736 \tTest_accuracy: 0.1704\n",
      "Iteration: 2551 \t Total Loss:634.22797 \tTest_accuracy: 0.1704\n",
      "Iteration: 2552 \t Total Loss:649.95447 \tTest_accuracy: 0.1704\n",
      "Iteration: 2553 \t Total Loss:653.16473 \tTest_accuracy: 0.1704\n",
      "Iteration: 2554 \t Total Loss:650.26404 \tTest_accuracy: 0.1704\n",
      "Iteration: 2555 \t Total Loss:643.48492 \tTest_accuracy: 0.1704\n",
      "Iteration: 2556 \t Total Loss:640.50543 \tTest_accuracy: 0.1704\n",
      "Iteration: 2557 \t Total Loss:655.30237 \tTest_accuracy: 0.1704\n",
      "Iteration: 2558 \t Total Loss:648.03638 \tTest_accuracy: 0.1704\n",
      "Iteration: 2559 \t Total Loss:649.59210 \tTest_accuracy: 0.1704\n",
      "Iteration: 2560 \t Total Loss:646.33435 \tTest_accuracy: 0.1704\n",
      "Iteration: 2561 \t Total Loss:649.86389 \tTest_accuracy: 0.1704\n",
      "Iteration: 2562 \t Total Loss:638.62726 \tTest_accuracy: 0.1704\n",
      "Iteration: 2563 \t Total Loss:654.00659 \tTest_accuracy: 0.1704\n",
      "Iteration: 2564 \t Total Loss:647.83752 \tTest_accuracy: 0.1704\n",
      "Iteration: 2565 \t Total Loss:650.98743 \tTest_accuracy: 0.1704\n",
      "Iteration: 2566 \t Total Loss:643.76959 \tTest_accuracy: 0.1704\n",
      "Iteration: 2567 \t Total Loss:655.14404 \tTest_accuracy: 0.1704\n",
      "Iteration: 2568 \t Total Loss:653.54230 \tTest_accuracy: 0.1704\n",
      "Iteration: 2569 \t Total Loss:646.32672 \tTest_accuracy: 0.1704\n",
      "Iteration: 2570 \t Total Loss:643.31403 \tTest_accuracy: 0.1704\n",
      "Iteration: 2571 \t Total Loss:643.79987 \tTest_accuracy: 0.1704\n",
      "Iteration: 2572 \t Total Loss:652.46564 \tTest_accuracy: 0.1704\n",
      "Iteration: 2573 \t Total Loss:637.88843 \tTest_accuracy: 0.1704\n",
      "Iteration: 2574 \t Total Loss:642.28949 \tTest_accuracy: 0.1704\n",
      "Iteration: 2575 \t Total Loss:648.27502 \tTest_accuracy: 0.1704\n",
      "Iteration: 2576 \t Total Loss:647.88971 \tTest_accuracy: 0.1704\n",
      "Iteration: 2577 \t Total Loss:645.08154 \tTest_accuracy: 0.1704\n",
      "Iteration: 2578 \t Total Loss:643.66132 \tTest_accuracy: 0.1704\n",
      "Iteration: 2579 \t Total Loss:638.84216 \tTest_accuracy: 0.1704\n",
      "Iteration: 2580 \t Total Loss:639.47882 \tTest_accuracy: 0.1704\n",
      "Iteration: 2581 \t Total Loss:642.36761 \tTest_accuracy: 0.1704\n",
      "Iteration: 2582 \t Total Loss:643.33936 \tTest_accuracy: 0.1704\n",
      "Iteration: 2583 \t Total Loss:654.65015 \tTest_accuracy: 0.1704\n",
      "Iteration: 2584 \t Total Loss:647.14368 \tTest_accuracy: 0.1704\n",
      "Iteration: 2585 \t Total Loss:642.77325 \tTest_accuracy: 0.1704\n",
      "Iteration: 2586 \t Total Loss:654.38153 \tTest_accuracy: 0.1704\n",
      "Iteration: 2587 \t Total Loss:645.97308 \tTest_accuracy: 0.1704\n",
      "Iteration: 2588 \t Total Loss:634.38019 \tTest_accuracy: 0.1704\n",
      "Iteration: 2589 \t Total Loss:638.19269 \tTest_accuracy: 0.1704\n",
      "Iteration: 2590 \t Total Loss:646.41254 \tTest_accuracy: 0.1704\n",
      "Iteration: 2591 \t Total Loss:640.45978 \tTest_accuracy: 0.1704\n",
      "Iteration: 2592 \t Total Loss:634.03058 \tTest_accuracy: 0.1704\n",
      "Iteration: 2593 \t Total Loss:641.11957 \tTest_accuracy: 0.1704\n",
      "Iteration: 2594 \t Total Loss:658.21545 \tTest_accuracy: 0.1704\n",
      "Iteration: 2595 \t Total Loss:644.28143 \tTest_accuracy: 0.1704\n",
      "Iteration: 2596 \t Total Loss:635.16595 \tTest_accuracy: 0.1704\n",
      "Iteration: 2597 \t Total Loss:651.18182 \tTest_accuracy: 0.1704\n",
      "Iteration: 2598 \t Total Loss:638.65179 \tTest_accuracy: 0.1704\n",
      "Iteration: 2599 \t Total Loss:639.88422 \tTest_accuracy: 0.1704\n",
      "Iteration: 2600 \t Total Loss:654.03290 \tTest_accuracy: 0.1704\n",
      "Iteration: 2601 \t Total Loss:643.98334 \tTest_accuracy: 0.1704\n",
      "Iteration: 2602 \t Total Loss:659.93719 \tTest_accuracy: 0.1704\n",
      "Iteration: 2603 \t Total Loss:640.93927 \tTest_accuracy: 0.1704\n",
      "Iteration: 2604 \t Total Loss:650.89911 \tTest_accuracy: 0.1704\n",
      "Iteration: 2605 \t Total Loss:649.67163 \tTest_accuracy: 0.1704\n",
      "Iteration: 2606 \t Total Loss:648.27161 \tTest_accuracy: 0.1704\n",
      "Iteration: 2607 \t Total Loss:651.20312 \tTest_accuracy: 0.1704\n",
      "Iteration: 2608 \t Total Loss:633.62109 \tTest_accuracy: 0.1704\n",
      "Iteration: 2609 \t Total Loss:650.64832 \tTest_accuracy: 0.1704\n",
      "Iteration: 2610 \t Total Loss:652.05695 \tTest_accuracy: 0.1704\n",
      "Iteration: 2611 \t Total Loss:644.97687 \tTest_accuracy: 0.1704\n",
      "Iteration: 2612 \t Total Loss:644.48291 \tTest_accuracy: 0.1704\n",
      "Iteration: 2613 \t Total Loss:642.97412 \tTest_accuracy: 0.1704\n",
      "Iteration: 2614 \t Total Loss:648.35626 \tTest_accuracy: 0.1704\n",
      "Iteration: 2615 \t Total Loss:651.67682 \tTest_accuracy: 0.1704\n",
      "Iteration: 2616 \t Total Loss:650.37250 \tTest_accuracy: 0.1704\n",
      "Iteration: 2617 \t Total Loss:639.77917 \tTest_accuracy: 0.1704\n",
      "Iteration: 2618 \t Total Loss:650.00616 \tTest_accuracy: 0.1704\n",
      "Iteration: 2619 \t Total Loss:656.90643 \tTest_accuracy: 0.1704\n",
      "Iteration: 2620 \t Total Loss:636.69690 \tTest_accuracy: 0.1704\n",
      "Iteration: 2621 \t Total Loss:645.69073 \tTest_accuracy: 0.1704\n",
      "Iteration: 2622 \t Total Loss:639.60370 \tTest_accuracy: 0.1704\n",
      "Iteration: 2623 \t Total Loss:655.91852 \tTest_accuracy: 0.1704\n",
      "Iteration: 2624 \t Total Loss:643.03992 \tTest_accuracy: 0.1704\n",
      "Iteration: 2625 \t Total Loss:659.92761 \tTest_accuracy: 0.1704\n",
      "Iteration: 2626 \t Total Loss:629.87982 \tTest_accuracy: 0.1704\n",
      "Iteration: 2627 \t Total Loss:644.90729 \tTest_accuracy: 0.1704\n",
      "Iteration: 2628 \t Total Loss:641.53333 \tTest_accuracy: 0.1704\n",
      "Iteration: 2629 \t Total Loss:639.18561 \tTest_accuracy: 0.1704\n",
      "Iteration: 2630 \t Total Loss:653.81543 \tTest_accuracy: 0.1704\n",
      "Iteration: 2631 \t Total Loss:653.29950 \tTest_accuracy: 0.1704\n",
      "Iteration: 2632 \t Total Loss:640.20593 \tTest_accuracy: 0.1704\n",
      "Iteration: 2633 \t Total Loss:651.02954 \tTest_accuracy: 0.1704\n",
      "Iteration: 2634 \t Total Loss:656.99298 \tTest_accuracy: 0.1704\n",
      "Iteration: 2635 \t Total Loss:645.60822 \tTest_accuracy: 0.1704\n",
      "Iteration: 2636 \t Total Loss:645.09448 \tTest_accuracy: 0.1704\n",
      "Iteration: 2637 \t Total Loss:645.58258 \tTest_accuracy: 0.1704\n",
      "Iteration: 2638 \t Total Loss:649.74762 \tTest_accuracy: 0.1704\n",
      "Iteration: 2639 \t Total Loss:645.11389 \tTest_accuracy: 0.1704\n",
      "Iteration: 2640 \t Total Loss:646.34332 \tTest_accuracy: 0.1704\n",
      "Iteration: 2641 \t Total Loss:642.55237 \tTest_accuracy: 0.1704\n",
      "Iteration: 2642 \t Total Loss:651.45361 \tTest_accuracy: 0.1704\n",
      "Iteration: 2643 \t Total Loss:640.42560 \tTest_accuracy: 0.1704\n",
      "Iteration: 2644 \t Total Loss:660.88605 \tTest_accuracy: 0.1704\n",
      "Iteration: 2645 \t Total Loss:640.07928 \tTest_accuracy: 0.1704\n",
      "Iteration: 2646 \t Total Loss:639.87823 \tTest_accuracy: 0.1704\n",
      "Iteration: 2647 \t Total Loss:642.57947 \tTest_accuracy: 0.1704\n",
      "Iteration: 2648 \t Total Loss:648.42621 \tTest_accuracy: 0.1704\n",
      "Iteration: 2649 \t Total Loss:641.82953 \tTest_accuracy: 0.1704\n",
      "Iteration: 2650 \t Total Loss:651.43817 \tTest_accuracy: 0.1704\n",
      "Iteration: 2651 \t Total Loss:652.39655 \tTest_accuracy: 0.1704\n",
      "Iteration: 2652 \t Total Loss:654.89191 \tTest_accuracy: 0.1704\n",
      "Iteration: 2653 \t Total Loss:649.12775 \tTest_accuracy: 0.1704\n",
      "Iteration: 2654 \t Total Loss:648.94714 \tTest_accuracy: 0.1704\n",
      "Iteration: 2655 \t Total Loss:642.12714 \tTest_accuracy: 0.1704\n",
      "Iteration: 2656 \t Total Loss:651.53375 \tTest_accuracy: 0.1704\n",
      "Iteration: 2657 \t Total Loss:661.32471 \tTest_accuracy: 0.1704\n",
      "Iteration: 2658 \t Total Loss:633.66180 \tTest_accuracy: 0.1704\n",
      "Iteration: 2659 \t Total Loss:637.30457 \tTest_accuracy: 0.1704\n",
      "Iteration: 2660 \t Total Loss:645.64410 \tTest_accuracy: 0.1704\n",
      "Iteration: 2661 \t Total Loss:638.28473 \tTest_accuracy: 0.1704\n",
      "Iteration: 2662 \t Total Loss:647.40283 \tTest_accuracy: 0.1704\n",
      "Iteration: 2663 \t Total Loss:648.85846 \tTest_accuracy: 0.1704\n",
      "Iteration: 2664 \t Total Loss:645.09845 \tTest_accuracy: 0.1704\n",
      "Iteration: 2665 \t Total Loss:640.19635 \tTest_accuracy: 0.1704\n",
      "Iteration: 2666 \t Total Loss:642.93408 \tTest_accuracy: 0.1704\n",
      "Iteration: 2667 \t Total Loss:643.86407 \tTest_accuracy: 0.1704\n",
      "Iteration: 2668 \t Total Loss:644.90234 \tTest_accuracy: 0.1704\n",
      "Iteration: 2669 \t Total Loss:652.62909 \tTest_accuracy: 0.1704\n",
      "Iteration: 2670 \t Total Loss:644.39606 \tTest_accuracy: 0.1704\n",
      "Iteration: 2671 \t Total Loss:660.06525 \tTest_accuracy: 0.1704\n",
      "Iteration: 2672 \t Total Loss:646.57031 \tTest_accuracy: 0.1704\n",
      "Iteration: 2673 \t Total Loss:647.40680 \tTest_accuracy: 0.1704\n",
      "Iteration: 2674 \t Total Loss:635.36121 \tTest_accuracy: 0.1704\n",
      "Iteration: 2675 \t Total Loss:643.85370 \tTest_accuracy: 0.1704\n",
      "Iteration: 2676 \t Total Loss:652.10907 \tTest_accuracy: 0.1704\n",
      "Iteration: 2677 \t Total Loss:645.88715 \tTest_accuracy: 0.1704\n",
      "Iteration: 2678 \t Total Loss:653.47845 \tTest_accuracy: 0.1704\n",
      "Iteration: 2679 \t Total Loss:652.89862 \tTest_accuracy: 0.1704\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 50\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# y_hat = forward_model(x_hat.squeeze(0).unsqueeze(-1), adj)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# y = torch.where(y_hat > 0.05, 1, 0)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m loss, L0 \u001b[38;5;241m=\u001b[39m loss_inverse(y_true, y_hat, x_hat)\n\u001b[0;32m---> 50\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     51\u001b[0m z_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     53\u001b[0m _, top_seeds_predict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(x_hat, seed_num)\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for param in vae_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in forward_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "encoder = vae_model.Encoder\n",
    "decoder = vae_model.Decoder\n",
    "\n",
    "def loss_inverse(y_true, y_hat, x_hat):\n",
    "    _, top_indices_true = torch.topk(y_true.clone(), top_num)\n",
    "    label_2 = torch.zeros(y_true.shape).to(device)\n",
    "    label_2[top_indices_true] = 1\n",
    "    \n",
    "    forward_loss = 0.5*F.mse_loss(y_hat.squeeze(-1), y_i, reduction='sum') + F.mse_loss(y_hat.squeeze(-1), label_2, reduction='sum')    \n",
    "\n",
    "    # forward_loss = F.mse_loss(y_hat, y_true)\n",
    "    L0_loss = torch.sum(torch.abs(x_hat))/x_hat.shape[0]\n",
    "    return forward_loss+L0_loss, L0_loss\n",
    "\n",
    "\n",
    "topk_seed = torch.ones(len(seeds_infection[0][0])).to(device)\n",
    "\n",
    "y_true = torch.tensor(seeds_infection[66][1]).to(device)\n",
    "\n",
    "init = torch.tensor(seeds_infection[777][0]).to(device)\n",
    "\n",
    "z_hat = encoder(init).detach().to(device)\n",
    "z_hat.requires_grad = True\n",
    "z_optimizer = Adam([z_hat], lr=1e-5)\n",
    "\n",
    "for i in range(10000):\n",
    "    x_hat = decoder(z_hat)\n",
    "    \n",
    "    infection = inflected * torch.unsqueeze(x_hat, 1)\n",
    "\n",
    "            \n",
    "    infection_i = encoder(infection)\n",
    "    seeds_i = encoder(x_hat)\n",
    "    seeds_i = seeds_i.expand(x_hat.shape[0], -1)\n",
    "    \n",
    "    y_hat = forward_model(seeds_i, infection_i, edge_index)\n",
    "    \n",
    "    # y_hat = forward_model(x_hat.squeeze(0).unsqueeze(-1), adj)\n",
    "    \n",
    "    # y = torch.where(y_hat > 0.05, 1, 0)\n",
    "    \n",
    "    loss, L0 = loss_inverse(y_true, y_hat, x_hat)\n",
    "    \n",
    "    loss.backward()\n",
    "    z_optimizer.step()\n",
    "            \n",
    "    _, top_seeds_predict = torch.topk(x_hat, seed_num)\n",
    "    _, top_seeds_true = torch.topk(topk_seed, seed_num)\n",
    "    \n",
    "\n",
    "\n",
    "    # 将张量数组转换为Python列表\n",
    "    list_pre = top_seeds_predict.tolist()\n",
    "    list_true = top_seeds_true.tolist()\n",
    "    \n",
    "    # 使用集合操作找到交集\n",
    "    intersection = list(set(list1) & set(list_pre))\n",
    "\n",
    "    \n",
    "    accuracy = len(intersection) / seed_num  \n",
    "\n",
    "    print('Iteration: {}'.format(i+1),\n",
    "          '\\t Total Loss:{:.5f}'.format(loss.item()),\n",
    "          \"\\tTest_accuracy: {:.4f}\".format(accuracy)\n",
    "        )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
