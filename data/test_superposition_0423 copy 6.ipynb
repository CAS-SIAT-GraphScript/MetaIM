{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=7)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('/home/zjy/project/MetaIM')\n",
    "pwd = '/home/zjy/project/MetaIM/data'\n",
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "cora_dataset = Planetoid(root=pwd+'/cora', name='cora')\n",
    "data = cora_dataset[0]\n",
    "edge_index = data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 2708), (1000, 2, 2708))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "individual_infection_path = pwd+'/for_meta/cora_individual_infection_sir_200.npy'\n",
    "seeds_infection_path = pwd+'/for_meta/cora_seed_infection_sir_200_sample_1000.npy'\n",
    "\n",
    "individual_infection = np.load(individual_infection_path)\n",
    "seeds_infection = np.load(seeds_infection_path)\n",
    "individual_infection.shape,seeds_infection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "                       [ 633, 1862, 2582,  ...,  598, 1473, 2706]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "       size=(2708, 2708), nnz=10556, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# 转换为 scipy 稀疏矩阵\n",
    "adj = to_scipy_sparse_matrix(edge_index)\n",
    "\n",
    "adj = torch.Tensor(adj.toarray()).to_sparse()\n",
    "adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2546363/4019088435.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "def graph_laplacian_embedding(adjacency_matrix, num_dimensions):\n",
    "    # 将邻接矩阵转换为PyTorch张量\n",
    "    adjacency_matrix = torch.tensor(adjacency_matrix, dtype=torch.float32)\n",
    "    \n",
    "    # Step 1: 计算度矩阵\n",
    "    degree_matrix = torch.diag(adjacency_matrix.sum(dim=1))\n",
    "    \n",
    "    # Step 2: 计算拉普拉斯矩阵\n",
    "    laplacian_matrix = degree_matrix - adjacency_matrix\n",
    "    \n",
    "    # Step 3: 计算拉普拉斯矩阵的特征向量和特征值\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(laplacian_matrix)\n",
    "    \n",
    "    # Step 4: 选择低维表示\n",
    "    # 取特征值非零的前 num_dimensions 个特征向量作为嵌入结果\n",
    "    embedding = eigenvectors[:, :num_dimensions]\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "def edge_index_to_adj(edge_index, num_nodes):\n",
    "    adj = torch.zeros((num_nodes, num_nodes))\n",
    "    for i in range(edge_index.size(1)):\n",
    "        start_node = edge_index[0, i]\n",
    "        end_node = edge_index[1, i]\n",
    "        adj[start_node, end_node] = 1\n",
    "        adj[end_node, start_node] = 1  # 如果是有向图，可以不需要这行\n",
    "    return adj\n",
    "\n",
    "latent_dim = 128\n",
    "\n",
    "adj_n = edge_index_to_adj(edge_index, individual_infection.shape[0])\n",
    "\n",
    "laplace_emb = graph_laplacian_embedding(adj_n, latent_dim)\n",
    "\n",
    "laplace_emb = laplace_emb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = int(seeds_infection[0][0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, individual_infection,seeds_infection, seed_num):\n",
    "        self.individual_infection = individual_infection\n",
    "        self.seeds_infection = seeds_infection\n",
    "        self.feat_shape = (len(individual_infection), seed_num)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seeds_infection)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seeds= np.nonzero(self.seeds_infection[idx][0])[0]\n",
    "        \n",
    "        feature = torch.zeros(self.feat_shape[0],self.feat_shape[1])\n",
    "        for i in range(len(seeds)):\n",
    "            seed_i_infection = torch.tensor(self.individual_infection[seeds[i]])\n",
    "            feature[:, i] = seed_i_infection\n",
    "            \n",
    "        label = self.seeds_infection[idx][1]\n",
    "        \n",
    "        return self.seeds_infection[idx][0], feature, label\n",
    "\n",
    "dataset = CustomDataset(individual_infection, seeds_infection, seed_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义划分比例\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "# 划分数据集\n",
    "train_dataset, test_dataset = random_split(dataset, [int(len(dataset)*train_ratio), int(len(dataset)*test_ratio)])\n",
    "\n",
    "train_batch_size = 64\n",
    "test_batch_size = 4\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, feat_dim, latent_dim, hidden_channels, out_channels, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        # self.linear1 = nn.Linear(latent_dim, 128)\n",
    "        self.conv1 = GATConv(feat_dim, hidden_channels, heads=num_heads)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels * num_heads, heads=1)\n",
    "        self.linear2 = nn.Linear(hidden_channels * num_heads+latent_dim, 1)\n",
    "\n",
    "    def forward(self, feat_i, x_i, edge_index):\n",
    "        x = self.conv1(feat_i, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # latten = F.relu(self.linear1(x_i))\n",
    "        x =  torch.cat((x, x_i), dim=-1)\n",
    "        x = self.linear2(x)\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (conv1): GATConv(135, 512, heads=4)\n",
       "  (conv2): GATConv(2048, 2048, heads=1)\n",
       "  (linear2): Linear(in_features=2176, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_num = seed_num\n",
    "\n",
    "forward_model = GAT(feat_num,latent_dim, 512, 1, 4)\n",
    "\n",
    "optimizer = Adam([{'params': forward_model.parameters()}], \n",
    "                 lr=0.001)\n",
    "\n",
    "adj = adj.to(device)\n",
    "forward_model = forward_model.to(device)\n",
    "forward_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(tensor):\n",
    "    # 计算每个特征的最小值和最大值\n",
    "    min_vals, _ = torch.min(tensor, dim=0)\n",
    "    max_vals, _ = torch.max(tensor, dim=0)\n",
    "\n",
    "    # 对每个特征进行归一化\n",
    "    normalized_tensor = (tensor - min_vals) / (max_vals - min_vals)\n",
    "    return normalized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTotal: 1574.5874 \tMean_train_accuracy: 0.5531\n",
      "\tMean_test_accuracy: 0.5365 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 2 \tTotal: 1274.6249 \tMean_train_accuracy: 0.5594\n",
      "\tMean_test_accuracy: 0.5540 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 3 \tTotal: 1115.8809 \tMean_train_accuracy: 0.5589\n",
      "\tMean_test_accuracy: 0.5560 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 4 \tTotal: 1041.2600 \tMean_train_accuracy: 0.5592\n",
      "\tMean_test_accuracy: 0.5605 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 5 \tTotal: 1013.5685 \tMean_train_accuracy: 0.5692\n",
      "\tMean_test_accuracy: 0.5605 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 6 \tTotal: 1002.5521 \tMean_train_accuracy: 0.5691\n",
      "\tMean_test_accuracy: 0.5620 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 7 \tTotal: 995.0504 \tMean_train_accuracy: 0.5768\n",
      "\tMean_test_accuracy: 0.5630 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 8 \tTotal: 992.1504 \tMean_train_accuracy: 0.5847\n",
      "\tMean_test_accuracy: 0.5685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 9 \tTotal: 983.7546 \tMean_train_accuracy: 0.5716\n",
      "\tMean_test_accuracy: 0.5710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 10 \tTotal: 978.1648 \tMean_train_accuracy: 0.5703\n",
      "\tMean_test_accuracy: 0.5675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 11 \tTotal: 970.2751 \tMean_train_accuracy: 0.5802\n",
      "\tMean_test_accuracy: 0.5665 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 12 \tTotal: 963.8917 \tMean_train_accuracy: 0.5824\n",
      "\tMean_test_accuracy: 0.5655 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 13 \tTotal: 959.2948 \tMean_train_accuracy: 0.5936\n",
      "\tMean_test_accuracy: 0.5755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 14 \tTotal: 954.8149 \tMean_train_accuracy: 0.5866\n",
      "\tMean_test_accuracy: 0.5715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 15 \tTotal: 949.2496 \tMean_train_accuracy: 0.5916\n",
      "\tMean_test_accuracy: 0.5795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 16 \tTotal: 944.4307 \tMean_train_accuracy: 0.5853\n",
      "\tMean_test_accuracy: 0.5800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 17 \tTotal: 942.2370 \tMean_train_accuracy: 0.5903\n",
      "\tMean_test_accuracy: 0.5925 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 18 \tTotal: 942.2458 \tMean_train_accuracy: 0.6012\n",
      "\tMean_test_accuracy: 0.5865 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 19 \tTotal: 934.0756 \tMean_train_accuracy: 0.5936\n",
      "\tMean_test_accuracy: 0.5925 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 20 \tTotal: 929.8614 \tMean_train_accuracy: 0.6099\n",
      "\tMean_test_accuracy: 0.5910 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 21 \tTotal: 927.1285 \tMean_train_accuracy: 0.6009\n",
      "\tMean_test_accuracy: 0.5970 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 22 \tTotal: 924.9586 \tMean_train_accuracy: 0.6091\n",
      "\tMean_test_accuracy: 0.6015 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 23 \tTotal: 919.8294 \tMean_train_accuracy: 0.6102\n",
      "\tMean_test_accuracy: 0.5960 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 24 \tTotal: 915.7745 \tMean_train_accuracy: 0.6184\n",
      "\tMean_test_accuracy: 0.6005 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 25 \tTotal: 912.8462 \tMean_train_accuracy: 0.6094\n",
      "\tMean_test_accuracy: 0.6045 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 26 \tTotal: 907.4874 \tMean_train_accuracy: 0.6142\n",
      "\tMean_test_accuracy: 0.6090 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 27 \tTotal: 904.1076 \tMean_train_accuracy: 0.6189\n",
      "\tMean_test_accuracy: 0.6085 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 28 \tTotal: 899.8242 \tMean_train_accuracy: 0.6212\n",
      "\tMean_test_accuracy: 0.6180 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 29 \tTotal: 896.2332 \tMean_train_accuracy: 0.6157\n",
      "\tMean_test_accuracy: 0.6215 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 30 \tTotal: 893.3301 \tMean_train_accuracy: 0.6229\n",
      "\tMean_test_accuracy: 0.6245 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 31 \tTotal: 887.3652 \tMean_train_accuracy: 0.6332\n",
      "\tMean_test_accuracy: 0.6240 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 32 \tTotal: 884.5115 \tMean_train_accuracy: 0.6332\n",
      "\tMean_test_accuracy: 0.6270 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 33 \tTotal: 879.9412 \tMean_train_accuracy: 0.6316\n",
      "\tMean_test_accuracy: 0.6190 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 34 \tTotal: 877.3674 \tMean_train_accuracy: 0.6288\n",
      "\tMean_test_accuracy: 0.6225 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 35 \tTotal: 874.3309 \tMean_train_accuracy: 0.6282\n",
      "\tMean_test_accuracy: 0.6330 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 36 \tTotal: 870.5146 \tMean_train_accuracy: 0.6269\n",
      "\tMean_test_accuracy: 0.6250 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 37 \tTotal: 867.9682 \tMean_train_accuracy: 0.6446\n",
      "\tMean_test_accuracy: 0.6330 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 38 \tTotal: 864.2073 \tMean_train_accuracy: 0.6342\n",
      "\tMean_test_accuracy: 0.6310 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 39 \tTotal: 862.0640 \tMean_train_accuracy: 0.6457\n",
      "\tMean_test_accuracy: 0.6345 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 40 \tTotal: 859.6410 \tMean_train_accuracy: 0.6394\n",
      "\tMean_test_accuracy: 0.6285 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 41 \tTotal: 855.7790 \tMean_train_accuracy: 0.6497\n",
      "\tMean_test_accuracy: 0.6360 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 42 \tTotal: 852.5032 \tMean_train_accuracy: 0.6478\n",
      "\tMean_test_accuracy: 0.6300 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 43 \tTotal: 848.0916 \tMean_train_accuracy: 0.6418\n",
      "\tMean_test_accuracy: 0.6325 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 44 \tTotal: 842.9483 \tMean_train_accuracy: 0.6466\n",
      "\tMean_test_accuracy: 0.6395 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 45 \tTotal: 836.3555 \tMean_train_accuracy: 0.6317\n",
      "\tMean_test_accuracy: 0.6515 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 46 \tTotal: 833.0467 \tMean_train_accuracy: 0.6609\n",
      "\tMean_test_accuracy: 0.6505 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 47 \tTotal: 830.5381 \tMean_train_accuracy: 0.6551\n",
      "\tMean_test_accuracy: 0.6445 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 48 \tTotal: 825.7406 \tMean_train_accuracy: 0.6549\n",
      "\tMean_test_accuracy: 0.6490 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 49 \tTotal: 823.5312 \tMean_train_accuracy: 0.6601\n",
      "\tMean_test_accuracy: 0.6595 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 50 \tTotal: 821.6461 \tMean_train_accuracy: 0.6565\n",
      "\tMean_test_accuracy: 0.6405 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 51 \tTotal: 820.6731 \tMean_train_accuracy: 0.6515\n",
      "\tMean_test_accuracy: 0.6455 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 52 \tTotal: 814.8964 \tMean_train_accuracy: 0.6619\n",
      "\tMean_test_accuracy: 0.6495 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 53 \tTotal: 812.5620 \tMean_train_accuracy: 0.6541\n",
      "\tMean_test_accuracy: 0.6555 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 54 \tTotal: 810.0770 \tMean_train_accuracy: 0.6549\n",
      "\tMean_test_accuracy: 0.6565 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 55 \tTotal: 810.1239 \tMean_train_accuracy: 0.6624\n",
      "\tMean_test_accuracy: 0.6475 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 56 \tTotal: 807.3398 \tMean_train_accuracy: 0.6519\n",
      "\tMean_test_accuracy: 0.6520 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 57 \tTotal: 804.1108 \tMean_train_accuracy: 0.6581\n",
      "\tMean_test_accuracy: 0.6545 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 58 \tTotal: 801.9760 \tMean_train_accuracy: 0.6541\n",
      "\tMean_test_accuracy: 0.6495 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 59 \tTotal: 800.1840 \tMean_train_accuracy: 0.6609\n",
      "\tMean_test_accuracy: 0.6475 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 60 \tTotal: 798.1042 \tMean_train_accuracy: 0.6545\n",
      "\tMean_test_accuracy: 0.6480 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 61 \tTotal: 797.2228 \tMean_train_accuracy: 0.6587\n",
      "\tMean_test_accuracy: 0.6535 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 62 \tTotal: 795.2361 \tMean_train_accuracy: 0.6489\n",
      "\tMean_test_accuracy: 0.6510 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 63 \tTotal: 793.8812 \tMean_train_accuracy: 0.6590\n",
      "\tMean_test_accuracy: 0.6500 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 64 \tTotal: 792.0374 \tMean_train_accuracy: 0.6597\n",
      "\tMean_test_accuracy: 0.6590 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 65 \tTotal: 790.8019 \tMean_train_accuracy: 0.6513\n",
      "\tMean_test_accuracy: 0.6530 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 66 \tTotal: 789.6038 \tMean_train_accuracy: 0.6585\n",
      "\tMean_test_accuracy: 0.6480 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 67 \tTotal: 788.4645 \tMean_train_accuracy: 0.6450\n",
      "\tMean_test_accuracy: 0.6520 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 68 \tTotal: 786.2561 \tMean_train_accuracy: 0.6595\n",
      "\tMean_test_accuracy: 0.6545 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 69 \tTotal: 784.7615 \tMean_train_accuracy: 0.6537\n",
      "\tMean_test_accuracy: 0.6475 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 70 \tTotal: 784.3869 \tMean_train_accuracy: 0.6542\n",
      "\tMean_test_accuracy: 0.6545 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 71 \tTotal: 782.3005 \tMean_train_accuracy: 0.6537\n",
      "\tMean_test_accuracy: 0.6495 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 72 \tTotal: 781.0934 \tMean_train_accuracy: 0.6598\n",
      "\tMean_test_accuracy: 0.6530 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 73 \tTotal: 779.6711 \tMean_train_accuracy: 0.6629\n",
      "\tMean_test_accuracy: 0.6480 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 74 \tTotal: 778.9755 \tMean_train_accuracy: 0.6591\n",
      "\tMean_test_accuracy: 0.6510 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 75 \tTotal: 777.6767 \tMean_train_accuracy: 0.6601\n",
      "\tMean_test_accuracy: 0.6450 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 76 \tTotal: 776.2216 \tMean_train_accuracy: 0.6616\n",
      "\tMean_test_accuracy: 0.6495 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 77 \tTotal: 776.1629 \tMean_train_accuracy: 0.6521\n",
      "\tMean_test_accuracy: 0.6495 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 78 \tTotal: 775.0092 \tMean_train_accuracy: 0.6559\n",
      "\tMean_test_accuracy: 0.6545 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 79 \tTotal: 773.4021 \tMean_train_accuracy: 0.6582\n",
      "\tMean_test_accuracy: 0.6545 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 80 \tTotal: 773.8451 \tMean_train_accuracy: 0.6541\n",
      "\tMean_test_accuracy: 0.6565 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 81 \tTotal: 770.9199 \tMean_train_accuracy: 0.6595\n",
      "\tMean_test_accuracy: 0.6495 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 82 \tTotal: 770.8762 \tMean_train_accuracy: 0.6648\n",
      "\tMean_test_accuracy: 0.6565 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 83 \tTotal: 768.9425 \tMean_train_accuracy: 0.6608\n",
      "\tMean_test_accuracy: 0.6555 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 84 \tTotal: 767.3503 \tMean_train_accuracy: 0.6600\n",
      "\tMean_test_accuracy: 0.6525 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 85 \tTotal: 766.9180 \tMean_train_accuracy: 0.6532\n",
      "\tMean_test_accuracy: 0.6550 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 86 \tTotal: 765.5905 \tMean_train_accuracy: 0.6574\n",
      "\tMean_test_accuracy: 0.6640 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 87 \tTotal: 764.7457 \tMean_train_accuracy: 0.6630\n",
      "\tMean_test_accuracy: 0.6590 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 88 \tTotal: 764.3157 \tMean_train_accuracy: 0.6591\n",
      "\tMean_test_accuracy: 0.6500 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 89 \tTotal: 763.2982 \tMean_train_accuracy: 0.6599\n",
      "\tMean_test_accuracy: 0.6575 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 90 \tTotal: 761.7293 \tMean_train_accuracy: 0.6643\n",
      "\tMean_test_accuracy: 0.6570 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 91 \tTotal: 760.6794 \tMean_train_accuracy: 0.6714\n",
      "\tMean_test_accuracy: 0.6650 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 92 \tTotal: 759.5963 \tMean_train_accuracy: 0.6607\n",
      "\tMean_test_accuracy: 0.6650 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 93 \tTotal: 758.2831 \tMean_train_accuracy: 0.6682\n",
      "\tMean_test_accuracy: 0.6650 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 94 \tTotal: 757.2387 \tMean_train_accuracy: 0.6688\n",
      "\tMean_test_accuracy: 0.6615 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 95 \tTotal: 755.8353 \tMean_train_accuracy: 0.6624\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 96 \tTotal: 754.3925 \tMean_train_accuracy: 0.6703\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 97 \tTotal: 752.8148 \tMean_train_accuracy: 0.6706\n",
      "\tMean_test_accuracy: 0.6605 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 98 \tTotal: 751.7226 \tMean_train_accuracy: 0.6685\n",
      "\tMean_test_accuracy: 0.6670 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 99 \tTotal: 749.9704 \tMean_train_accuracy: 0.6651\n",
      "\tMean_test_accuracy: 0.6630 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 100 \tTotal: 748.6486 \tMean_train_accuracy: 0.6738\n",
      "\tMean_test_accuracy: 0.6630 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 101 \tTotal: 749.7040 \tMean_train_accuracy: 0.6740\n",
      "\tMean_test_accuracy: 0.6595 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 102 \tTotal: 746.9129 \tMean_train_accuracy: 0.6642\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 103 \tTotal: 747.2414 \tMean_train_accuracy: 0.6673\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 104 \tTotal: 747.7036 \tMean_train_accuracy: 0.6764\n",
      "\tMean_test_accuracy: 0.6635 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 105 \tTotal: 745.1777 \tMean_train_accuracy: 0.6696\n",
      "\tMean_test_accuracy: 0.6570 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 106 \tTotal: 743.3017 \tMean_train_accuracy: 0.6612\n",
      "\tMean_test_accuracy: 0.6665 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 107 \tTotal: 740.9887 \tMean_train_accuracy: 0.6703\n",
      "\tMean_test_accuracy: 0.6625 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 108 \tTotal: 738.1778 \tMean_train_accuracy: 0.6718\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 109 \tTotal: 736.7797 \tMean_train_accuracy: 0.6713\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 110 \tTotal: 735.6313 \tMean_train_accuracy: 0.6736\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 111 \tTotal: 734.5499 \tMean_train_accuracy: 0.6724\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 112 \tTotal: 732.7420 \tMean_train_accuracy: 0.6764\n",
      "\tMean_test_accuracy: 0.6660 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 113 \tTotal: 732.0551 \tMean_train_accuracy: 0.6712\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 114 \tTotal: 731.1202 \tMean_train_accuracy: 0.6590\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 115 \tTotal: 729.3330 \tMean_train_accuracy: 0.6709\n",
      "\tMean_test_accuracy: 0.6690 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 116 \tTotal: 729.7336 \tMean_train_accuracy: 0.6635\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 117 \tTotal: 727.5701 \tMean_train_accuracy: 0.6696\n",
      "\tMean_test_accuracy: 0.6670 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 118 \tTotal: 726.9969 \tMean_train_accuracy: 0.6722\n",
      "\tMean_test_accuracy: 0.6665 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 119 \tTotal: 725.2424 \tMean_train_accuracy: 0.6703\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 120 \tTotal: 723.9496 \tMean_train_accuracy: 0.6633\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 121 \tTotal: 722.5519 \tMean_train_accuracy: 0.6718\n",
      "\tMean_test_accuracy: 0.6655 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 122 \tTotal: 722.0780 \tMean_train_accuracy: 0.6769\n",
      "\tMean_test_accuracy: 0.6670 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 123 \tTotal: 720.7271 \tMean_train_accuracy: 0.6742\n",
      "\tMean_test_accuracy: 0.6690 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 124 \tTotal: 719.6973 \tMean_train_accuracy: 0.6591\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 125 \tTotal: 720.1543 \tMean_train_accuracy: 0.6823\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 126 \tTotal: 719.8281 \tMean_train_accuracy: 0.6749\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 127 \tTotal: 718.0090 \tMean_train_accuracy: 0.6624\n",
      "\tMean_test_accuracy: 0.6690 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 128 \tTotal: 721.2355 \tMean_train_accuracy: 0.6765\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 129 \tTotal: 720.1001 \tMean_train_accuracy: 0.6804\n",
      "\tMean_test_accuracy: 0.6630 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 130 \tTotal: 717.6254 \tMean_train_accuracy: 0.6695\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 131 \tTotal: 713.4012 \tMean_train_accuracy: 0.6749\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 132 \tTotal: 711.9942 \tMean_train_accuracy: 0.6751\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 133 \tTotal: 711.5934 \tMean_train_accuracy: 0.6777\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 134 \tTotal: 711.6780 \tMean_train_accuracy: 0.6769\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 135 \tTotal: 709.1593 \tMean_train_accuracy: 0.6748\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 136 \tTotal: 708.3975 \tMean_train_accuracy: 0.6774\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 137 \tTotal: 707.1043 \tMean_train_accuracy: 0.6802\n",
      "\tMean_test_accuracy: 0.6665 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 138 \tTotal: 707.9414 \tMean_train_accuracy: 0.6716\n",
      "\tMean_test_accuracy: 0.6665 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 139 \tTotal: 705.8283 \tMean_train_accuracy: 0.6744\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 140 \tTotal: 705.4388 \tMean_train_accuracy: 0.6791\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 141 \tTotal: 704.8617 \tMean_train_accuracy: 0.6797\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 142 \tTotal: 703.4129 \tMean_train_accuracy: 0.6748\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 143 \tTotal: 702.5852 \tMean_train_accuracy: 0.6783\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 144 \tTotal: 701.8787 \tMean_train_accuracy: 0.6819\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 145 \tTotal: 704.0758 \tMean_train_accuracy: 0.6634\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 146 \tTotal: 703.2586 \tMean_train_accuracy: 0.6718\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 147 \tTotal: 702.8221 \tMean_train_accuracy: 0.6862\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 148 \tTotal: 701.0519 \tMean_train_accuracy: 0.6780\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 149 \tTotal: 699.0670 \tMean_train_accuracy: 0.6751\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 150 \tTotal: 698.7670 \tMean_train_accuracy: 0.6755\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 151 \tTotal: 696.5487 \tMean_train_accuracy: 0.6698\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 152 \tTotal: 695.7765 \tMean_train_accuracy: 0.6738\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 153 \tTotal: 695.1663 \tMean_train_accuracy: 0.6793\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 154 \tTotal: 694.6810 \tMean_train_accuracy: 0.6829\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 155 \tTotal: 693.3087 \tMean_train_accuracy: 0.6744\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 156 \tTotal: 693.7198 \tMean_train_accuracy: 0.6737\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 157 \tTotal: 692.7813 \tMean_train_accuracy: 0.6821\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 158 \tTotal: 693.5364 \tMean_train_accuracy: 0.6813\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 159 \tTotal: 692.2914 \tMean_train_accuracy: 0.6697\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 160 \tTotal: 692.1399 \tMean_train_accuracy: 0.6848\n",
      "\tMean_test_accuracy: 0.6660 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 161 \tTotal: 690.7317 \tMean_train_accuracy: 0.6796\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 162 \tTotal: 691.0532 \tMean_train_accuracy: 0.6720\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 163 \tTotal: 690.7275 \tMean_train_accuracy: 0.6818\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 164 \tTotal: 690.2723 \tMean_train_accuracy: 0.6839\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 165 \tTotal: 689.1640 \tMean_train_accuracy: 0.6767\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 166 \tTotal: 688.2678 \tMean_train_accuracy: 0.6808\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 167 \tTotal: 687.9788 \tMean_train_accuracy: 0.6817\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 168 \tTotal: 686.6749 \tMean_train_accuracy: 0.6825\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 169 \tTotal: 686.9026 \tMean_train_accuracy: 0.6741\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 170 \tTotal: 685.8906 \tMean_train_accuracy: 0.6782\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 171 \tTotal: 685.5193 \tMean_train_accuracy: 0.6782\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 172 \tTotal: 684.6226 \tMean_train_accuracy: 0.6804\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 173 \tTotal: 685.1676 \tMean_train_accuracy: 0.6739\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 174 \tTotal: 684.5998 \tMean_train_accuracy: 0.6770\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 175 \tTotal: 683.8407 \tMean_train_accuracy: 0.6839\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 176 \tTotal: 682.5301 \tMean_train_accuracy: 0.6797\n",
      "\tMean_test_accuracy: 0.6660 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 177 \tTotal: 682.1290 \tMean_train_accuracy: 0.6750\n",
      "\tMean_test_accuracy: 0.6825 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 178 \tTotal: 681.7965 \tMean_train_accuracy: 0.6796\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 179 \tTotal: 680.3198 \tMean_train_accuracy: 0.6832\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 180 \tTotal: 683.4888 \tMean_train_accuracy: 0.6884\n",
      "\tMean_test_accuracy: 0.6835 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 181 \tTotal: 681.0632 \tMean_train_accuracy: 0.6790\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 182 \tTotal: 681.7503 \tMean_train_accuracy: 0.6792\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 183 \tTotal: 679.7181 \tMean_train_accuracy: 0.6869\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 184 \tTotal: 677.5881 \tMean_train_accuracy: 0.6831\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 185 \tTotal: 677.2181 \tMean_train_accuracy: 0.6780\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 186 \tTotal: 678.4822 \tMean_train_accuracy: 0.6888\n",
      "\tMean_test_accuracy: 0.6640 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 187 \tTotal: 677.0072 \tMean_train_accuracy: 0.6882\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 188 \tTotal: 677.3755 \tMean_train_accuracy: 0.6856\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 189 \tTotal: 675.4160 \tMean_train_accuracy: 0.6779\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 190 \tTotal: 673.8210 \tMean_train_accuracy: 0.6899\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 191 \tTotal: 673.3027 \tMean_train_accuracy: 0.6774\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 192 \tTotal: 675.3390 \tMean_train_accuracy: 0.6905\n",
      "\tMean_test_accuracy: 0.6665 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 193 \tTotal: 673.9444 \tMean_train_accuracy: 0.6866\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 194 \tTotal: 673.0257 \tMean_train_accuracy: 0.6869\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 195 \tTotal: 671.9339 \tMean_train_accuracy: 0.6881\n",
      "\tMean_test_accuracy: 0.6660 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 196 \tTotal: 671.3336 \tMean_train_accuracy: 0.6860\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 197 \tTotal: 670.3529 \tMean_train_accuracy: 0.6874\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 198 \tTotal: 669.5308 \tMean_train_accuracy: 0.6851\n",
      "\tMean_test_accuracy: 0.6655 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 199 \tTotal: 668.9471 \tMean_train_accuracy: 0.6863\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 200 \tTotal: 668.9083 \tMean_train_accuracy: 0.6808\n",
      "\tMean_test_accuracy: 0.6655 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 201 \tTotal: 669.4932 \tMean_train_accuracy: 0.6877\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 202 \tTotal: 667.8039 \tMean_train_accuracy: 0.6931\n",
      "\tMean_test_accuracy: 0.6620 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 203 \tTotal: 668.3409 \tMean_train_accuracy: 0.6926\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 204 \tTotal: 669.8147 \tMean_train_accuracy: 0.6907\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 205 \tTotal: 668.7432 \tMean_train_accuracy: 0.6891\n",
      "\tMean_test_accuracy: 0.6850 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 206 \tTotal: 665.9430 \tMean_train_accuracy: 0.6886\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 207 \tTotal: 664.9525 \tMean_train_accuracy: 0.6882\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 208 \tTotal: 664.1132 \tMean_train_accuracy: 0.6934\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 209 \tTotal: 662.7684 \tMean_train_accuracy: 0.6881\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 210 \tTotal: 662.8403 \tMean_train_accuracy: 0.6914\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 211 \tTotal: 662.1696 \tMean_train_accuracy: 0.6809\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 212 \tTotal: 662.4095 \tMean_train_accuracy: 0.6876\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 213 \tTotal: 660.9695 \tMean_train_accuracy: 0.6931\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 214 \tTotal: 660.3120 \tMean_train_accuracy: 0.6843\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 215 \tTotal: 659.3785 \tMean_train_accuracy: 0.6794\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 216 \tTotal: 658.6780 \tMean_train_accuracy: 0.6893\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 217 \tTotal: 659.1494 \tMean_train_accuracy: 0.6806\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 218 \tTotal: 658.5963 \tMean_train_accuracy: 0.6916\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 219 \tTotal: 658.4848 \tMean_train_accuracy: 0.6949\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 220 \tTotal: 658.3683 \tMean_train_accuracy: 0.6815\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 221 \tTotal: 656.9772 \tMean_train_accuracy: 0.6956\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 222 \tTotal: 656.8756 \tMean_train_accuracy: 0.6868\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 223 \tTotal: 656.3458 \tMean_train_accuracy: 0.6827\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 224 \tTotal: 655.6750 \tMean_train_accuracy: 0.6759\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 225 \tTotal: 657.8539 \tMean_train_accuracy: 0.6822\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 226 \tTotal: 655.3070 \tMean_train_accuracy: 0.6817\n",
      "\tMean_test_accuracy: 0.6825 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 227 \tTotal: 653.0894 \tMean_train_accuracy: 0.6867\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 228 \tTotal: 651.9083 \tMean_train_accuracy: 0.6887\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 229 \tTotal: 651.9924 \tMean_train_accuracy: 0.6971\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 230 \tTotal: 651.3467 \tMean_train_accuracy: 0.6864\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 231 \tTotal: 651.1043 \tMean_train_accuracy: 0.6879\n",
      "\tMean_test_accuracy: 0.6875 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 232 \tTotal: 652.1473 \tMean_train_accuracy: 0.6804\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 233 \tTotal: 652.4300 \tMean_train_accuracy: 0.6952\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 234 \tTotal: 651.2789 \tMean_train_accuracy: 0.6883\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 235 \tTotal: 649.0339 \tMean_train_accuracy: 0.6865\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 236 \tTotal: 649.6540 \tMean_train_accuracy: 0.6852\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 237 \tTotal: 648.6930 \tMean_train_accuracy: 0.6878\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 238 \tTotal: 647.4706 \tMean_train_accuracy: 0.6900\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 239 \tTotal: 647.5246 \tMean_train_accuracy: 0.6905\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 240 \tTotal: 645.3606 \tMean_train_accuracy: 0.6909\n",
      "\tMean_test_accuracy: 0.6830 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 241 \tTotal: 644.5181 \tMean_train_accuracy: 0.6833\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 242 \tTotal: 645.0783 \tMean_train_accuracy: 0.6964\n",
      "\tMean_test_accuracy: 0.6670 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 243 \tTotal: 644.3855 \tMean_train_accuracy: 0.6890\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 244 \tTotal: 643.4118 \tMean_train_accuracy: 0.6854\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 245 \tTotal: 641.9523 \tMean_train_accuracy: 0.6891\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 246 \tTotal: 641.6587 \tMean_train_accuracy: 0.6918\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 247 \tTotal: 641.8774 \tMean_train_accuracy: 0.6892\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 248 \tTotal: 643.7035 \tMean_train_accuracy: 0.6868\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 249 \tTotal: 642.8904 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 250 \tTotal: 640.8608 \tMean_train_accuracy: 0.6818\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 251 \tTotal: 641.1535 \tMean_train_accuracy: 0.6805\n",
      "\tMean_test_accuracy: 0.6935 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 252 \tTotal: 640.8709 \tMean_train_accuracy: 0.6903\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 253 \tTotal: 644.8565 \tMean_train_accuracy: 0.6987\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 254 \tTotal: 644.8206 \tMean_train_accuracy: 0.6873\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 255 \tTotal: 642.2202 \tMean_train_accuracy: 0.6947\n",
      "\tMean_test_accuracy: 0.6560 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 256 \tTotal: 642.4350 \tMean_train_accuracy: 0.6731\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 257 \tTotal: 639.1147 \tMean_train_accuracy: 0.6934\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 258 \tTotal: 636.8142 \tMean_train_accuracy: 0.6855\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 259 \tTotal: 636.6219 \tMean_train_accuracy: 0.6901\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 260 \tTotal: 636.7546 \tMean_train_accuracy: 0.6931\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 261 \tTotal: 634.5815 \tMean_train_accuracy: 0.6917\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 262 \tTotal: 634.3089 \tMean_train_accuracy: 0.6887\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 263 \tTotal: 633.3237 \tMean_train_accuracy: 0.6913\n",
      "\tMean_test_accuracy: 0.6690 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 264 \tTotal: 633.5068 \tMean_train_accuracy: 0.6814\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 265 \tTotal: 633.2259 \tMean_train_accuracy: 0.6957\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 266 \tTotal: 635.2312 \tMean_train_accuracy: 0.6837\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 267 \tTotal: 633.3282 \tMean_train_accuracy: 0.6926\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 268 \tTotal: 631.8340 \tMean_train_accuracy: 0.6846\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 269 \tTotal: 630.4427 \tMean_train_accuracy: 0.6903\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 270 \tTotal: 630.2452 \tMean_train_accuracy: 0.6785\n",
      "\tMean_test_accuracy: 0.6830 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 271 \tTotal: 629.8832 \tMean_train_accuracy: 0.6862\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 272 \tTotal: 629.3597 \tMean_train_accuracy: 0.6897\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 273 \tTotal: 628.5541 \tMean_train_accuracy: 0.6927\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 274 \tTotal: 629.4277 \tMean_train_accuracy: 0.6888\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 275 \tTotal: 627.9395 \tMean_train_accuracy: 0.6913\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 276 \tTotal: 627.1207 \tMean_train_accuracy: 0.6846\n",
      "\tMean_test_accuracy: 0.6855 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 277 \tTotal: 627.5448 \tMean_train_accuracy: 0.6829\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 278 \tTotal: 626.5607 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 279 \tTotal: 625.4359 \tMean_train_accuracy: 0.6848\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 280 \tTotal: 625.5458 \tMean_train_accuracy: 0.7004\n",
      "\tMean_test_accuracy: 0.6600 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 281 \tTotal: 624.4629 \tMean_train_accuracy: 0.6947\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 282 \tTotal: 624.3606 \tMean_train_accuracy: 0.6811\n",
      "\tMean_test_accuracy: 0.6825 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 283 \tTotal: 624.5519 \tMean_train_accuracy: 0.6932\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 284 \tTotal: 623.2322 \tMean_train_accuracy: 0.6814\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 285 \tTotal: 623.2383 \tMean_train_accuracy: 0.6909\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 286 \tTotal: 624.5472 \tMean_train_accuracy: 0.6916\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 287 \tTotal: 624.5201 \tMean_train_accuracy: 0.6911\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 288 \tTotal: 621.7915 \tMean_train_accuracy: 0.6848\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 289 \tTotal: 620.1337 \tMean_train_accuracy: 0.6969\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 290 \tTotal: 619.0385 \tMean_train_accuracy: 0.6869\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 291 \tTotal: 620.1466 \tMean_train_accuracy: 0.6836\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 292 \tTotal: 621.2233 \tMean_train_accuracy: 0.6746\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 293 \tTotal: 619.5216 \tMean_train_accuracy: 0.6901\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 294 \tTotal: 617.6999 \tMean_train_accuracy: 0.6954\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 295 \tTotal: 616.8780 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 296 \tTotal: 617.9526 \tMean_train_accuracy: 0.6967\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 297 \tTotal: 617.4435 \tMean_train_accuracy: 0.6849\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 298 \tTotal: 617.1949 \tMean_train_accuracy: 0.6791\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 299 \tTotal: 616.7218 \tMean_train_accuracy: 0.6957\n",
      "\tMean_test_accuracy: 0.6610 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 300 \tTotal: 615.8322 \tMean_train_accuracy: 0.6867\n",
      "\tMean_test_accuracy: 0.6630 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 301 \tTotal: 615.5695 \tMean_train_accuracy: 0.6875\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 302 \tTotal: 613.5074 \tMean_train_accuracy: 0.6949\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 303 \tTotal: 613.4618 \tMean_train_accuracy: 0.6903\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 304 \tTotal: 612.9855 \tMean_train_accuracy: 0.6916\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 305 \tTotal: 612.7230 \tMean_train_accuracy: 0.6936\n",
      "\tMean_test_accuracy: 0.6640 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 306 \tTotal: 612.3213 \tMean_train_accuracy: 0.6879\n",
      "\tMean_test_accuracy: 0.6860 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 307 \tTotal: 612.6792 \tMean_train_accuracy: 0.6959\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 308 \tTotal: 611.4172 \tMean_train_accuracy: 0.6967\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 309 \tTotal: 611.2146 \tMean_train_accuracy: 0.6816\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 310 \tTotal: 610.7664 \tMean_train_accuracy: 0.6931\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 311 \tTotal: 609.8878 \tMean_train_accuracy: 0.6942\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 312 \tTotal: 609.1533 \tMean_train_accuracy: 0.6920\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 313 \tTotal: 608.2826 \tMean_train_accuracy: 0.6886\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 314 \tTotal: 608.3711 \tMean_train_accuracy: 0.6872\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 315 \tTotal: 607.7548 \tMean_train_accuracy: 0.6870\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 316 \tTotal: 609.0951 \tMean_train_accuracy: 0.6959\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 317 \tTotal: 607.2131 \tMean_train_accuracy: 0.6784\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 318 \tTotal: 610.5851 \tMean_train_accuracy: 0.6842\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 319 \tTotal: 606.6839 \tMean_train_accuracy: 0.6957\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 320 \tTotal: 606.2369 \tMean_train_accuracy: 0.6924\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 321 \tTotal: 606.3313 \tMean_train_accuracy: 0.6877\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 322 \tTotal: 604.2620 \tMean_train_accuracy: 0.6873\n",
      "\tMean_test_accuracy: 0.6600 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 323 \tTotal: 606.3601 \tMean_train_accuracy: 0.6953\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 324 \tTotal: 604.9544 \tMean_train_accuracy: 0.6848\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 325 \tTotal: 602.9539 \tMean_train_accuracy: 0.6903\n",
      "\tMean_test_accuracy: 0.6670 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 326 \tTotal: 603.6555 \tMean_train_accuracy: 0.6966\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 327 \tTotal: 602.2756 \tMean_train_accuracy: 0.6834\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 328 \tTotal: 601.4285 \tMean_train_accuracy: 0.6970\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 329 \tTotal: 600.9217 \tMean_train_accuracy: 0.6924\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 330 \tTotal: 600.4462 \tMean_train_accuracy: 0.6893\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 331 \tTotal: 600.3694 \tMean_train_accuracy: 0.6905\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 332 \tTotal: 600.7720 \tMean_train_accuracy: 0.6919\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 333 \tTotal: 599.2703 \tMean_train_accuracy: 0.6886\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 334 \tTotal: 599.6003 \tMean_train_accuracy: 0.6881\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 335 \tTotal: 598.2272 \tMean_train_accuracy: 0.6876\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 336 \tTotal: 599.5239 \tMean_train_accuracy: 0.6901\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 337 \tTotal: 598.3930 \tMean_train_accuracy: 0.6920\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 338 \tTotal: 598.4194 \tMean_train_accuracy: 0.6920\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 339 \tTotal: 599.6536 \tMean_train_accuracy: 0.6793\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 340 \tTotal: 597.2441 \tMean_train_accuracy: 0.6967\n",
      "\tMean_test_accuracy: 0.6710 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 341 \tTotal: 596.1091 \tMean_train_accuracy: 0.6838\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 342 \tTotal: 595.7378 \tMean_train_accuracy: 0.6902\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 343 \tTotal: 594.9554 \tMean_train_accuracy: 0.6856\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 344 \tTotal: 594.6551 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 345 \tTotal: 594.3761 \tMean_train_accuracy: 0.6884\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 346 \tTotal: 594.2101 \tMean_train_accuracy: 0.6856\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 347 \tTotal: 593.8891 \tMean_train_accuracy: 0.6842\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 348 \tTotal: 594.8218 \tMean_train_accuracy: 0.6846\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 349 \tTotal: 597.5978 \tMean_train_accuracy: 0.6864\n",
      "\tMean_test_accuracy: 0.6615 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 350 \tTotal: 593.6951 \tMean_train_accuracy: 0.6841\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 351 \tTotal: 593.0590 \tMean_train_accuracy: 0.6833\n",
      "\tMean_test_accuracy: 0.6625 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 352 \tTotal: 592.1894 \tMean_train_accuracy: 0.6896\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 353 \tTotal: 591.7740 \tMean_train_accuracy: 0.6922\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 354 \tTotal: 590.6841 \tMean_train_accuracy: 0.6814\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 355 \tTotal: 590.1749 \tMean_train_accuracy: 0.6870\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 356 \tTotal: 589.6318 \tMean_train_accuracy: 0.6902\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 357 \tTotal: 589.6169 \tMean_train_accuracy: 0.6802\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 358 \tTotal: 589.7303 \tMean_train_accuracy: 0.6904\n",
      "\tMean_test_accuracy: 0.6690 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 359 \tTotal: 588.4611 \tMean_train_accuracy: 0.6946\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 360 \tTotal: 588.1061 \tMean_train_accuracy: 0.6914\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 361 \tTotal: 587.5644 \tMean_train_accuracy: 0.6866\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 362 \tTotal: 587.8169 \tMean_train_accuracy: 0.6857\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 363 \tTotal: 587.2838 \tMean_train_accuracy: 0.6795\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 364 \tTotal: 589.0010 \tMean_train_accuracy: 0.6763\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 365 \tTotal: 589.8089 \tMean_train_accuracy: 0.6932\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 366 \tTotal: 590.6046 \tMean_train_accuracy: 0.6855\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 367 \tTotal: 591.2716 \tMean_train_accuracy: 0.6919\n",
      "\tMean_test_accuracy: 0.6525 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 368 \tTotal: 589.7429 \tMean_train_accuracy: 0.6740\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 369 \tTotal: 586.3205 \tMean_train_accuracy: 0.6968\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 370 \tTotal: 585.2361 \tMean_train_accuracy: 0.6899\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 371 \tTotal: 584.3406 \tMean_train_accuracy: 0.6803\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 372 \tTotal: 583.7669 \tMean_train_accuracy: 0.6859\n",
      "\tMean_test_accuracy: 0.6830 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 373 \tTotal: 582.8838 \tMean_train_accuracy: 0.6893\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 374 \tTotal: 582.6953 \tMean_train_accuracy: 0.6893\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 375 \tTotal: 581.9491 \tMean_train_accuracy: 0.6952\n",
      "\tMean_test_accuracy: 0.6845 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 376 \tTotal: 581.7585 \tMean_train_accuracy: 0.6889\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 377 \tTotal: 580.7781 \tMean_train_accuracy: 0.6842\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 378 \tTotal: 580.4179 \tMean_train_accuracy: 0.6946\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 379 \tTotal: 579.1821 \tMean_train_accuracy: 0.6882\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 380 \tTotal: 579.2353 \tMean_train_accuracy: 0.6857\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 381 \tTotal: 578.2730 \tMean_train_accuracy: 0.6881\n",
      "\tMean_test_accuracy: 0.6835 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 382 \tTotal: 577.7001 \tMean_train_accuracy: 0.6957\n",
      "\tMean_test_accuracy: 0.6850 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 383 \tTotal: 577.0509 \tMean_train_accuracy: 0.6834\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 384 \tTotal: 575.3452 \tMean_train_accuracy: 0.6814\n",
      "\tMean_test_accuracy: 0.6635 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 385 \tTotal: 574.7528 \tMean_train_accuracy: 0.6919\n",
      "\tMean_test_accuracy: 0.6700 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 386 \tTotal: 573.0592 \tMean_train_accuracy: 0.6942\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 387 \tTotal: 571.4368 \tMean_train_accuracy: 0.6881\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 388 \tTotal: 569.6066 \tMean_train_accuracy: 0.6822\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 389 \tTotal: 567.7624 \tMean_train_accuracy: 0.6944\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 390 \tTotal: 566.4490 \tMean_train_accuracy: 0.6934\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 391 \tTotal: 564.5795 \tMean_train_accuracy: 0.6857\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 392 \tTotal: 562.9532 \tMean_train_accuracy: 0.6865\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 393 \tTotal: 559.6317 \tMean_train_accuracy: 0.6809\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 394 \tTotal: 558.0864 \tMean_train_accuracy: 0.7006\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 395 \tTotal: 556.5245 \tMean_train_accuracy: 0.6891\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 396 \tTotal: 553.2421 \tMean_train_accuracy: 0.6842\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 397 \tTotal: 550.0822 \tMean_train_accuracy: 0.6823\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 398 \tTotal: 545.2999 \tMean_train_accuracy: 0.6907\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 399 \tTotal: 541.0160 \tMean_train_accuracy: 0.6915\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 400 \tTotal: 539.1453 \tMean_train_accuracy: 0.6890\n",
      "\tMean_test_accuracy: 0.6610 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 401 \tTotal: 535.4049 \tMean_train_accuracy: 0.6806\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 402 \tTotal: 534.1817 \tMean_train_accuracy: 0.6905\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 403 \tTotal: 532.3797 \tMean_train_accuracy: 0.6924\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 404 \tTotal: 530.2495 \tMean_train_accuracy: 0.6891\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 405 \tTotal: 527.8146 \tMean_train_accuracy: 0.6863\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 406 \tTotal: 526.4566 \tMean_train_accuracy: 0.6937\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 407 \tTotal: 524.8385 \tMean_train_accuracy: 0.6924\n",
      "\tMean_test_accuracy: 0.6690 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 408 \tTotal: 523.0466 \tMean_train_accuracy: 0.6848\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 409 \tTotal: 521.5856 \tMean_train_accuracy: 0.6862\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 410 \tTotal: 520.3440 \tMean_train_accuracy: 0.6864\n",
      "\tMean_test_accuracy: 0.6860 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 411 \tTotal: 519.3728 \tMean_train_accuracy: 0.6873\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 412 \tTotal: 518.0801 \tMean_train_accuracy: 0.6919\n",
      "\tMean_test_accuracy: 0.6795 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 413 \tTotal: 516.6981 \tMean_train_accuracy: 0.6907\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 414 \tTotal: 517.1934 \tMean_train_accuracy: 0.6981\n",
      "\tMean_test_accuracy: 0.6680 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 415 \tTotal: 515.4032 \tMean_train_accuracy: 0.6945\n",
      "\tMean_test_accuracy: 0.6655 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 416 \tTotal: 514.4070 \tMean_train_accuracy: 0.6930\n",
      "\tMean_test_accuracy: 0.6645 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 417 \tTotal: 515.9519 \tMean_train_accuracy: 0.6908\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 418 \tTotal: 514.2350 \tMean_train_accuracy: 0.6901\n",
      "\tMean_test_accuracy: 0.6740 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 419 \tTotal: 513.5652 \tMean_train_accuracy: 0.6919\n",
      "\tMean_test_accuracy: 0.6635 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 420 \tTotal: 511.7044 \tMean_train_accuracy: 0.6902\n",
      "\tMean_test_accuracy: 0.6705 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 421 \tTotal: 511.1108 \tMean_train_accuracy: 0.6922\n",
      "\tMean_test_accuracy: 0.6675 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 422 \tTotal: 510.7186 \tMean_train_accuracy: 0.6923\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 423 \tTotal: 510.2092 \tMean_train_accuracy: 0.6962\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 424 \tTotal: 508.2393 \tMean_train_accuracy: 0.6954\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 425 \tTotal: 506.4820 \tMean_train_accuracy: 0.6991\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 426 \tTotal: 506.6281 \tMean_train_accuracy: 0.6916\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 427 \tTotal: 505.0820 \tMean_train_accuracy: 0.6897\n",
      "\tMean_test_accuracy: 0.6895 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 428 \tTotal: 504.6932 \tMean_train_accuracy: 0.6938\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 429 \tTotal: 504.6807 \tMean_train_accuracy: 0.6853\n",
      "\tMean_test_accuracy: 0.6880 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 430 \tTotal: 502.9830 \tMean_train_accuracy: 0.6908\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 431 \tTotal: 502.5501 \tMean_train_accuracy: 0.6937\n",
      "\tMean_test_accuracy: 0.6855 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 432 \tTotal: 502.2509 \tMean_train_accuracy: 0.6996\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 433 \tTotal: 501.7255 \tMean_train_accuracy: 0.6966\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 434 \tTotal: 501.7426 \tMean_train_accuracy: 0.6946\n",
      "\tMean_test_accuracy: 0.6650 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 435 \tTotal: 502.1037 \tMean_train_accuracy: 0.6901\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 436 \tTotal: 500.8260 \tMean_train_accuracy: 0.6976\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 437 \tTotal: 501.8222 \tMean_train_accuracy: 0.6893\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 438 \tTotal: 499.2261 \tMean_train_accuracy: 0.6912\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 439 \tTotal: 498.0241 \tMean_train_accuracy: 0.6862\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 440 \tTotal: 497.3769 \tMean_train_accuracy: 0.6901\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 441 \tTotal: 496.8938 \tMean_train_accuracy: 0.6977\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 442 \tTotal: 496.0022 \tMean_train_accuracy: 0.6908\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 443 \tTotal: 496.3726 \tMean_train_accuracy: 0.6983\n",
      "\tMean_test_accuracy: 0.6715 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 444 \tTotal: 494.9633 \tMean_train_accuracy: 0.6945\n",
      "\tMean_test_accuracy: 0.6790 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 445 \tTotal: 494.0290 \tMean_train_accuracy: 0.6904\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 446 \tTotal: 493.5359 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 447 \tTotal: 493.3495 \tMean_train_accuracy: 0.6979\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 448 \tTotal: 493.6369 \tMean_train_accuracy: 0.6895\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 449 \tTotal: 493.7308 \tMean_train_accuracy: 0.6960\n",
      "\tMean_test_accuracy: 0.6850 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 450 \tTotal: 493.6623 \tMean_train_accuracy: 0.6936\n",
      "\tMean_test_accuracy: 0.6890 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 451 \tTotal: 490.5521 \tMean_train_accuracy: 0.6918\n",
      "\tMean_test_accuracy: 0.6735 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 452 \tTotal: 491.4949 \tMean_train_accuracy: 0.6904\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 453 \tTotal: 490.6100 \tMean_train_accuracy: 0.6887\n",
      "\tMean_test_accuracy: 0.6835 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 454 \tTotal: 489.9708 \tMean_train_accuracy: 0.6897\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 455 \tTotal: 489.5661 \tMean_train_accuracy: 0.6923\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 456 \tTotal: 489.4641 \tMean_train_accuracy: 0.6997\n",
      "\tMean_test_accuracy: 0.6720 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 457 \tTotal: 490.2557 \tMean_train_accuracy: 0.6986\n",
      "\tMean_test_accuracy: 0.6825 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 458 \tTotal: 489.5291 \tMean_train_accuracy: 0.6985\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 459 \tTotal: 488.6360 \tMean_train_accuracy: 0.6919\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 460 \tTotal: 488.1829 \tMean_train_accuracy: 0.6913\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 461 \tTotal: 488.5509 \tMean_train_accuracy: 0.6939\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 462 \tTotal: 488.6831 \tMean_train_accuracy: 0.6893\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 463 \tTotal: 488.1684 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6695 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 464 \tTotal: 485.7684 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6835 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 465 \tTotal: 485.2154 \tMean_train_accuracy: 0.6991\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 466 \tTotal: 484.4703 \tMean_train_accuracy: 0.6944\n",
      "\tMean_test_accuracy: 0.6870 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 467 \tTotal: 483.6795 \tMean_train_accuracy: 0.6915\n",
      "\tMean_test_accuracy: 0.6745 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 468 \tTotal: 483.5647 \tMean_train_accuracy: 0.6972\n",
      "\tMean_test_accuracy: 0.6685 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 469 \tTotal: 482.7256 \tMean_train_accuracy: 0.6974\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 470 \tTotal: 482.1311 \tMean_train_accuracy: 0.7017\n",
      "\tMean_test_accuracy: 0.6660 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 471 \tTotal: 483.3900 \tMean_train_accuracy: 0.6978\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 472 \tTotal: 481.8184 \tMean_train_accuracy: 0.7046\n",
      "\tMean_test_accuracy: 0.6875 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 473 \tTotal: 481.8030 \tMean_train_accuracy: 0.6982\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 474 \tTotal: 482.0988 \tMean_train_accuracy: 0.7005\n",
      "\tMean_test_accuracy: 0.6690 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 475 \tTotal: 481.6581 \tMean_train_accuracy: 0.6916\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 476 \tTotal: 480.4430 \tMean_train_accuracy: 0.6941\n",
      "\tMean_test_accuracy: 0.6775 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 477 \tTotal: 479.3836 \tMean_train_accuracy: 0.6987\n",
      "\tMean_test_accuracy: 0.6750 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 478 \tTotal: 479.2247 \tMean_train_accuracy: 0.6969\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 479 \tTotal: 479.5505 \tMean_train_accuracy: 0.6985\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 480 \tTotal: 479.2566 \tMean_train_accuracy: 0.6964\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 481 \tTotal: 478.0443 \tMean_train_accuracy: 0.6926\n",
      "\tMean_test_accuracy: 0.6875 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 482 \tTotal: 478.2970 \tMean_train_accuracy: 0.6847\n",
      "\tMean_test_accuracy: 0.6770 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 483 \tTotal: 478.6012 \tMean_train_accuracy: 0.7007\n",
      "\tMean_test_accuracy: 0.6855 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 484 \tTotal: 478.0159 \tMean_train_accuracy: 0.7008\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 485 \tTotal: 477.1979 \tMean_train_accuracy: 0.6960\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 486 \tTotal: 476.3456 \tMean_train_accuracy: 0.6947\n",
      "\tMean_test_accuracy: 0.6825 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 487 \tTotal: 476.9964 \tMean_train_accuracy: 0.7019\n",
      "\tMean_test_accuracy: 0.6780 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 488 \tTotal: 477.7878 \tMean_train_accuracy: 0.6872\n",
      "\tMean_test_accuracy: 0.6910 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 489 \tTotal: 477.9129 \tMean_train_accuracy: 0.6916\n",
      "\tMean_test_accuracy: 0.6785 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 490 \tTotal: 476.2148 \tMean_train_accuracy: 0.6941\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 491 \tTotal: 475.1963 \tMean_train_accuracy: 0.6953\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 492 \tTotal: 475.4158 \tMean_train_accuracy: 0.6984\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 493 \tTotal: 474.4563 \tMean_train_accuracy: 0.6914\n",
      "\tMean_test_accuracy: 0.6810 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 494 \tTotal: 473.2769 \tMean_train_accuracy: 0.6926\n",
      "\tMean_test_accuracy: 0.6760 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 495 \tTotal: 473.1862 \tMean_train_accuracy: 0.6929\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 496 \tTotal: 472.5128 \tMean_train_accuracy: 0.6963\n",
      "\tMean_test_accuracy: 0.6765 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 497 \tTotal: 471.9130 \tMean_train_accuracy: 0.6980\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 498 \tTotal: 471.3450 \tMean_train_accuracy: 0.7007\n",
      "\tMean_test_accuracy: 0.6815 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 499 \tTotal: 472.0383 \tMean_train_accuracy: 0.6965\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 500 \tTotal: 471.3566 \tMean_train_accuracy: 0.7009\n",
      "\tMean_test_accuracy: 0.6730 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 501 \tTotal: 471.1914 \tMean_train_accuracy: 0.6996\n",
      "\tMean_test_accuracy: 0.6830 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 502 \tTotal: 470.3376 \tMean_train_accuracy: 0.7006\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 503 \tTotal: 470.3542 \tMean_train_accuracy: 0.6967\n",
      "\tMean_test_accuracy: 0.6805 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 504 \tTotal: 470.9162 \tMean_train_accuracy: 0.6947\n",
      "\tMean_test_accuracy: 0.6665 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 505 \tTotal: 469.2468 \tMean_train_accuracy: 0.7014\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 506 \tTotal: 470.0740 \tMean_train_accuracy: 0.6958\n",
      "\tMean_test_accuracy: 0.6800 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 507 \tTotal: 469.1216 \tMean_train_accuracy: 0.7030\n",
      "\tMean_test_accuracy: 0.6725 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 508 \tTotal: 469.5734 \tMean_train_accuracy: 0.6983\n",
      "\tMean_test_accuracy: 0.6755 \tMean_test_accuracy_sum: 0.5085\n",
      "Epoch: 509 \tTotal: 468.2831 \tMean_train_accuracy: 0.6986\n",
      "\tMean_test_accuracy: 0.6820 \tMean_test_accuracy_sum: 0.5085\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam([{'params': forward_model.parameters()}], \n",
    "                 lr=0.0001)\n",
    "edge_index = edge_index.to(device)\n",
    "top_num = 500\n",
    "# encoder = vae_model.Encoder\n",
    "\n",
    "for epoch in range(2000):\n",
    "\n",
    "    total_overall = 0\n",
    "    forward_loss = 0\n",
    "\n",
    "    mean_train_accuracy = 0\n",
    "    for batch_idx, x_feature_label in enumerate(train_loader):  \n",
    "        x =  x_feature_label[0].to(device)     \n",
    "        features = x_feature_label[1].to(device)\n",
    "        labels = x_feature_label[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        train_accuracy = 0\n",
    "        for i, feat_i in enumerate(features):\n",
    "            \n",
    "            # log_sum = torch.sum(torch.log(1 - x_i), dim=1, keepdim=True)\n",
    "            # feat = 1 - torch.exp(log_sum)\n",
    "            x_i = x[i]\n",
    "            x_i = torch.matmul(x_i, laplace_emb)\n",
    "            \n",
    "            \n",
    "            # x_i = encoder(x_i).detach()\n",
    "            # x_i = torch.rand(latent_dim).to(device)\n",
    "            # x_i = normalize_features(x_i)\n",
    "            x_i = x_i.expand(features.shape[1], -1)\n",
    "            # final_feat_i =  torch.cat((feat_i, x_i), dim=1)\n",
    "            \n",
    "            \n",
    "            y_i = labels[i]\n",
    "            y_hat = forward_model(feat_i, x_i, edge_index)\n",
    "            _, top_indices_true = torch.topk(y_i.clone(), top_num)\n",
    "            label_2 = torch.zeros(y_i.shape).to(device)\n",
    "            label_2[top_indices_true] = 1\n",
    "            \n",
    "            _, top_indices_predict = torch.topk(y_hat.clone().squeeze(-1), top_num)\n",
    "            \n",
    "            # 将张量数组转换为Python列表\n",
    "            list1 = top_indices_true.tolist()\n",
    "            list_pre = top_indices_predict.tolist()\n",
    "\n",
    "            # 使用集合操作找到交集\n",
    "            intersection = list(set(list1) & set(list_pre))\n",
    "            accuracy_i = len(intersection) / top_num       \n",
    "            train_accuracy += accuracy_i \n",
    "\n",
    "            forward_loss = F.mse_loss(y_hat.squeeze(-1), y_i, reduction='sum')\n",
    "            loss += forward_loss    \n",
    "        \n",
    "        total_overall += loss.item()    \n",
    "        train_accuracy /= len(features)\n",
    "        mean_train_accuracy = train_accuracy\n",
    "        loss = loss/features.size(0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # for p in forward_model.parameters():\n",
    "        #     p.data.clamp_(min=0)\n",
    "        \n",
    "        \n",
    "    print(\"Epoch: {}\".format(epoch+1), \n",
    "        \"\\tTotal: {:.4f}\".format(total_overall / train_batch_size),\n",
    "        \"\\tMean_train_accuracy: {:.4f}\".format(mean_train_accuracy),\n",
    "        )  \n",
    "    \n",
    "    mean_accuracy = 0\n",
    "    mean_accuracy_sum = 0\n",
    "\n",
    "    \n",
    "    for batch_idx, x_feature_label in enumerate(test_loader):  \n",
    "        x =  x_feature_label[0].to(device)\n",
    "        features = x_feature_label[1].to(device)\n",
    "        labels = x_feature_label[2].to(device)\n",
    "        \n",
    "        accuracy = 0\n",
    "        accuracy_sum = 0\n",
    "        \n",
    "        for i, feat_i in enumerate(features):\n",
    "            # x_i = x[i]\n",
    "            # x_i = encoder(x_i).detach()\n",
    "            # x_i = normalize_features(x_i)\n",
    "            x_i = x[i]\n",
    "            x_i = torch.matmul(x_i, laplace_emb)\n",
    "            x_i = x_i.expand(features.shape[1], -1)\n",
    "            # final_feat_i =  torch.cat((feat_i, x_i), dim=1)\n",
    "            y_i = labels[i]\n",
    "            _, top_indices_true = torch.topk(y_i, top_num)\n",
    "            \n",
    "            y_hat = forward_model(feat_i, x_i, edge_index)\n",
    "            \n",
    "            _, top_indices_predict = torch.topk(y_hat.squeeze(-1), top_num)\n",
    "            \n",
    "            sum_pre = torch.sum(feat_i, dim=1, keepdim=True)\n",
    "            _, top_indices_sum = torch.topk(sum_pre.squeeze(-1), top_num)\n",
    "            \n",
    "            # 将张量数组转换为Python列表\n",
    "            list1 = top_indices_true.tolist()\n",
    "            list_pre = top_indices_predict.tolist()\n",
    "            \n",
    "            list_sum = top_indices_sum.tolist()\n",
    "\n",
    "            # 使用集合操作找到交集\n",
    "            intersection = list(set(list1) & set(list_pre))\n",
    "            \n",
    "            intersection_sum = list(set(list1) & set(list_sum))\n",
    "            \n",
    "            accuracy_i = len(intersection) / top_num       \n",
    "            accuracy += accuracy_i \n",
    "            accuracy_sum += len(intersection_sum) / top_num  \n",
    "        accuracy /= test_batch_size\n",
    "        accuracy_sum/= test_batch_size\n",
    "        mean_accuracy = accuracy\n",
    "        mean_accuracy_sum = accuracy_sum\n",
    "        break\n",
    "    \n",
    "    print(\n",
    "        \"\\tMean_test_accuracy: {:.4f}\".format(mean_accuracy),\n",
    "        \"\\tMean_test_accuracy_sum: {:.4f}\".format(mean_accuracy_sum)\n",
    "        )  \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
