{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=4)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('/home/zjy/project/MetaIM')\n",
    "pwd = '/home/zjy/project/MetaIM/data'\n",
    "device = torch.device('cuda:4' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "cora_dataset = Planetoid(root=pwd+'/cora', name='cora')\n",
    "data = cora_dataset[0]\n",
    "edge_index = data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2708, 2708), (1000, 2, 2708))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "individual_infection_path = pwd+'/for_meta/cora_individual_infection_sir_200_sample_500.npy'\n",
    "seeds_infection_path = pwd+'/for_meta/cora_seed_infection_sir_200_sample_500.npy'\n",
    "\n",
    "individual_infection = np.load(individual_infection_path)\n",
    "seeds_infection = np.load(seeds_infection_path)\n",
    "individual_infection.shape,seeds_infection.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "                       [ 633, 1862, 2582,  ...,  598, 1473, 2706]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "       size=(2708, 2708), nnz=10556, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# 转换为 scipy 稀疏矩阵\n",
    "adj = to_scipy_sparse_matrix(edge_index)\n",
    "\n",
    "\n",
    "# def normalize_adj(mx):\n",
    "#     \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "#     rowsum = np.array(mx.sum(1))\n",
    "#     r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "#     r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "#     r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "#     return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "\n",
    "\n",
    "# adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "# adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "adj = torch.Tensor(adj.toarray()).to_sparse()\n",
    "adj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_num = int(seeds_infection[0][0].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, individual_infection,seeds_infection, feat_num):\n",
    "        self.individual_infection = individual_infection\n",
    "        self.seeds_infection = seeds_infection\n",
    "        self.feat_shape = (len(individual_infection), feat_num)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seeds_infection)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seeds= np.nonzero(self.seeds_infection[idx][0])[0]\n",
    "        \n",
    "        feature = torch.zeros(self.feat_shape[0],self.feat_shape[1])\n",
    "        for i in range(len(seeds)):\n",
    "            seed_i_infection = torch.tensor(self.individual_infection[seeds[i]])\n",
    "            feature[:, i] = seed_i_infection\n",
    "            \n",
    "        label = self.seeds_infection[idx][1]\n",
    "        \n",
    "        return self.seeds_infection[idx][0], feature, label\n",
    "\n",
    "dataset = CustomDataset(individual_infection, seeds_infection, feat_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义划分比例\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "# 划分数据集\n",
    "train_dataset, test_dataset = random_split(dataset, [int(len(dataset)*train_ratio), int(len(dataset)*test_ratio)])\n",
    "\n",
    "train_batch_size = 64\n",
    "test_batch_size = 4\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAEModel(\n",
       "  (Encoder): Encoder(\n",
       "    (FC_input): Linear(in_features=2708, out_features=512, bias=True)\n",
       "    (FC_input2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (FC_output): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Decoder): Decoder(\n",
       "    (FC_input): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (FC_hidden_1): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (FC_hidden_2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (FC_output): Linear(in_features=512, out_features=2708, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from data import model \n",
    "from data.model.model import VAEModel, Encoder, Decoder\n",
    "from torch.optim import Adam, SGD\n",
    "import torch.nn.functional as F\n",
    "\n",
    "hidden_dim = 512\n",
    "latent_dim = 128\n",
    "\n",
    "encoder = Encoder(input_dim= len(seeds_infection[0][0]), \n",
    "                  hidden_dim=hidden_dim, \n",
    "                  latent_dim=latent_dim)\n",
    "\n",
    "decoder = Decoder(input_dim=latent_dim, \n",
    "                  latent_dim=latent_dim, \n",
    "                  hidden_dim=hidden_dim, \n",
    "                  output_dim=len(seeds_infection[0][0]))\n",
    "\n",
    "vae_model = VAEModel(Encoder=encoder, Decoder=decoder).to(device)\n",
    "\n",
    "optimizer_vae = Adam([{'params': vae_model.parameters()}], \n",
    "                 lr=0.0001)\n",
    "vae_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTrain_vae_loss: 8404.9955\n",
      "Epoch: 2 \tTrain_vae_loss: 8143.6473\n",
      "Epoch: 3 \tTrain_vae_loss: 5811.0344\n",
      "Epoch: 4 \tTrain_vae_loss: 1811.6202\n",
      "Epoch: 5 \tTrain_vae_loss: 1686.4022\n",
      "Epoch: 6 \tTrain_vae_loss: 1687.3970\n",
      "Epoch: 7 \tTrain_vae_loss: 1687.4539\n",
      "Epoch: 8 \tTrain_vae_loss: 1687.4620\n",
      "Epoch: 9 \tTrain_vae_loss: 1687.4631\n",
      "Epoch: 10 \tTrain_vae_loss: 1687.4624\n",
      "Epoch: 11 \tTrain_vae_loss: 1687.4610\n",
      "Epoch: 12 \tTrain_vae_loss: 1687.4590\n",
      "Epoch: 13 \tTrain_vae_loss: 1687.4565\n",
      "Epoch: 14 \tTrain_vae_loss: 1687.4527\n",
      "Epoch: 15 \tTrain_vae_loss: 1687.4476\n",
      "Epoch: 16 \tTrain_vae_loss: 1687.4398\n",
      "Epoch: 17 \tTrain_vae_loss: 1687.4280\n",
      "Epoch: 18 \tTrain_vae_loss: 1687.4072\n",
      "Epoch: 19 \tTrain_vae_loss: 1687.3569\n",
      "Epoch: 20 \tTrain_vae_loss: 1687.2081\n",
      "Epoch: 21 \tTrain_vae_loss: 1686.9358\n",
      "Epoch: 22 \tTrain_vae_loss: 1686.3623\n",
      "Epoch: 23 \tTrain_vae_loss: 1684.8150\n",
      "Epoch: 24 \tTrain_vae_loss: 1680.1514\n",
      "Epoch: 25 \tTrain_vae_loss: 1670.4013\n",
      "Epoch: 26 \tTrain_vae_loss: 1654.1857\n",
      "Epoch: 27 \tTrain_vae_loss: 1633.8608\n",
      "Epoch: 28 \tTrain_vae_loss: 1618.5128\n",
      "Epoch: 29 \tTrain_vae_loss: 1610.5121\n",
      "Epoch: 30 \tTrain_vae_loss: 1606.3786\n",
      "Epoch: 31 \tTrain_vae_loss: 1604.3931\n",
      "Epoch: 32 \tTrain_vae_loss: 1603.3657\n",
      "Epoch: 33 \tTrain_vae_loss: 1602.7833\n",
      "Epoch: 34 \tTrain_vae_loss: 1602.4762\n",
      "Epoch: 35 \tTrain_vae_loss: 1602.2890\n",
      "Epoch: 36 \tTrain_vae_loss: 1602.2669\n",
      "Epoch: 37 \tTrain_vae_loss: 1602.2356\n",
      "Epoch: 38 \tTrain_vae_loss: 1602.1991\n",
      "Epoch: 39 \tTrain_vae_loss: 1602.2129\n",
      "Epoch: 40 \tTrain_vae_loss: 1602.2190\n",
      "Epoch: 41 \tTrain_vae_loss: 1602.1864\n",
      "Epoch: 42 \tTrain_vae_loss: 1602.1660\n",
      "Epoch: 43 \tTrain_vae_loss: 1602.1923\n",
      "Epoch: 44 \tTrain_vae_loss: 1602.1991\n",
      "Epoch: 45 \tTrain_vae_loss: 1602.1750\n",
      "Epoch: 46 \tTrain_vae_loss: 1602.1787\n",
      "Epoch: 47 \tTrain_vae_loss: 1602.1485\n",
      "Epoch: 48 \tTrain_vae_loss: 1602.1518\n",
      "Epoch: 49 \tTrain_vae_loss: 1602.1300\n",
      "Epoch: 50 \tTrain_vae_loss: 1602.1310\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "\n",
    "    train_vae_loss = 0\n",
    "\n",
    "    mean_train_accuracy = 0\n",
    "    for batch_idx, x_feature_label in enumerate(train_loader):        \n",
    "        x = x_feature_label[0].to(device)\n",
    "        optimizer_vae.zero_grad()\n",
    "        loss = 0\n",
    "        for i, x_i in enumerate(x):\n",
    "            x_hat = vae_model(x_i)\n",
    "\n",
    "            reproduction_loss = F.mse_loss(x_hat, x_i, reduction='sum')    \n",
    "            loss += reproduction_loss    \n",
    "        \n",
    "        train_vae_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer_vae.step()\n",
    "        \n",
    "        \n",
    "    print(\"Epoch: {}\".format(epoch+1), \n",
    "        \"\\tTrain_vae_loss: {:.4f}\".format(train_vae_loss / train_batch_size),\n",
    "        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_heads):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads=num_heads)\n",
    "        self.conv2 = GATConv(hidden_channels * num_heads, out_channels, heads=1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAT(\n",
       "  (conv1): GATConv(391, 512, heads=8)\n",
       "  (conv2): GATConv(4096, 1, heads=1)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from data.model.gat import GAT, SpGAT\n",
    "\n",
    "\n",
    "\n",
    "# forward_model = SpGAT(nfeat=feat_num, \n",
    "#                 nhid=64, \n",
    "#                 nclass=1, \n",
    "#                 dropout=0.2, \n",
    "#                 nheads=1, \n",
    "#                 alpha=0.2)\n",
    "\n",
    "feat_num += latent_dim\n",
    "\n",
    "forward_model = GAT(feat_num, 512, 1, 8)\n",
    "\n",
    "optimizer = Adam([{'params': forward_model.parameters()}], \n",
    "                 lr=0.001)\n",
    "\n",
    "adj = adj.to(device)\n",
    "forward_model = forward_model.to(device)\n",
    "forward_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 208.00 MiB. GPU 4 has a total capacity of 23.65 GiB of which 126.56 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 21.29 GiB is allocated by PyTorch, and 921.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m final_feat_i \u001b[38;5;241m=\u001b[39m  torch\u001b[38;5;241m.\u001b[39mcat((feat_i, x_i), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     29\u001b[0m y_i \u001b[38;5;241m=\u001b[39m labels[i]\n\u001b[0;32m---> 30\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m forward_model(final_feat_i, edge_index)\n\u001b[1;32m     31\u001b[0m _, top_indices_true \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(y_i\u001b[38;5;241m.\u001b[39mclone(), top_num)\n\u001b[1;32m     32\u001b[0m label_2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(y_i\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m, in \u001b[0;36mGAT.forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m---> 13\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index))\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/cm/shared/apps/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch_geometric/nn/conv/gat_conv.py:341\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    337\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_updater(edge_index, alpha\u001b[38;5;241m=\u001b[39malpha, edge_attr\u001b[38;5;241m=\u001b[39medge_attr,\n\u001b[1;32m    338\u001b[0m                           size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, alpha\u001b[38;5;241m=\u001b[39malpha, size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcat:\n\u001b[1;32m    344\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_channels)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:547\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m         msg_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 547\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmessage(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmsg_kwargs)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    549\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (msg_kwargs, ), out)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch_geometric/nn/conv/gat_conv.py:386\u001b[0m, in \u001b[0;36mGATConv.message\u001b[0;34m(self, x_j, alpha)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmessage\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_j: Tensor, alpha: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m alpha\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m x_j\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 208.00 MiB. GPU 4 has a total capacity of 23.65 GiB of which 126.56 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 21.29 GiB is allocated by PyTorch, and 921.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "edge_index = edge_index.to(device)\n",
    "top_num = 500\n",
    "encoder = vae_model.Encoder\n",
    "\n",
    "for epoch in range(2000):\n",
    "\n",
    "    total_overall = 0\n",
    "    forward_loss = 0\n",
    "\n",
    "    mean_train_accuracy = 0\n",
    "    for batch_idx, x_feature_label in enumerate(train_loader):  \n",
    "        x =  x_feature_label[0].to(device)     \n",
    "        features = x_feature_label[1].to(device)\n",
    "        labels = x_feature_label[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        train_accuracy = 0\n",
    "        for i, feat_i in enumerate(features):\n",
    "            \n",
    "            # log_sum = torch.sum(torch.log(1 - x_i), dim=1, keepdim=True)\n",
    "            # feat = 1 - torch.exp(log_sum)\n",
    "            x_i = x[i]\n",
    "            x_i = encoder(x_i).detach()\n",
    "            x_i = x_i.expand(features.shape[1], -1)\n",
    "            final_feat_i =  torch.cat((feat_i, x_i), dim=1)\n",
    "            \n",
    "            \n",
    "            y_i = labels[i]\n",
    "            y_hat = forward_model(final_feat_i, edge_index)\n",
    "            _, top_indices_true = torch.topk(y_i.clone(), top_num)\n",
    "            label_2 = torch.zeros(y_i.shape).to(device)\n",
    "            label_2[top_indices_true] = 1\n",
    "            \n",
    "            _, top_indices_predict = torch.topk(y_hat.clone().squeeze(-1), top_num)\n",
    "            \n",
    "            # 将张量数组转换为Python列表\n",
    "            list1 = top_indices_true.tolist()\n",
    "            list_pre = top_indices_predict.tolist()\n",
    "\n",
    "            # 使用集合操作找到交集\n",
    "            intersection = list(set(list1) & set(list_pre))\n",
    "            accuracy_i = len(intersection) / top_num       \n",
    "            train_accuracy += accuracy_i \n",
    "\n",
    "            forward_loss = 0.5*F.mse_loss(y_hat.squeeze(-1), y_i, reduction='sum') + F.mse_loss(y_hat.squeeze(-1), label_2, reduction='sum')    \n",
    "            loss += forward_loss    \n",
    "        \n",
    "        total_overall += loss.item()    \n",
    "        train_accuracy /= len(features)\n",
    "        mean_train_accuracy = train_accuracy\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # for p in forward_model.parameters():\n",
    "        #     p.data.clamp_(min=0)\n",
    "        \n",
    "        \n",
    "    print(\"Epoch: {}\".format(epoch+1), \n",
    "        \"\\tTotal: {:.4f}\".format(total_overall / train_batch_size),\n",
    "        \"\\tMean_train_accuracy: {:.4f}\".format(mean_train_accuracy),\n",
    "        )  \n",
    "    \n",
    "    mean_accuracy = 0\n",
    "    mean_accuracy_sum = 0\n",
    "\n",
    "    \n",
    "    for batch_idx, x_feature_label in enumerate(test_loader):  \n",
    "        x =  x_feature_label[0].to(device)\n",
    "        features = x_feature_label[1].to(device)\n",
    "        labels = x_feature_label[2].to(device)\n",
    "        \n",
    "        accuracy = 0\n",
    "        accuracy_sum = 0\n",
    "        \n",
    "        for i, feat_i in enumerate(features):\n",
    "            x_i = x[i]\n",
    "            x_i = encoder(x_i).detach()\n",
    "            x_i = x_i.expand(features.shape[1], -1)\n",
    "            final_feat_i =  torch.cat((feat_i, x_i), dim=1)\n",
    "            y_i = labels[i]\n",
    "            _, top_indices_true = torch.topk(y_i, top_num)\n",
    "            \n",
    "            y_hat = forward_model(final_feat_i, edge_index)\n",
    "            \n",
    "            _, top_indices_predict = torch.topk(y_hat.squeeze(-1), top_num)\n",
    "            \n",
    "            sum_pre = torch.sum(final_feat_i, dim=1, keepdim=True)\n",
    "            _, top_indices_sum = torch.topk(sum_pre.squeeze(-1), top_num)\n",
    "            \n",
    "            # 将张量数组转换为Python列表\n",
    "            list1 = top_indices_true.tolist()\n",
    "            list_pre = top_indices_predict.tolist()\n",
    "            \n",
    "            list_sum = top_indices_sum.tolist()\n",
    "\n",
    "            # 使用集合操作找到交集\n",
    "            intersection = list(set(list1) & set(list_pre))\n",
    "            \n",
    "            intersection_sum = list(set(list1) & set(list_sum))\n",
    "            \n",
    "            accuracy_i = len(intersection) / top_num       \n",
    "            accuracy += accuracy_i \n",
    "            accuracy_sum += len(intersection_sum) / top_num  \n",
    "        accuracy /= test_batch_size\n",
    "        accuracy_sum/= test_batch_size\n",
    "        mean_accuracy = accuracy\n",
    "        mean_accuracy_sum = accuracy_sum\n",
    "        break\n",
    "    \n",
    "    print(\n",
    "        \"\\tMean_test_accuracy: {:.4f}\".format(mean_accuracy),\n",
    "        \"\\tMean_test_accuracy_sum: {:.4f}\".format(mean_accuracy_sum)\n",
    "        )  \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
