{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/51r_nlz93n7__jn387b614040000gn/T/ipykernel_8491/1949735674.py:23: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  graph = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"GenIM\")\n",
    "datasets = ['jazz', 'cora_ml', 'power_grid', 'netscience', 'random5']\n",
    "parser.add_argument(\"-d\", \"--dataset\", default=\"cora_ml\", type=str,\n",
    "                    help=\"one of: {}\".format(\", \".join(sorted(datasets))))\n",
    "diffusion = ['IC', 'LT', 'SIS']\n",
    "parser.add_argument(\"-dm\", \"--diffusion_model\", default=\"LT\", type=str,\n",
    "                    help=\"one of: {}\".format(\", \".join(sorted(diffusion))))\n",
    "seed_rate = [1, 5, 10, 20]\n",
    "parser.add_argument(\"-sp\", \"--seed_rate\", default=1, type=int,\n",
    "                    help=\"one of: {}\".format(\", \".join(str(sorted(seed_rate)))))\n",
    "mode = ['Normal', 'Budget Constraint']\n",
    "parser.add_argument(\"-m\", \"--mode\", default=\"normal\", type=str,\n",
    "                    help=\"one of: {}\".format(\", \".join(sorted(mode))))\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "with open('data/' + args.dataset + '_mean_' + args.diffusion_model + str(50) + '.SG', 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'cora_{args.diffusion_model}_50.SG', 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "batch_size = 16\n",
    "hidden_dim = 1024\n",
    "latent_dim = 512\n",
    "\n",
    "adj, inverse_pairs = graph['adj'], graph['inverse_pairs']\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "adj = torch.Tensor(adj.toarray()).to_sparse()\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(inverse_pairs, \n",
    "                                                    [len(inverse_pairs)-batch_size, \n",
    "                                                     batch_size])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "test_loader  = DataLoader(dataset=test_set,  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpGAT(\n",
       "  (attention_0): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention_1): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention_2): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention_3): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention1_0): SpGraphAttentionLayer (256 -> 64)\n",
       "  (attention1_1): SpGraphAttentionLayer (256 -> 64)\n",
       "  (attention1_2): SpGraphAttentionLayer (256 -> 64)\n",
       "  (attention1_3): SpGraphAttentionLayer (256 -> 64)\n",
       "  (out_att): SpGraphAttentionLayer (256 -> 1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main.model.gat import GAT, SpGAT\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "\n",
    "forward_model = SpGAT(nfeat=1, \n",
    "                nhid=64, \n",
    "                nclass=1, \n",
    "                dropout=0.1, \n",
    "                nheads=4, \n",
    "                alpha=0.2)\n",
    "\n",
    "optimizer = Adam([{'params': forward_model.parameters()}], \n",
    "                 lr=1e-3)\n",
    "\n",
    "adj = adj.to(device)\n",
    "forward_model = forward_model.to(device)\n",
    "forward_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "# for epoch in range(600):\n",
    "#     # 训练\n",
    "#     loss = 0\n",
    "#     for t in range(80):\n",
    "#         y_hat = forward_model(x[t].unsqueeze(-1), adj)\n",
    "#         forward_loss = F.binary_cross_entropy(y_hat.squeeze(-1), y[t], reduction='sum')    \n",
    "#         loss += forward_loss\n",
    "#     loss /= 80\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     for p in forward_model.parameters():\n",
    "#         p.data.clamp_(min=0)\n",
    "    \n",
    "#     # 测试\n",
    "#     with torch.no_grad():\n",
    "#         test_loss = 0\n",
    "#         correct = 0\n",
    "#         correct_1 = 0\n",
    "#         for t in range(80,100):\n",
    "#             y_hat = forward_model(x[t].unsqueeze(-1), adj)\n",
    "#             # forward_loss = F.binary_cross_entropy(y_hat.squeeze(-1), y[t], reduction='sum')    \n",
    "#             forward_loss = F.mse_loss(y_hat.squeeze(-1), y[t], reduction='sum')\n",
    "#             test_loss += forward_loss\n",
    "            \n",
    "#             threshold = 0.6\n",
    "#             y_pre = y_hat.squeeze(-1)\n",
    "#             filtered_y_hat = (y_pre > threshold).float()\n",
    "#             correct += ((filtered_y_hat == y[t]).sum()/len(y[t]))\n",
    "#             count_both_ones = torch.sum((filtered_y_hat == 1) & (y[t] == 1))\n",
    "#             correct_1 += count_both_ones/y[t].sum()\n",
    "#         correct /= 20\n",
    "#         correct_1 /= 20    \n",
    "#         test_loss /= 20\n",
    "#     print(\"Epoch: {}\".format(epoch+1), \n",
    "#         \"\\tTotal: {:.4f}\".format(loss),\n",
    "#         \"\\tTest_loss: {:.4f}\".format(test_loss),\n",
    "#         \"\\tTest_accuracy: {:.4f}\".format(correct),\n",
    "#         \"\\tTest_accuracy_1: {:.4f}\".format(correct_1),\n",
    "#         # \"\\tTime: {:.4f}\".format(end - begin)\n",
    "#         )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def loss_all(y, y_hat):\n",
    "    # reproduction_loss = F.binary_cross_entropy(x_hat, x, reduction='sum')\n",
    "    forward_loss = F.mse_loss(y_hat, y, reduction='sum')\n",
    "    # print(f'foward_loss====={forward_loss}')\n",
    "    # forward_loss = F.binary_cross_entropy(y_hat, y, reduction='sum')\n",
    "    # return reproduction_loss+forward_loss, reproduction_loss, forward_loss\n",
    "    \n",
    "    threshold = 0.3\n",
    "    filtered_y_hat = (y_hat > threshold).float()\n",
    "    correct = ((filtered_y_hat == y).sum()/len(y))\n",
    "    count_both_ones = torch.sum((filtered_y_hat == 1) & (y == 1))\n",
    "    correct_1 = count_both_ones/y.sum()\n",
    "    \n",
    "    return forward_loss,correct,correct_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTrain_loss: 839.5335 \tTrain_accuracy: 0.6967 \tTrain_accuracy_1: 0.5163 \tTest_loss: 745.6663 \tTest_accuracy: 0.7448 \tTest_accuracy_1: 0.5749 \tTime: 5.9124\n",
      "Epoch: 2 \tTrain_loss: 796.1602 \tTrain_accuracy: 0.7231 \tTrain_accuracy_1: 0.5694 \tTest_loss: 717.0917 \tTest_accuracy: 0.7566 \tTest_accuracy_1: 0.6118 \tTime: 5.7136\n",
      "Epoch: 3 \tTrain_loss: 763.3956 \tTrain_accuracy: 0.7404 \tTrain_accuracy_1: 0.6102 \tTest_loss: 679.6266 \tTest_accuracy: 0.7770 \tTest_accuracy_1: 0.6588 \tTime: 5.8065\n",
      "Epoch: 4 \tTrain_loss: 737.5449 \tTrain_accuracy: 0.7556 \tTrain_accuracy_1: 0.6427 \tTest_loss: 662.6205 \tTest_accuracy: 0.7830 \tTest_accuracy_1: 0.6822 \tTime: 5.8709\n",
      "Epoch: 5 \tTrain_loss: 710.9743 \tTrain_accuracy: 0.7659 \tTrain_accuracy_1: 0.6731 \tTest_loss: 638.2781 \tTest_accuracy: 0.7938 \tTest_accuracy_1: 0.7116 \tTime: 5.7111\n",
      "Epoch: 6 \tTrain_loss: 693.1459 \tTrain_accuracy: 0.7734 \tTrain_accuracy_1: 0.6943 \tTest_loss: 631.4355 \tTest_accuracy: 0.7952 \tTest_accuracy_1: 0.7247 \tTime: 5.6756\n",
      "Epoch: 7 \tTrain_loss: 678.6822 \tTrain_accuracy: 0.7777 \tTrain_accuracy_1: 0.7095 \tTest_loss: 618.9146 \tTest_accuracy: 0.7984 \tTest_accuracy_1: 0.7382 \tTime: 5.7106\n",
      "Epoch: 8 \tTrain_loss: 670.4119 \tTrain_accuracy: 0.7810 \tTrain_accuracy_1: 0.7236 \tTest_loss: 608.1733 \tTest_accuracy: 0.8013 \tTest_accuracy_1: 0.7533 \tTime: 5.7641\n",
      "Epoch: 9 \tTrain_loss: 661.3548 \tTrain_accuracy: 0.7843 \tTrain_accuracy_1: 0.7346 \tTest_loss: 606.2277 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.7642 \tTime: 5.7640\n",
      "Epoch: 10 \tTrain_loss: 656.2624 \tTrain_accuracy: 0.7863 \tTrain_accuracy_1: 0.7443 \tTest_loss: 598.0521 \tTest_accuracy: 0.8006 \tTest_accuracy_1: 0.7679 \tTime: 5.7002\n",
      "Epoch: 11 \tTrain_loss: 655.9753 \tTrain_accuracy: 0.7878 \tTrain_accuracy_1: 0.7489 \tTest_loss: 605.9933 \tTest_accuracy: 0.7989 \tTest_accuracy_1: 0.7667 \tTime: 5.9515\n",
      "Epoch: 12 \tTrain_loss: 652.1934 \tTrain_accuracy: 0.7880 \tTrain_accuracy_1: 0.7536 \tTest_loss: 593.8892 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.7761 \tTime: 6.0803\n",
      "Epoch: 13 \tTrain_loss: 656.6493 \tTrain_accuracy: 0.7882 \tTrain_accuracy_1: 0.7555 \tTest_loss: 604.0447 \tTest_accuracy: 0.7989 \tTest_accuracy_1: 0.7760 \tTime: 5.8958\n",
      "Epoch: 14 \tTrain_loss: 646.8847 \tTrain_accuracy: 0.7905 \tTrain_accuracy_1: 0.7617 \tTest_loss: 598.1071 \tTest_accuracy: 0.7986 \tTest_accuracy_1: 0.7799 \tTime: 5.8745\n",
      "Epoch: 15 \tTrain_loss: 647.6938 \tTrain_accuracy: 0.7906 \tTrain_accuracy_1: 0.7610 \tTest_loss: 586.7708 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.7855 \tTime: 5.8265\n",
      "Epoch: 16 \tTrain_loss: 643.4479 \tTrain_accuracy: 0.7904 \tTrain_accuracy_1: 0.7642 \tTest_loss: 591.4312 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.7874 \tTime: 6.0188\n",
      "Epoch: 17 \tTrain_loss: 642.7790 \tTrain_accuracy: 0.7915 \tTrain_accuracy_1: 0.7654 \tTest_loss: 592.8478 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.7818 \tTime: 6.0146\n",
      "Epoch: 18 \tTrain_loss: 636.3557 \tTrain_accuracy: 0.7919 \tTrain_accuracy_1: 0.7661 \tTest_loss: 589.6932 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.7836 \tTime: 5.9413\n",
      "Epoch: 19 \tTrain_loss: 643.0210 \tTrain_accuracy: 0.7901 \tTrain_accuracy_1: 0.7644 \tTest_loss: 576.8502 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.7885 \tTime: 5.8713\n",
      "Epoch: 20 \tTrain_loss: 637.1993 \tTrain_accuracy: 0.7915 \tTrain_accuracy_1: 0.7666 \tTest_loss: 575.4421 \tTest_accuracy: 0.8051 \tTest_accuracy_1: 0.7912 \tTime: 5.9715\n",
      "Epoch: 21 \tTrain_loss: 635.2589 \tTrain_accuracy: 0.7917 \tTrain_accuracy_1: 0.7680 \tTest_loss: 585.8743 \tTest_accuracy: 0.8011 \tTest_accuracy_1: 0.7856 \tTime: 6.0307\n",
      "Epoch: 22 \tTrain_loss: 634.5436 \tTrain_accuracy: 0.7920 \tTrain_accuracy_1: 0.7677 \tTest_loss: 596.5698 \tTest_accuracy: 0.7974 \tTest_accuracy_1: 0.7749 \tTime: 6.3219\n",
      "Epoch: 23 \tTrain_loss: 634.2265 \tTrain_accuracy: 0.7907 \tTrain_accuracy_1: 0.7675 \tTest_loss: 583.1746 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.7877 \tTime: 5.9351\n",
      "Epoch: 24 \tTrain_loss: 629.7609 \tTrain_accuracy: 0.7927 \tTrain_accuracy_1: 0.7712 \tTest_loss: 574.7335 \tTest_accuracy: 0.8073 \tTest_accuracy_1: 0.7951 \tTime: 5.8761\n",
      "Epoch: 25 \tTrain_loss: 628.4568 \tTrain_accuracy: 0.7933 \tTrain_accuracy_1: 0.7714 \tTest_loss: 586.8335 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.7823 \tTime: 5.9762\n",
      "Epoch: 26 \tTrain_loss: 631.5182 \tTrain_accuracy: 0.7916 \tTrain_accuracy_1: 0.7703 \tTest_loss: 581.2686 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.7905 \tTime: 5.8833\n",
      "Epoch: 27 \tTrain_loss: 629.5142 \tTrain_accuracy: 0.7911 \tTrain_accuracy_1: 0.7697 \tTest_loss: 580.8374 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.7892 \tTime: 6.2299\n",
      "Epoch: 28 \tTrain_loss: 628.1276 \tTrain_accuracy: 0.7920 \tTrain_accuracy_1: 0.7713 \tTest_loss: 581.7532 \tTest_accuracy: 0.7992 \tTest_accuracy_1: 0.7824 \tTime: 5.8921\n",
      "Epoch: 29 \tTrain_loss: 627.5985 \tTrain_accuracy: 0.7932 \tTrain_accuracy_1: 0.7728 \tTest_loss: 585.3333 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.7906 \tTime: 6.5046\n",
      "Epoch: 30 \tTrain_loss: 622.8877 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7753 \tTest_loss: 572.1569 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.7927 \tTime: 6.0025\n",
      "Epoch: 31 \tTrain_loss: 625.9800 \tTrain_accuracy: 0.7919 \tTrain_accuracy_1: 0.7732 \tTest_loss: 572.2372 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.7904 \tTime: 5.9567\n",
      "Epoch: 32 \tTrain_loss: 624.9205 \tTrain_accuracy: 0.7923 \tTrain_accuracy_1: 0.7726 \tTest_loss: 569.5766 \tTest_accuracy: 0.8070 \tTest_accuracy_1: 0.7954 \tTime: 5.9909\n",
      "Epoch: 33 \tTrain_loss: 620.0006 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7768 \tTest_loss: 569.3654 \tTest_accuracy: 0.8072 \tTest_accuracy_1: 0.7959 \tTime: 5.8738\n",
      "Epoch: 34 \tTrain_loss: 626.6422 \tTrain_accuracy: 0.7913 \tTrain_accuracy_1: 0.7744 \tTest_loss: 576.3148 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.7926 \tTime: 5.8903\n",
      "Epoch: 35 \tTrain_loss: 623.0644 \tTrain_accuracy: 0.7923 \tTrain_accuracy_1: 0.7770 \tTest_loss: 583.0126 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.7931 \tTime: 5.9820\n",
      "Epoch: 36 \tTrain_loss: 622.1219 \tTrain_accuracy: 0.7927 \tTrain_accuracy_1: 0.7774 \tTest_loss: 576.7782 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.7985 \tTime: 6.0468\n",
      "Epoch: 37 \tTrain_loss: 619.5083 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7787 \tTest_loss: 571.9619 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.7961 \tTime: 6.0660\n",
      "Epoch: 38 \tTrain_loss: 623.4260 \tTrain_accuracy: 0.7912 \tTrain_accuracy_1: 0.7771 \tTest_loss: 568.0388 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.7974 \tTime: 5.8129\n",
      "Epoch: 39 \tTrain_loss: 620.1892 \tTrain_accuracy: 0.7931 \tTrain_accuracy_1: 0.7804 \tTest_loss: 569.3989 \tTest_accuracy: 0.8021 \tTest_accuracy_1: 0.7943 \tTime: 5.6823\n",
      "Epoch: 40 \tTrain_loss: 616.6960 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7813 \tTest_loss: 563.0609 \tTest_accuracy: 0.8045 \tTest_accuracy_1: 0.8023 \tTime: 5.6925\n",
      "Epoch: 41 \tTrain_loss: 617.3673 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7828 \tTest_loss: 575.8137 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.7998 \tTime: 5.9956\n",
      "Epoch: 42 \tTrain_loss: 617.8959 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7811 \tTest_loss: 565.0615 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8044 \tTime: 5.9825\n",
      "Epoch: 43 \tTrain_loss: 619.4814 \tTrain_accuracy: 0.7928 \tTrain_accuracy_1: 0.7797 \tTest_loss: 570.0070 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8001 \tTime: 5.8941\n",
      "Epoch: 44 \tTrain_loss: 618.6802 \tTrain_accuracy: 0.7925 \tTrain_accuracy_1: 0.7805 \tTest_loss: 566.6177 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.7939 \tTime: 5.9685\n",
      "Epoch: 45 \tTrain_loss: 613.9154 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7823 \tTest_loss: 574.5098 \tTest_accuracy: 0.7991 \tTest_accuracy_1: 0.7928 \tTime: 5.8813\n",
      "Epoch: 46 \tTrain_loss: 615.6834 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7829 \tTest_loss: 570.0827 \tTest_accuracy: 0.8014 \tTest_accuracy_1: 0.8015 \tTime: 5.9211\n",
      "Epoch: 47 \tTrain_loss: 614.3189 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7837 \tTest_loss: 561.3409 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8030 \tTime: 5.8625\n",
      "Epoch: 48 \tTrain_loss: 617.6715 \tTrain_accuracy: 0.7932 \tTrain_accuracy_1: 0.7816 \tTest_loss: 568.8847 \tTest_accuracy: 0.8011 \tTest_accuracy_1: 0.7989 \tTime: 5.8775\n",
      "Epoch: 49 \tTrain_loss: 614.3483 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7844 \tTest_loss: 564.7474 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8022 \tTime: 5.7835\n",
      "Epoch: 50 \tTrain_loss: 614.0597 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7838 \tTest_loss: 568.7945 \tTest_accuracy: 0.7992 \tTest_accuracy_1: 0.7974 \tTime: 6.0824\n",
      "Epoch: 51 \tTrain_loss: 615.3409 \tTrain_accuracy: 0.7933 \tTrain_accuracy_1: 0.7840 \tTest_loss: 571.8546 \tTest_accuracy: 0.7999 \tTest_accuracy_1: 0.7963 \tTime: 5.7560\n",
      "Epoch: 52 \tTrain_loss: 612.4399 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7856 \tTest_loss: 560.6083 \tTest_accuracy: 0.8014 \tTest_accuracy_1: 0.8006 \tTime: 5.7906\n",
      "Epoch: 53 \tTrain_loss: 615.3897 \tTrain_accuracy: 0.7925 \tTrain_accuracy_1: 0.7814 \tTest_loss: 558.9520 \tTest_accuracy: 0.8050 \tTest_accuracy_1: 0.8029 \tTime: 5.9617\n",
      "Epoch: 54 \tTrain_loss: 613.7862 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7867 \tTest_loss: 566.7349 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8051 \tTime: 6.1652\n",
      "Epoch: 55 \tTrain_loss: 614.1211 \tTrain_accuracy: 0.7936 \tTrain_accuracy_1: 0.7863 \tTest_loss: 572.0961 \tTest_accuracy: 0.7998 \tTest_accuracy_1: 0.7986 \tTime: 5.8805\n",
      "Epoch: 56 \tTrain_loss: 611.2665 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7877 \tTest_loss: 568.8872 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8010 \tTime: 5.8173\n",
      "Epoch: 57 \tTrain_loss: 611.1312 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7883 \tTest_loss: 559.2476 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8064 \tTime: 5.8317\n",
      "Epoch: 58 \tTrain_loss: 612.6751 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7855 \tTest_loss: 565.9534 \tTest_accuracy: 0.8057 \tTest_accuracy_1: 0.8024 \tTime: 5.9385\n",
      "Epoch: 59 \tTrain_loss: 608.7615 \tTrain_accuracy: 0.7938 \tTrain_accuracy_1: 0.7872 \tTest_loss: 565.9883 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8026 \tTime: 6.0251\n",
      "Epoch: 60 \tTrain_loss: 613.3585 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7851 \tTest_loss: 562.8568 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8019 \tTime: 5.9235\n",
      "Epoch: 61 \tTrain_loss: 606.9389 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7899 \tTest_loss: 564.1927 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8055 \tTime: 5.9180\n",
      "Epoch: 62 \tTrain_loss: 610.8863 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7889 \tTest_loss: 565.9310 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.7969 \tTime: 5.8979\n",
      "Epoch: 63 \tTrain_loss: 608.0691 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7886 \tTest_loss: 560.6904 \tTest_accuracy: 0.8021 \tTest_accuracy_1: 0.8028 \tTime: 5.8184\n",
      "Epoch: 64 \tTrain_loss: 605.5665 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7902 \tTest_loss: 574.6646 \tTest_accuracy: 0.8007 \tTest_accuracy_1: 0.7989 \tTime: 5.8304\n",
      "Epoch: 65 \tTrain_loss: 607.1852 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7910 \tTest_loss: 559.1593 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8056 \tTime: 5.7870\n",
      "Epoch: 66 \tTrain_loss: 608.4001 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7889 \tTest_loss: 559.5298 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8063 \tTime: 5.7226\n",
      "Epoch: 67 \tTrain_loss: 609.1636 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7892 \tTest_loss: 557.3779 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8083 \tTime: 5.7786\n",
      "Epoch: 68 \tTrain_loss: 613.5385 \tTrain_accuracy: 0.7922 \tTrain_accuracy_1: 0.7838 \tTest_loss: 564.1627 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8030 \tTime: 5.8247\n",
      "Epoch: 69 \tTrain_loss: 604.5507 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7888 \tTest_loss: 553.9328 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8085 \tTime: 5.8711\n",
      "Epoch: 70 \tTrain_loss: 605.5755 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7891 \tTest_loss: 564.0427 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8055 \tTime: 5.9481\n",
      "Epoch: 71 \tTrain_loss: 609.5112 \tTrain_accuracy: 0.7930 \tTrain_accuracy_1: 0.7897 \tTest_loss: 561.9284 \tTest_accuracy: 0.8049 \tTest_accuracy_1: 0.8097 \tTime: 5.7178\n",
      "Epoch: 72 \tTrain_loss: 610.8648 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7901 \tTest_loss: 553.1004 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8122 \tTime: 5.7355\n",
      "Epoch: 73 \tTrain_loss: 607.3291 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7925 \tTest_loss: 553.6013 \tTest_accuracy: 0.8045 \tTest_accuracy_1: 0.8124 \tTime: 5.7611\n",
      "Epoch: 74 \tTrain_loss: 601.6718 \tTrain_accuracy: 0.7967 \tTrain_accuracy_1: 0.7946 \tTest_loss: 562.7032 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8069 \tTime: 5.7378\n",
      "Epoch: 75 \tTrain_loss: 605.0681 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7900 \tTest_loss: 567.0731 \tTest_accuracy: 0.8000 \tTest_accuracy_1: 0.8018 \tTime: 5.6940\n",
      "Epoch: 76 \tTrain_loss: 610.5544 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7883 \tTest_loss: 555.3629 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.8130 \tTime: 5.7223\n",
      "Epoch: 77 \tTrain_loss: 608.2620 \tTrain_accuracy: 0.7936 \tTrain_accuracy_1: 0.7883 \tTest_loss: 564.1711 \tTest_accuracy: 0.7987 \tTest_accuracy_1: 0.8032 \tTime: 5.8209\n",
      "Epoch: 78 \tTrain_loss: 606.8591 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7916 \tTest_loss: 558.1631 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8071 \tTime: 5.7032\n",
      "Epoch: 79 \tTrain_loss: 606.8431 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7921 \tTest_loss: 554.5003 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8115 \tTime: 5.7186\n",
      "Epoch: 80 \tTrain_loss: 604.8738 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7936 \tTest_loss: 566.0062 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8065 \tTime: 5.6960\n",
      "Epoch: 81 \tTrain_loss: 607.4048 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7910 \tTest_loss: 556.5933 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8088 \tTime: 5.7799\n",
      "Epoch: 82 \tTrain_loss: 610.1484 \tTrain_accuracy: 0.7937 \tTrain_accuracy_1: 0.7905 \tTest_loss: 554.8665 \tTest_accuracy: 0.8033 \tTest_accuracy_1: 0.8066 \tTime: 5.7533\n",
      "Epoch: 83 \tTrain_loss: 605.2718 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7930 \tTest_loss: 560.7014 \tTest_accuracy: 0.8017 \tTest_accuracy_1: 0.8100 \tTime: 5.6944\n",
      "Epoch: 84 \tTrain_loss: 605.0996 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7902 \tTest_loss: 563.5781 \tTest_accuracy: 0.8011 \tTest_accuracy_1: 0.8060 \tTime: 5.7027\n",
      "Epoch: 85 \tTrain_loss: 606.6041 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7936 \tTest_loss: 558.1450 \tTest_accuracy: 0.8001 \tTest_accuracy_1: 0.8081 \tTime: 5.7586\n",
      "Epoch: 86 \tTrain_loss: 604.3032 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7960 \tTest_loss: 565.6162 \tTest_accuracy: 0.8003 \tTest_accuracy_1: 0.8057 \tTime: 5.6963\n",
      "Epoch: 87 \tTrain_loss: 603.6939 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7929 \tTest_loss: 562.9496 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8030 \tTime: 5.7303\n",
      "Epoch: 88 \tTrain_loss: 609.1246 \tTrain_accuracy: 0.7933 \tTrain_accuracy_1: 0.7888 \tTest_loss: 565.0573 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8045 \tTime: 5.7140\n",
      "Epoch: 89 \tTrain_loss: 603.9842 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7931 \tTest_loss: 553.7219 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8119 \tTime: 5.7837\n",
      "Epoch: 90 \tTrain_loss: 603.4210 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7952 \tTest_loss: 568.3478 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8057 \tTime: 5.7474\n",
      "Epoch: 91 \tTrain_loss: 603.8774 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7949 \tTest_loss: 559.7993 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8077 \tTime: 5.7177\n",
      "Epoch: 92 \tTrain_loss: 606.3356 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7966 \tTest_loss: 561.1385 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8095 \tTime: 5.7330\n",
      "Epoch: 93 \tTrain_loss: 609.6713 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7904 \tTest_loss: 549.5533 \tTest_accuracy: 0.8063 \tTest_accuracy_1: 0.8140 \tTime: 5.7642\n",
      "Epoch: 94 \tTrain_loss: 607.3980 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7917 \tTest_loss: 559.9777 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.8095 \tTime: 5.7457\n",
      "Epoch: 95 \tTrain_loss: 608.7601 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7897 \tTest_loss: 550.8380 \tTest_accuracy: 0.8058 \tTest_accuracy_1: 0.8134 \tTime: 5.7728\n",
      "Epoch: 96 \tTrain_loss: 603.3652 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7935 \tTest_loss: 558.7043 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8104 \tTime: 5.7192\n",
      "Epoch: 97 \tTrain_loss: 604.7938 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7936 \tTest_loss: 557.7509 \tTest_accuracy: 0.8003 \tTest_accuracy_1: 0.8091 \tTime: 5.7233\n",
      "Epoch: 98 \tTrain_loss: 603.7849 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7959 \tTest_loss: 560.2441 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8086 \tTime: 5.7439\n",
      "Epoch: 99 \tTrain_loss: 604.1199 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7952 \tTest_loss: 564.1199 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8054 \tTime: 5.7738\n",
      "Epoch: 100 \tTrain_loss: 604.8820 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7934 \tTest_loss: 554.8771 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8149 \tTime: 5.6875\n",
      "Epoch: 101 \tTrain_loss: 607.8941 \tTrain_accuracy: 0.7937 \tTrain_accuracy_1: 0.7932 \tTest_loss: 561.4417 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8110 \tTime: 5.7774\n",
      "Epoch: 102 \tTrain_loss: 600.5754 \tTrain_accuracy: 0.7975 \tTrain_accuracy_1: 0.7986 \tTest_loss: 554.3887 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8105 \tTime: 5.6904\n",
      "Epoch: 103 \tTrain_loss: 603.3446 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7938 \tTest_loss: 561.3777 \tTest_accuracy: 0.8013 \tTest_accuracy_1: 0.8113 \tTime: 5.7501\n",
      "Epoch: 104 \tTrain_loss: 603.7186 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7910 \tTest_loss: 553.3318 \tTest_accuracy: 0.8049 \tTest_accuracy_1: 0.8157 \tTime: 5.7324\n",
      "Epoch: 105 \tTrain_loss: 602.1655 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7948 \tTest_loss: 556.1638 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8137 \tTime: 5.7416\n",
      "Epoch: 106 \tTrain_loss: 606.5232 \tTrain_accuracy: 0.7937 \tTrain_accuracy_1: 0.7914 \tTest_loss: 561.5831 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8102 \tTime: 5.7078\n",
      "Epoch: 107 \tTrain_loss: 609.7207 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7901 \tTest_loss: 556.1852 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8097 \tTime: 5.7165\n",
      "Epoch: 108 \tTrain_loss: 606.8252 \tTrain_accuracy: 0.7932 \tTrain_accuracy_1: 0.7920 \tTest_loss: 559.5558 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8097 \tTime: 5.7346\n",
      "Epoch: 109 \tTrain_loss: 606.3067 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7940 \tTest_loss: 557.0062 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8120 \tTime: 5.7183\n",
      "Epoch: 110 \tTrain_loss: 602.7922 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7960 \tTest_loss: 562.5199 \tTest_accuracy: 0.8004 \tTest_accuracy_1: 0.8115 \tTime: 5.6919\n",
      "Epoch: 111 \tTrain_loss: 604.0853 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7975 \tTest_loss: 559.5943 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8079 \tTime: 5.7300\n",
      "Epoch: 112 \tTrain_loss: 606.9193 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7946 \tTest_loss: 558.6342 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8085 \tTime: 5.7142\n",
      "Epoch: 113 \tTrain_loss: 602.5309 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7963 \tTest_loss: 556.2214 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8117 \tTime: 5.7326\n",
      "Epoch: 114 \tTrain_loss: 607.3075 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7949 \tTest_loss: 554.0815 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8111 \tTime: 6.0204\n",
      "Epoch: 115 \tTrain_loss: 601.8543 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7971 \tTest_loss: 557.6155 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8089 \tTime: 5.8628\n",
      "Epoch: 116 \tTrain_loss: 602.1068 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7940 \tTest_loss: 554.5905 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8120 \tTime: 5.8176\n",
      "Epoch: 117 \tTrain_loss: 599.2194 \tTrain_accuracy: 0.7967 \tTrain_accuracy_1: 0.7988 \tTest_loss: 555.6468 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8132 \tTime: 5.6807\n",
      "Epoch: 118 \tTrain_loss: 603.7644 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7948 \tTest_loss: 562.9109 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.8116 \tTime: 5.6844\n",
      "Epoch: 119 \tTrain_loss: 606.5698 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7928 \tTest_loss: 552.0919 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8140 \tTime: 5.7548\n",
      "Epoch: 120 \tTrain_loss: 608.1628 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7938 \tTest_loss: 557.5408 \tTest_accuracy: 0.8059 \tTest_accuracy_1: 0.8100 \tTime: 5.6849\n",
      "Epoch: 121 \tTrain_loss: 604.9789 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7936 \tTest_loss: 565.4374 \tTest_accuracy: 0.7983 \tTest_accuracy_1: 0.8081 \tTime: 5.6763\n",
      "Epoch: 122 \tTrain_loss: 603.7981 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7942 \tTest_loss: 549.1107 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8178 \tTime: 5.6985\n",
      "Epoch: 123 \tTrain_loss: 603.3533 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7957 \tTest_loss: 559.2744 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8108 \tTime: 5.7066\n",
      "Epoch: 124 \tTrain_loss: 603.5458 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7964 \tTest_loss: 559.4935 \tTest_accuracy: 0.8000 \tTest_accuracy_1: 0.8072 \tTime: 5.7064\n",
      "Epoch: 125 \tTrain_loss: 601.2236 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7962 \tTest_loss: 556.6870 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8081 \tTime: 5.7345\n",
      "Epoch: 126 \tTrain_loss: 606.6637 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7938 \tTest_loss: 551.2960 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8133 \tTime: 5.7062\n",
      "Epoch: 127 \tTrain_loss: 601.6060 \tTrain_accuracy: 0.7970 \tTrain_accuracy_1: 0.7965 \tTest_loss: 555.4790 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8132 \tTime: 5.6921\n",
      "Epoch: 128 \tTrain_loss: 604.6166 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7946 \tTest_loss: 551.7731 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8075 \tTime: 5.7184\n",
      "Epoch: 129 \tTrain_loss: 602.8869 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7966 \tTest_loss: 558.2254 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8096 \tTime: 5.7030\n",
      "Epoch: 130 \tTrain_loss: 599.5372 \tTrain_accuracy: 0.7966 \tTrain_accuracy_1: 0.7976 \tTest_loss: 554.9788 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8166 \tTime: 5.7116\n",
      "Epoch: 131 \tTrain_loss: 606.9356 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7933 \tTest_loss: 558.5847 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8096 \tTime: 5.6622\n",
      "Epoch: 132 \tTrain_loss: 604.1167 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7935 \tTest_loss: 558.2808 \tTest_accuracy: 0.8002 \tTest_accuracy_1: 0.8115 \tTime: 5.7104\n",
      "Epoch: 133 \tTrain_loss: 601.2153 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7977 \tTest_loss: 559.1284 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8117 \tTime: 5.6970\n",
      "Epoch: 134 \tTrain_loss: 602.6021 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7971 \tTest_loss: 553.2220 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8118 \tTime: 5.7411\n",
      "Epoch: 135 \tTrain_loss: 607.0504 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7933 \tTest_loss: 559.4315 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8103 \tTime: 5.7686\n",
      "Epoch: 136 \tTrain_loss: 604.1368 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7942 \tTest_loss: 559.8740 \tTest_accuracy: 0.8045 \tTest_accuracy_1: 0.8109 \tTime: 5.7353\n",
      "Epoch: 137 \tTrain_loss: 603.2566 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7939 \tTest_loss: 558.1597 \tTest_accuracy: 0.7988 \tTest_accuracy_1: 0.8094 \tTime: 5.7182\n",
      "Epoch: 138 \tTrain_loss: 604.7600 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7976 \tTest_loss: 563.0787 \tTest_accuracy: 0.7977 \tTest_accuracy_1: 0.8034 \tTime: 5.7329\n",
      "Epoch: 139 \tTrain_loss: 608.4044 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7928 \tTest_loss: 559.5060 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8101 \tTime: 5.7413\n",
      "Epoch: 140 \tTrain_loss: 601.1182 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7968 \tTest_loss: 553.4571 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.8123 \tTime: 5.7486\n",
      "Epoch: 141 \tTrain_loss: 604.8054 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7948 \tTest_loss: 551.3066 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8187 \tTime: 5.7501\n",
      "Epoch: 142 \tTrain_loss: 604.4862 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7964 \tTest_loss: 550.1252 \tTest_accuracy: 0.8084 \tTest_accuracy_1: 0.8125 \tTime: 5.7167\n",
      "Epoch: 143 \tTrain_loss: 603.6261 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7985 \tTest_loss: 557.3681 \tTest_accuracy: 0.8047 \tTest_accuracy_1: 0.8107 \tTime: 5.7179\n",
      "Epoch: 144 \tTrain_loss: 604.3861 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7960 \tTest_loss: 553.7046 \tTest_accuracy: 0.8047 \tTest_accuracy_1: 0.8091 \tTime: 5.7897\n",
      "Epoch: 145 \tTrain_loss: 602.8104 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7962 \tTest_loss: 555.0471 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8150 \tTime: 5.7402\n",
      "Epoch: 146 \tTrain_loss: 600.0962 \tTrain_accuracy: 0.7973 \tTrain_accuracy_1: 0.7983 \tTest_loss: 561.5406 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8119 \tTime: 5.7219\n",
      "Epoch: 147 \tTrain_loss: 605.0836 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7961 \tTest_loss: 558.4399 \tTest_accuracy: 0.8005 \tTest_accuracy_1: 0.8104 \tTime: 5.7022\n",
      "Epoch: 148 \tTrain_loss: 602.3649 \tTrain_accuracy: 0.7968 \tTrain_accuracy_1: 0.7977 \tTest_loss: 554.0190 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8180 \tTime: 5.7689\n",
      "Epoch: 149 \tTrain_loss: 604.4504 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7959 \tTest_loss: 555.6429 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8114 \tTime: 5.7267\n",
      "Epoch: 150 \tTrain_loss: 606.0747 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7983 \tTest_loss: 561.1043 \tTest_accuracy: 0.7998 \tTest_accuracy_1: 0.8129 \tTime: 5.7119\n",
      "Epoch: 151 \tTrain_loss: 602.8735 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7977 \tTest_loss: 556.7789 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8126 \tTime: 5.7068\n",
      "Epoch: 152 \tTrain_loss: 606.4654 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7934 \tTest_loss: 555.0884 \tTest_accuracy: 0.8070 \tTest_accuracy_1: 0.8128 \tTime: 5.7939\n",
      "Epoch: 153 \tTrain_loss: 604.8881 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7957 \tTest_loss: 555.4577 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8170 \tTime: 5.7504\n",
      "Epoch: 154 \tTrain_loss: 605.2818 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7937 \tTest_loss: 560.1003 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8101 \tTime: 5.7072\n",
      "Epoch: 155 \tTrain_loss: 604.1639 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7943 \tTest_loss: 553.9709 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.8150 \tTime: 5.7089\n",
      "Epoch: 156 \tTrain_loss: 603.8010 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7965 \tTest_loss: 554.8491 \tTest_accuracy: 0.8061 \tTest_accuracy_1: 0.8157 \tTime: 5.7884\n",
      "Epoch: 157 \tTrain_loss: 607.1852 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7944 \tTest_loss: 555.2038 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8097 \tTime: 5.7704\n",
      "Epoch: 158 \tTrain_loss: 607.5437 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7943 \tTest_loss: 557.0016 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8101 \tTime: 5.7188\n",
      "Epoch: 159 \tTrain_loss: 602.0846 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7955 \tTest_loss: 562.9032 \tTest_accuracy: 0.8007 \tTest_accuracy_1: 0.8054 \tTime: 5.7457\n",
      "Epoch: 160 \tTrain_loss: 604.0037 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7965 \tTest_loss: 548.6960 \tTest_accuracy: 0.8052 \tTest_accuracy_1: 0.8163 \tTime: 5.7433\n",
      "Epoch: 161 \tTrain_loss: 607.2428 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7941 \tTest_loss: 558.4589 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8120 \tTime: 5.7580\n",
      "Epoch: 162 \tTrain_loss: 604.6551 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7968 \tTest_loss: 552.4659 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8128 \tTime: 5.7213\n",
      "Epoch: 163 \tTrain_loss: 608.6694 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7930 \tTest_loss: 546.9469 \tTest_accuracy: 0.8077 \tTest_accuracy_1: 0.8210 \tTime: 5.7946\n",
      "Epoch: 164 \tTrain_loss: 606.7615 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7961 \tTest_loss: 559.8667 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8155 \tTime: 5.7586\n",
      "Epoch: 165 \tTrain_loss: 605.1409 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7969 \tTest_loss: 552.6633 \tTest_accuracy: 0.8045 \tTest_accuracy_1: 0.8161 \tTime: 5.7264\n",
      "Epoch: 166 \tTrain_loss: 603.6892 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7968 \tTest_loss: 561.3906 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8120 \tTime: 5.7631\n",
      "Epoch: 167 \tTrain_loss: 604.3776 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7968 \tTest_loss: 567.5469 \tTest_accuracy: 0.8005 \tTest_accuracy_1: 0.8097 \tTime: 5.6931\n",
      "Epoch: 168 \tTrain_loss: 604.4295 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7978 \tTest_loss: 560.0405 \tTest_accuracy: 0.8021 \tTest_accuracy_1: 0.8116 \tTime: 5.7320\n",
      "Epoch: 169 \tTrain_loss: 607.1654 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7956 \tTest_loss: 559.9015 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8152 \tTime: 5.7722\n",
      "Epoch: 170 \tTrain_loss: 602.3703 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7966 \tTest_loss: 554.2630 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8125 \tTime: 5.9741\n",
      "Epoch: 171 \tTrain_loss: 604.0617 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7940 \tTest_loss: 561.1870 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8062 \tTime: 5.7784\n",
      "Epoch: 172 \tTrain_loss: 599.6270 \tTrain_accuracy: 0.7970 \tTrain_accuracy_1: 0.7984 \tTest_loss: 560.6684 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8122 \tTime: 5.7244\n",
      "Epoch: 173 \tTrain_loss: 611.6412 \tTrain_accuracy: 0.7933 \tTrain_accuracy_1: 0.7930 \tTest_loss: 563.6686 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8079 \tTime: 5.7651\n",
      "Epoch: 174 \tTrain_loss: 601.9292 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7978 \tTest_loss: 557.9105 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.8146 \tTime: 5.7590\n",
      "Epoch: 175 \tTrain_loss: 606.2726 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7936 \tTest_loss: 557.2432 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8127 \tTime: 5.7735\n",
      "Epoch: 176 \tTrain_loss: 603.7972 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7953 \tTest_loss: 551.6917 \tTest_accuracy: 0.8068 \tTest_accuracy_1: 0.8151 \tTime: 5.7391\n",
      "Epoch: 177 \tTrain_loss: 604.9765 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7963 \tTest_loss: 553.6754 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8145 \tTime: 5.8615\n",
      "Epoch: 178 \tTrain_loss: 602.0000 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7980 \tTest_loss: 553.5198 \tTest_accuracy: 0.8067 \tTest_accuracy_1: 0.8126 \tTime: 5.7886\n",
      "Epoch: 179 \tTrain_loss: 607.5985 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7941 \tTest_loss: 557.1073 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8136 \tTime: 5.7635\n",
      "Epoch: 180 \tTrain_loss: 605.1097 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7957 \tTest_loss: 560.8558 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.8124 \tTime: 5.7547\n",
      "Epoch: 181 \tTrain_loss: 603.4094 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7958 \tTest_loss: 561.9678 \tTest_accuracy: 0.7998 \tTest_accuracy_1: 0.8057 \tTime: 5.7399\n",
      "Epoch: 182 \tTrain_loss: 603.8311 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7946 \tTest_loss: 559.4708 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8119 \tTime: 5.7377\n",
      "Epoch: 183 \tTrain_loss: 604.6645 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7956 \tTest_loss: 551.1964 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8160 \tTime: 5.7584\n",
      "Epoch: 184 \tTrain_loss: 606.9743 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7935 \tTest_loss: 554.6887 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8138 \tTime: 5.7851\n",
      "Epoch: 185 \tTrain_loss: 604.3016 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7945 \tTest_loss: 558.8057 \tTest_accuracy: 0.8066 \tTest_accuracy_1: 0.8092 \tTime: 5.7539\n",
      "Epoch: 186 \tTrain_loss: 601.7924 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7974 \tTest_loss: 553.4500 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8155 \tTime: 5.7419\n",
      "Epoch: 187 \tTrain_loss: 602.9972 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7975 \tTest_loss: 551.3986 \tTest_accuracy: 0.8070 \tTest_accuracy_1: 0.8225 \tTime: 5.7517\n",
      "Epoch: 188 \tTrain_loss: 604.8065 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7961 \tTest_loss: 554.5536 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8176 \tTime: 5.7262\n",
      "Epoch: 189 \tTrain_loss: 606.3328 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7953 \tTest_loss: 554.7105 \tTest_accuracy: 0.8059 \tTest_accuracy_1: 0.8150 \tTime: 5.7468\n",
      "Epoch: 190 \tTrain_loss: 608.1613 \tTrain_accuracy: 0.7930 \tTrain_accuracy_1: 0.7935 \tTest_loss: 554.6784 \tTest_accuracy: 0.8047 \tTest_accuracy_1: 0.8146 \tTime: 5.7642\n",
      "Epoch: 191 \tTrain_loss: 604.8659 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7946 \tTest_loss: 554.0331 \tTest_accuracy: 0.8060 \tTest_accuracy_1: 0.8139 \tTime: 5.7911\n",
      "Epoch: 192 \tTrain_loss: 605.6052 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7948 \tTest_loss: 556.2715 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8159 \tTime: 5.7618\n",
      "Epoch: 193 \tTrain_loss: 605.0979 \tTrain_accuracy: 0.7965 \tTrain_accuracy_1: 0.7944 \tTest_loss: 564.7631 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8096 \tTime: 5.8221\n",
      "Epoch: 194 \tTrain_loss: 608.9943 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7943 \tTest_loss: 557.4579 \tTest_accuracy: 0.8050 \tTest_accuracy_1: 0.8135 \tTime: 5.7573\n",
      "Epoch: 195 \tTrain_loss: 604.1803 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7973 \tTest_loss: 554.1801 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8152 \tTime: 5.7742\n",
      "Epoch: 196 \tTrain_loss: 604.0109 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7968 \tTest_loss: 557.8535 \tTest_accuracy: 0.8051 \tTest_accuracy_1: 0.8141 \tTime: 5.7387\n",
      "Epoch: 197 \tTrain_loss: 603.8486 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.7977 \tTest_loss: 555.2839 \tTest_accuracy: 0.8052 \tTest_accuracy_1: 0.8131 \tTime: 5.7664\n",
      "Epoch: 198 \tTrain_loss: 599.1505 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7981 \tTest_loss: 554.6258 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8137 \tTime: 5.9192\n",
      "Epoch: 199 \tTrain_loss: 606.4825 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7947 \tTest_loss: 567.4686 \tTest_accuracy: 0.7982 \tTest_accuracy_1: 0.8097 \tTime: 5.7817\n",
      "Epoch: 200 \tTrain_loss: 599.7853 \tTrain_accuracy: 0.7976 \tTrain_accuracy_1: 0.8008 \tTest_loss: 552.5989 \tTest_accuracy: 0.8055 \tTest_accuracy_1: 0.8165 \tTime: 5.8451\n",
      "Epoch: 201 \tTrain_loss: 601.5019 \tTrain_accuracy: 0.7973 \tTrain_accuracy_1: 0.7991 \tTest_loss: 560.9168 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8085 \tTime: 5.8048\n",
      "Epoch: 202 \tTrain_loss: 606.1690 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7958 \tTest_loss: 549.0326 \tTest_accuracy: 0.8063 \tTest_accuracy_1: 0.8163 \tTime: 5.7421\n",
      "Epoch: 203 \tTrain_loss: 602.1485 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7974 \tTest_loss: 559.2106 \tTest_accuracy: 0.8014 \tTest_accuracy_1: 0.8115 \tTime: 5.7780\n",
      "Epoch: 204 \tTrain_loss: 605.8976 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7953 \tTest_loss: 560.1844 \tTest_accuracy: 0.8033 \tTest_accuracy_1: 0.8096 \tTime: 5.7944\n",
      "Epoch: 205 \tTrain_loss: 605.1437 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7958 \tTest_loss: 555.8033 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8169 \tTime: 5.7860\n",
      "Epoch: 206 \tTrain_loss: 600.7510 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.7988 \tTest_loss: 555.5564 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8184 \tTime: 5.7705\n",
      "Epoch: 207 \tTrain_loss: 605.5189 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7958 \tTest_loss: 558.1991 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8122 \tTime: 5.7720\n",
      "Epoch: 208 \tTrain_loss: 604.3343 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7947 \tTest_loss: 557.9158 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8175 \tTime: 5.7552\n",
      "Epoch: 209 \tTrain_loss: 606.8459 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7947 \tTest_loss: 559.7044 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8087 \tTime: 5.7339\n",
      "Epoch: 210 \tTrain_loss: 604.5011 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7970 \tTest_loss: 560.0989 \tTest_accuracy: 0.7988 \tTest_accuracy_1: 0.8116 \tTime: 5.7356\n",
      "Epoch: 211 \tTrain_loss: 605.5680 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7953 \tTest_loss: 563.3330 \tTest_accuracy: 0.7987 \tTest_accuracy_1: 0.8088 \tTime: 5.7768\n",
      "Epoch: 212 \tTrain_loss: 605.2643 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7961 \tTest_loss: 562.1592 \tTest_accuracy: 0.7997 \tTest_accuracy_1: 0.8123 \tTime: 5.8012\n",
      "Epoch: 213 \tTrain_loss: 605.0683 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7961 \tTest_loss: 559.8327 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8125 \tTime: 5.7842\n",
      "Epoch: 214 \tTrain_loss: 604.2993 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7945 \tTest_loss: 553.9819 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8168 \tTime: 5.7666\n",
      "Epoch: 215 \tTrain_loss: 602.8530 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7954 \tTest_loss: 556.8542 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8132 \tTime: 5.8037\n",
      "Epoch: 216 \tTrain_loss: 604.3223 \tTrain_accuracy: 0.7965 \tTrain_accuracy_1: 0.7986 \tTest_loss: 563.2868 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8138 \tTime: 5.7489\n",
      "Epoch: 217 \tTrain_loss: 606.1432 \tTrain_accuracy: 0.7937 \tTrain_accuracy_1: 0.7951 \tTest_loss: 554.9647 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8143 \tTime: 5.7675\n",
      "Epoch: 218 \tTrain_loss: 605.1272 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7945 \tTest_loss: 562.9219 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8115 \tTime: 5.8743\n",
      "Epoch: 219 \tTrain_loss: 603.4086 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7972 \tTest_loss: 554.5216 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8140 \tTime: 5.9412\n",
      "Epoch: 220 \tTrain_loss: 608.1997 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7935 \tTest_loss: 552.8400 \tTest_accuracy: 0.8058 \tTest_accuracy_1: 0.8177 \tTime: 6.3131\n",
      "Epoch: 221 \tTrain_loss: 607.5841 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7917 \tTest_loss: 552.2924 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8171 \tTime: 6.0152\n",
      "Epoch: 222 \tTrain_loss: 604.3867 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7954 \tTest_loss: 561.2292 \tTest_accuracy: 0.8017 \tTest_accuracy_1: 0.8116 \tTime: 5.8599\n",
      "Epoch: 223 \tTrain_loss: 604.6675 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7973 \tTest_loss: 561.4322 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.8109 \tTime: 5.9496\n",
      "Epoch: 224 \tTrain_loss: 600.6680 \tTrain_accuracy: 0.7982 \tTrain_accuracy_1: 0.8023 \tTest_loss: 555.9488 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8120 \tTime: 5.8106\n",
      "Epoch: 225 \tTrain_loss: 602.2433 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7972 \tTest_loss: 566.9984 \tTest_accuracy: 0.7988 \tTest_accuracy_1: 0.8067 \tTime: 5.8406\n",
      "Epoch: 226 \tTrain_loss: 606.8889 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7961 \tTest_loss: 554.9543 \tTest_accuracy: 0.8065 \tTest_accuracy_1: 0.8125 \tTime: 5.8691\n",
      "Epoch: 227 \tTrain_loss: 604.4553 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7942 \tTest_loss: 564.2953 \tTest_accuracy: 0.7999 \tTest_accuracy_1: 0.8103 \tTime: 6.2258\n",
      "Epoch: 228 \tTrain_loss: 606.9215 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7947 \tTest_loss: 560.4445 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.8102 \tTime: 7.0204\n",
      "Epoch: 229 \tTrain_loss: 607.8145 \tTrain_accuracy: 0.7938 \tTrain_accuracy_1: 0.7925 \tTest_loss: 552.3797 \tTest_accuracy: 0.8059 \tTest_accuracy_1: 0.8210 \tTime: 6.1439\n",
      "Epoch: 230 \tTrain_loss: 606.4692 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7969 \tTest_loss: 552.9365 \tTest_accuracy: 0.8060 \tTest_accuracy_1: 0.8166 \tTime: 6.0806\n",
      "Epoch: 231 \tTrain_loss: 603.4582 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7968 \tTest_loss: 561.0326 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8119 \tTime: 6.5640\n",
      "Epoch: 232 \tTrain_loss: 606.5049 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7952 \tTest_loss: 555.2386 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8133 \tTime: 7.4825\n",
      "Epoch: 233 \tTrain_loss: 607.0684 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7938 \tTest_loss: 560.5109 \tTest_accuracy: 0.7995 \tTest_accuracy_1: 0.8124 \tTime: 7.2261\n",
      "Epoch: 234 \tTrain_loss: 605.4402 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7958 \tTest_loss: 554.3879 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8092 \tTime: 6.6957\n",
      "Epoch: 235 \tTrain_loss: 603.8691 \tTrain_accuracy: 0.7968 \tTrain_accuracy_1: 0.7977 \tTest_loss: 557.3826 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8121 \tTime: 6.3816\n",
      "Epoch: 236 \tTrain_loss: 602.0357 \tTrain_accuracy: 0.7967 \tTrain_accuracy_1: 0.8005 \tTest_loss: 562.9400 \tTest_accuracy: 0.7996 \tTest_accuracy_1: 0.8050 \tTime: 6.0275\n",
      "Epoch: 237 \tTrain_loss: 606.1938 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7958 \tTest_loss: 560.2194 \tTest_accuracy: 0.7985 \tTest_accuracy_1: 0.8094 \tTime: 6.8341\n",
      "Epoch: 238 \tTrain_loss: 602.8690 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7967 \tTest_loss: 557.5506 \tTest_accuracy: 0.8049 \tTest_accuracy_1: 0.8153 \tTime: 6.2190\n",
      "Epoch: 239 \tTrain_loss: 604.6930 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7960 \tTest_loss: 561.2925 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8068 \tTime: 6.2486\n",
      "Epoch: 240 \tTrain_loss: 604.2922 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7950 \tTest_loss: 552.0819 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8087 \tTime: 6.3619\n",
      "Epoch: 241 \tTrain_loss: 600.6863 \tTrain_accuracy: 0.7965 \tTrain_accuracy_1: 0.7988 \tTest_loss: 559.6123 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8092 \tTime: 6.1047\n",
      "Epoch: 242 \tTrain_loss: 607.2714 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7969 \tTest_loss: 557.3480 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8149 \tTime: 6.3855\n",
      "Epoch: 243 \tTrain_loss: 605.4017 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7951 \tTest_loss: 558.5286 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8154 \tTime: 6.0165\n",
      "Epoch: 244 \tTrain_loss: 606.0150 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7943 \tTest_loss: 557.2324 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8143 \tTime: 6.3554\n",
      "Epoch: 245 \tTrain_loss: 605.9294 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7944 \tTest_loss: 555.7302 \tTest_accuracy: 0.8075 \tTest_accuracy_1: 0.8109 \tTime: 5.9373\n",
      "Epoch: 246 \tTrain_loss: 604.0455 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7946 \tTest_loss: 553.8530 \tTest_accuracy: 0.8058 \tTest_accuracy_1: 0.8181 \tTime: 6.1905\n",
      "Epoch: 247 \tTrain_loss: 601.8453 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7966 \tTest_loss: 551.8773 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8106 \tTime: 6.1970\n",
      "Epoch: 248 \tTrain_loss: 603.0352 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7956 \tTest_loss: 557.2711 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8089 \tTime: 5.8625\n",
      "Epoch: 249 \tTrain_loss: 603.1249 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7954 \tTest_loss: 559.3038 \tTest_accuracy: 0.8005 \tTest_accuracy_1: 0.8085 \tTime: 5.9713\n",
      "Epoch: 250 \tTrain_loss: 601.6336 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7952 \tTest_loss: 560.3975 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8096 \tTime: 6.0859\n",
      "Epoch: 251 \tTrain_loss: 605.5839 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7936 \tTest_loss: 550.8058 \tTest_accuracy: 0.8064 \tTest_accuracy_1: 0.8187 \tTime: 6.3744\n",
      "Epoch: 252 \tTrain_loss: 603.0302 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7985 \tTest_loss: 550.1113 \tTest_accuracy: 0.8049 \tTest_accuracy_1: 0.8184 \tTime: 7.1045\n",
      "Epoch: 253 \tTrain_loss: 605.0195 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7974 \tTest_loss: 551.1943 \tTest_accuracy: 0.8051 \tTest_accuracy_1: 0.8181 \tTime: 6.2299\n",
      "Epoch: 254 \tTrain_loss: 601.8966 \tTrain_accuracy: 0.7970 \tTrain_accuracy_1: 0.7972 \tTest_loss: 557.1124 \tTest_accuracy: 0.8062 \tTest_accuracy_1: 0.8110 \tTime: 6.2579\n",
      "Epoch: 255 \tTrain_loss: 606.6369 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7949 \tTest_loss: 549.2557 \tTest_accuracy: 0.8058 \tTest_accuracy_1: 0.8155 \tTime: 6.2206\n",
      "Epoch: 256 \tTrain_loss: 605.8773 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7966 \tTest_loss: 551.5003 \tTest_accuracy: 0.8067 \tTest_accuracy_1: 0.8193 \tTime: 6.3198\n",
      "Epoch: 257 \tTrain_loss: 599.6849 \tTrain_accuracy: 0.7972 \tTrain_accuracy_1: 0.7991 \tTest_loss: 561.5031 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8133 \tTime: 6.3570\n",
      "Epoch: 258 \tTrain_loss: 606.1026 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7949 \tTest_loss: 550.9205 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8131 \tTime: 6.8456\n",
      "Epoch: 259 \tTrain_loss: 604.7835 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7950 \tTest_loss: 551.2669 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8190 \tTime: 6.1596\n",
      "Epoch: 260 \tTrain_loss: 606.0191 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7975 \tTest_loss: 554.6014 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8153 \tTime: 5.9253\n",
      "Epoch: 261 \tTrain_loss: 603.1737 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7978 \tTest_loss: 563.6335 \tTest_accuracy: 0.7998 \tTest_accuracy_1: 0.8082 \tTime: 6.3554\n",
      "Epoch: 262 \tTrain_loss: 604.6583 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7940 \tTest_loss: 556.9504 \tTest_accuracy: 0.7988 \tTest_accuracy_1: 0.8124 \tTime: 6.4488\n",
      "Epoch: 263 \tTrain_loss: 608.3395 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7913 \tTest_loss: 562.1392 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8093 \tTime: 6.0994\n",
      "Epoch: 264 \tTrain_loss: 601.4046 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7964 \tTest_loss: 559.3807 \tTest_accuracy: 0.7999 \tTest_accuracy_1: 0.8133 \tTime: 6.0721\n",
      "Epoch: 265 \tTrain_loss: 603.4481 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7964 \tTest_loss: 554.8147 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8136 \tTime: 6.0732\n",
      "Epoch: 266 \tTrain_loss: 607.5214 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7955 \tTest_loss: 555.1863 \tTest_accuracy: 0.8050 \tTest_accuracy_1: 0.8133 \tTime: 5.8955\n",
      "Epoch: 267 \tTrain_loss: 603.6373 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7967 \tTest_loss: 556.6740 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8097 \tTime: 5.8248\n",
      "Epoch: 268 \tTrain_loss: 604.4662 \tTrain_accuracy: 0.7965 \tTrain_accuracy_1: 0.7976 \tTest_loss: 550.3408 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8168 \tTime: 6.2847\n",
      "Epoch: 269 \tTrain_loss: 605.8540 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7938 \tTest_loss: 553.8516 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8136 \tTime: 6.3350\n",
      "Epoch: 270 \tTrain_loss: 603.7157 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7957 \tTest_loss: 552.3965 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8163 \tTime: 6.8340\n",
      "Epoch: 271 \tTrain_loss: 603.3482 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7966 \tTest_loss: 553.8713 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8181 \tTime: 6.9360\n",
      "Epoch: 272 \tTrain_loss: 600.7846 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7981 \tTest_loss: 558.4443 \tTest_accuracy: 0.8045 \tTest_accuracy_1: 0.8127 \tTime: 7.1351\n",
      "Epoch: 273 \tTrain_loss: 602.1743 \tTrain_accuracy: 0.7977 \tTrain_accuracy_1: 0.7981 \tTest_loss: 555.9238 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8136 \tTime: 6.3298\n",
      "Epoch: 274 \tTrain_loss: 606.1868 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7958 \tTest_loss: 555.8659 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8136 \tTime: 6.1177\n",
      "Epoch: 275 \tTrain_loss: 601.0599 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7980 \tTest_loss: 558.0577 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8094 \tTime: 6.6724\n",
      "Epoch: 276 \tTrain_loss: 604.0679 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7942 \tTest_loss: 547.9479 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8194 \tTime: 6.1416\n",
      "Epoch: 277 \tTrain_loss: 605.4416 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7947 \tTest_loss: 560.0544 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8118 \tTime: 6.0849\n",
      "Epoch: 278 \tTrain_loss: 604.8630 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7953 \tTest_loss: 552.8960 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8146 \tTime: 6.1043\n",
      "Epoch: 279 \tTrain_loss: 606.7162 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7942 \tTest_loss: 556.7524 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8134 \tTime: 6.3629\n",
      "Epoch: 280 \tTrain_loss: 606.1661 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7959 \tTest_loss: 561.1312 \tTest_accuracy: 0.8005 \tTest_accuracy_1: 0.8109 \tTime: 5.9824\n",
      "Epoch: 281 \tTrain_loss: 605.7777 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7973 \tTest_loss: 554.5067 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8216 \tTime: 5.7997\n",
      "Epoch: 282 \tTrain_loss: 605.7385 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7963 \tTest_loss: 558.2810 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8085 \tTime: 5.9803\n",
      "Epoch: 283 \tTrain_loss: 604.2423 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7966 \tTest_loss: 562.7213 \tTest_accuracy: 0.8001 \tTest_accuracy_1: 0.8080 \tTime: 5.9051\n",
      "Epoch: 284 \tTrain_loss: 607.1739 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7909 \tTest_loss: 550.3401 \tTest_accuracy: 0.8043 \tTest_accuracy_1: 0.8171 \tTime: 5.9488\n",
      "Epoch: 285 \tTrain_loss: 603.6721 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7965 \tTest_loss: 564.1063 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.8090 \tTime: 5.8833\n",
      "Epoch: 286 \tTrain_loss: 606.7452 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7942 \tTest_loss: 554.4691 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8109 \tTime: 6.0322\n",
      "Epoch: 287 \tTrain_loss: 600.7113 \tTrain_accuracy: 0.7966 \tTrain_accuracy_1: 0.7957 \tTest_loss: 558.8542 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8148 \tTime: 6.0271\n",
      "Epoch: 288 \tTrain_loss: 605.9960 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7969 \tTest_loss: 557.8181 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8123 \tTime: 6.3531\n",
      "Epoch: 289 \tTrain_loss: 602.8218 \tTrain_accuracy: 0.7968 \tTrain_accuracy_1: 0.7992 \tTest_loss: 556.2703 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.8125 \tTime: 6.2111\n",
      "Epoch: 290 \tTrain_loss: 603.6414 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7944 \tTest_loss: 551.7114 \tTest_accuracy: 0.8052 \tTest_accuracy_1: 0.8146 \tTime: 6.2032\n",
      "Epoch: 291 \tTrain_loss: 603.3757 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7959 \tTest_loss: 559.9022 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8140 \tTime: 6.2931\n",
      "Epoch: 292 \tTrain_loss: 604.0359 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7929 \tTest_loss: 554.9990 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8095 \tTime: 6.0909\n",
      "Epoch: 293 \tTrain_loss: 607.9521 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7906 \tTest_loss: 555.0548 \tTest_accuracy: 0.8051 \tTest_accuracy_1: 0.8138 \tTime: 6.5866\n",
      "Epoch: 294 \tTrain_loss: 604.9896 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7952 \tTest_loss: 561.2155 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8145 \tTime: 6.0136\n",
      "Epoch: 295 \tTrain_loss: 603.9584 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7973 \tTest_loss: 558.9935 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8155 \tTime: 6.1024\n",
      "Epoch: 296 \tTrain_loss: 604.9548 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7972 \tTest_loss: 557.8226 \tTest_accuracy: 0.8007 \tTest_accuracy_1: 0.8138 \tTime: 6.8822\n",
      "Epoch: 297 \tTrain_loss: 602.5498 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7994 \tTest_loss: 558.1310 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8136 \tTime: 6.4407\n",
      "Epoch: 298 \tTrain_loss: 601.0194 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7976 \tTest_loss: 558.4682 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8141 \tTime: 6.1231\n",
      "Epoch: 299 \tTrain_loss: 607.4708 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7929 \tTest_loss: 555.5761 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8140 \tTime: 6.1536\n",
      "Epoch: 300 \tTrain_loss: 601.5688 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7965 \tTest_loss: 560.6646 \tTest_accuracy: 0.8006 \tTest_accuracy_1: 0.8097 \tTime: 6.0103\n",
      "Epoch: 301 \tTrain_loss: 601.2523 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7996 \tTest_loss: 566.5357 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8089 \tTime: 6.0909\n",
      "Epoch: 302 \tTrain_loss: 602.4096 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7987 \tTest_loss: 547.7955 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8190 \tTime: 6.3032\n",
      "Epoch: 303 \tTrain_loss: 603.1567 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7956 \tTest_loss: 563.2254 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8084 \tTime: 6.0193\n",
      "Epoch: 304 \tTrain_loss: 603.6372 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7977 \tTest_loss: 562.4218 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8112 \tTime: 5.7697\n",
      "Epoch: 305 \tTrain_loss: 602.8460 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7981 \tTest_loss: 556.9603 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8168 \tTime: 5.7845\n",
      "Epoch: 306 \tTrain_loss: 600.4035 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7977 \tTest_loss: 552.0588 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8165 \tTime: 5.9035\n",
      "Epoch: 307 \tTrain_loss: 607.1251 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7965 \tTest_loss: 559.6320 \tTest_accuracy: 0.8063 \tTest_accuracy_1: 0.8140 \tTime: 6.1111\n",
      "Epoch: 308 \tTrain_loss: 606.4246 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7963 \tTest_loss: 551.3002 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8128 \tTime: 5.8154\n",
      "Epoch: 309 \tTrain_loss: 603.6449 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7971 \tTest_loss: 556.6339 \tTest_accuracy: 0.8006 \tTest_accuracy_1: 0.8111 \tTime: 6.3613\n",
      "Epoch: 310 \tTrain_loss: 604.6931 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7959 \tTest_loss: 561.6743 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8069 \tTime: 6.6466\n",
      "Epoch: 311 \tTrain_loss: 606.8764 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7970 \tTest_loss: 554.5955 \tTest_accuracy: 0.8058 \tTest_accuracy_1: 0.8166 \tTime: 6.5131\n",
      "Epoch: 312 \tTrain_loss: 605.8929 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7951 \tTest_loss: 558.9290 \tTest_accuracy: 0.7990 \tTest_accuracy_1: 0.8096 \tTime: 6.5094\n",
      "Epoch: 313 \tTrain_loss: 604.1963 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7962 \tTest_loss: 557.7180 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8138 \tTime: 6.7037\n",
      "Epoch: 314 \tTrain_loss: 605.1239 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7966 \tTest_loss: 555.9466 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8158 \tTime: 6.3825\n",
      "Epoch: 315 \tTrain_loss: 605.9745 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7954 \tTest_loss: 558.9236 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8097 \tTime: 6.8910\n",
      "Epoch: 316 \tTrain_loss: 602.6764 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7994 \tTest_loss: 557.0136 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8152 \tTime: 6.3321\n",
      "Epoch: 317 \tTrain_loss: 604.7272 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7969 \tTest_loss: 553.8661 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8155 \tTime: 6.2778\n",
      "Epoch: 318 \tTrain_loss: 603.8465 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7935 \tTest_loss: 555.6364 \tTest_accuracy: 0.8066 \tTest_accuracy_1: 0.8124 \tTime: 6.3915\n",
      "Epoch: 319 \tTrain_loss: 608.7565 \tTrain_accuracy: 0.7936 \tTrain_accuracy_1: 0.7938 \tTest_loss: 553.0392 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8174 \tTime: 6.5729\n",
      "Epoch: 320 \tTrain_loss: 603.6091 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7954 \tTest_loss: 558.9769 \tTest_accuracy: 0.8001 \tTest_accuracy_1: 0.8085 \tTime: 6.0935\n",
      "Epoch: 321 \tTrain_loss: 607.9200 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7911 \tTest_loss: 555.8616 \tTest_accuracy: 0.8061 \tTest_accuracy_1: 0.8092 \tTime: 6.2128\n",
      "Epoch: 322 \tTrain_loss: 608.4791 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7922 \tTest_loss: 559.5666 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8064 \tTime: 5.8870\n",
      "Epoch: 323 \tTrain_loss: 603.2243 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7969 \tTest_loss: 562.5035 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8112 \tTime: 6.0133\n",
      "Epoch: 324 \tTrain_loss: 605.9822 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7920 \tTest_loss: 553.1095 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8179 \tTime: 6.0241\n",
      "Epoch: 325 \tTrain_loss: 603.4903 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7985 \tTest_loss: 558.3619 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8161 \tTime: 6.0267\n",
      "Epoch: 326 \tTrain_loss: 605.2660 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7970 \tTest_loss: 554.8967 \tTest_accuracy: 0.8050 \tTest_accuracy_1: 0.8181 \tTime: 5.9416\n",
      "Epoch: 327 \tTrain_loss: 603.3852 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7959 \tTest_loss: 555.2433 \tTest_accuracy: 0.8033 \tTest_accuracy_1: 0.8123 \tTime: 6.9877\n",
      "Epoch: 328 \tTrain_loss: 605.7993 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7960 \tTest_loss: 556.0562 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8124 \tTime: 5.9559\n",
      "Epoch: 329 \tTrain_loss: 604.9307 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7948 \tTest_loss: 555.8180 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8147 \tTime: 5.9499\n",
      "Epoch: 330 \tTrain_loss: 606.1150 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7954 \tTest_loss: 558.8931 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8142 \tTime: 6.0059\n",
      "Epoch: 331 \tTrain_loss: 603.3553 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7988 \tTest_loss: 562.7242 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8105 \tTime: 5.9459\n",
      "Epoch: 332 \tTrain_loss: 610.0834 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7937 \tTest_loss: 563.2003 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8102 \tTime: 5.8796\n",
      "Epoch: 333 \tTrain_loss: 605.4887 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7961 \tTest_loss: 551.5217 \tTest_accuracy: 0.8058 \tTest_accuracy_1: 0.8185 \tTime: 5.9043\n",
      "Epoch: 334 \tTrain_loss: 607.3688 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7948 \tTest_loss: 554.2433 \tTest_accuracy: 0.8033 \tTest_accuracy_1: 0.8103 \tTime: 6.0391\n",
      "Epoch: 335 \tTrain_loss: 605.1618 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7926 \tTest_loss: 562.9244 \tTest_accuracy: 0.7998 \tTest_accuracy_1: 0.8105 \tTime: 6.1485\n",
      "Epoch: 336 \tTrain_loss: 604.5664 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7970 \tTest_loss: 548.3683 \tTest_accuracy: 0.8072 \tTest_accuracy_1: 0.8164 \tTime: 5.8921\n",
      "Epoch: 337 \tTrain_loss: 605.1824 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7961 \tTest_loss: 551.0844 \tTest_accuracy: 0.8069 \tTest_accuracy_1: 0.8179 \tTime: 5.9431\n",
      "Epoch: 338 \tTrain_loss: 602.5305 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7966 \tTest_loss: 553.1725 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8125 \tTime: 5.9519\n",
      "Epoch: 339 \tTrain_loss: 603.7252 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7971 \tTest_loss: 559.1396 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8118 \tTime: 5.9706\n",
      "Epoch: 340 \tTrain_loss: 605.1140 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7957 \tTest_loss: 550.9680 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8161 \tTime: 5.8385\n",
      "Epoch: 341 \tTrain_loss: 600.4640 \tTrain_accuracy: 0.7973 \tTrain_accuracy_1: 0.7974 \tTest_loss: 555.7239 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8140 \tTime: 5.8818\n",
      "Epoch: 342 \tTrain_loss: 607.4681 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7936 \tTest_loss: 563.6935 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.8114 \tTime: 6.0021\n",
      "Epoch: 343 \tTrain_loss: 606.1441 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7981 \tTest_loss: 556.6553 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8127 \tTime: 6.1802\n",
      "Epoch: 344 \tTrain_loss: 603.0384 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7957 \tTest_loss: 554.3455 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8141 \tTime: 5.9153\n",
      "Epoch: 345 \tTrain_loss: 604.2782 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7965 \tTest_loss: 559.5103 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8128 \tTime: 5.9030\n",
      "Epoch: 346 \tTrain_loss: 603.5423 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7992 \tTest_loss: 558.6982 \tTest_accuracy: 0.8004 \tTest_accuracy_1: 0.8091 \tTime: 5.9510\n",
      "Epoch: 347 \tTrain_loss: 605.5664 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7956 \tTest_loss: 560.3320 \tTest_accuracy: 0.8043 \tTest_accuracy_1: 0.8136 \tTime: 6.5011\n",
      "Epoch: 348 \tTrain_loss: 605.8007 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7930 \tTest_loss: 554.5963 \tTest_accuracy: 0.8061 \tTest_accuracy_1: 0.8179 \tTime: 6.3612\n",
      "Epoch: 349 \tTrain_loss: 606.7928 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7971 \tTest_loss: 556.4913 \tTest_accuracy: 0.8013 \tTest_accuracy_1: 0.8152 \tTime: 5.8027\n",
      "Epoch: 350 \tTrain_loss: 608.4999 \tTrain_accuracy: 0.7921 \tTrain_accuracy_1: 0.7929 \tTest_loss: 556.2241 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8142 \tTime: 6.0643\n",
      "Epoch: 351 \tTrain_loss: 602.7808 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7976 \tTest_loss: 552.5123 \tTest_accuracy: 0.8050 \tTest_accuracy_1: 0.8171 \tTime: 6.2088\n",
      "Epoch: 352 \tTrain_loss: 605.1812 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7964 \tTest_loss: 559.2418 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8105 \tTime: 6.3498\n",
      "Epoch: 353 \tTrain_loss: 603.2981 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7975 \tTest_loss: 551.2863 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8188 \tTime: 6.4109\n",
      "Epoch: 354 \tTrain_loss: 606.8005 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7953 \tTest_loss: 554.9707 \tTest_accuracy: 0.8072 \tTest_accuracy_1: 0.8172 \tTime: 6.1671\n",
      "Epoch: 355 \tTrain_loss: 606.6986 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7946 \tTest_loss: 550.5508 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8167 \tTime: 6.0470\n",
      "Epoch: 356 \tTrain_loss: 609.1627 \tTrain_accuracy: 0.7931 \tTrain_accuracy_1: 0.7918 \tTest_loss: 559.0938 \tTest_accuracy: 0.8052 \tTest_accuracy_1: 0.8154 \tTime: 5.9803\n",
      "Epoch: 357 \tTrain_loss: 604.0066 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7978 \tTest_loss: 562.5529 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8074 \tTime: 6.2081\n",
      "Epoch: 358 \tTrain_loss: 603.0701 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7980 \tTest_loss: 563.4468 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.8079 \tTime: 6.2072\n",
      "Epoch: 359 \tTrain_loss: 602.4466 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7969 \tTest_loss: 560.1006 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8062 \tTime: 5.9261\n",
      "Epoch: 360 \tTrain_loss: 605.2249 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7931 \tTest_loss: 548.0347 \tTest_accuracy: 0.8075 \tTest_accuracy_1: 0.8138 \tTime: 6.7399\n",
      "Epoch: 361 \tTrain_loss: 606.6305 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7928 \tTest_loss: 562.8614 \tTest_accuracy: 0.8033 \tTest_accuracy_1: 0.8152 \tTime: 6.8211\n",
      "Epoch: 362 \tTrain_loss: 604.3364 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7989 \tTest_loss: 556.5251 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8178 \tTime: 6.8198\n",
      "Epoch: 363 \tTrain_loss: 606.0293 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7967 \tTest_loss: 555.7258 \tTest_accuracy: 0.8045 \tTest_accuracy_1: 0.8162 \tTime: 7.3489\n",
      "Epoch: 364 \tTrain_loss: 606.0392 \tTrain_accuracy: 0.7938 \tTrain_accuracy_1: 0.7976 \tTest_loss: 557.2910 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8131 \tTime: 6.1661\n",
      "Epoch: 365 \tTrain_loss: 600.9991 \tTrain_accuracy: 0.7975 \tTrain_accuracy_1: 0.7974 \tTest_loss: 552.4637 \tTest_accuracy: 0.8062 \tTest_accuracy_1: 0.8151 \tTime: 6.4994\n",
      "Epoch: 366 \tTrain_loss: 602.0383 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7962 \tTest_loss: 551.1396 \tTest_accuracy: 0.8056 \tTest_accuracy_1: 0.8157 \tTime: 5.9238\n",
      "Epoch: 367 \tTrain_loss: 603.3054 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7955 \tTest_loss: 561.3603 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8128 \tTime: 5.8325\n",
      "Epoch: 368 \tTrain_loss: 604.3681 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7984 \tTest_loss: 562.5599 \tTest_accuracy: 0.8000 \tTest_accuracy_1: 0.8069 \tTime: 5.9473\n",
      "Epoch: 369 \tTrain_loss: 602.7212 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7969 \tTest_loss: 560.6163 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8072 \tTime: 6.2217\n",
      "Epoch: 370 \tTrain_loss: 606.4003 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7926 \tTest_loss: 556.1099 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8145 \tTime: 5.9780\n",
      "Epoch: 371 \tTrain_loss: 603.5327 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7986 \tTest_loss: 561.0239 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8101 \tTime: 5.9615\n",
      "Epoch: 372 \tTrain_loss: 605.4929 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7953 \tTest_loss: 558.8261 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8128 \tTime: 6.0001\n",
      "Epoch: 373 \tTrain_loss: 602.9575 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7962 \tTest_loss: 558.6308 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8122 \tTime: 6.0028\n",
      "Epoch: 374 \tTrain_loss: 605.0108 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7958 \tTest_loss: 560.1517 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8103 \tTime: 5.8071\n",
      "Epoch: 375 \tTrain_loss: 603.1529 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7970 \tTest_loss: 549.4433 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8200 \tTime: 5.7691\n",
      "Epoch: 376 \tTrain_loss: 601.2422 \tTrain_accuracy: 0.7965 \tTrain_accuracy_1: 0.7994 \tTest_loss: 552.6724 \tTest_accuracy: 0.8052 \tTest_accuracy_1: 0.8096 \tTime: 5.8042\n",
      "Epoch: 377 \tTrain_loss: 606.7615 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7930 \tTest_loss: 556.4840 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8085 \tTime: 5.7801\n",
      "Epoch: 378 \tTrain_loss: 606.1288 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7949 \tTest_loss: 557.1514 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8088 \tTime: 5.7979\n",
      "Epoch: 379 \tTrain_loss: 606.5138 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7914 \tTest_loss: 557.5336 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8151 \tTime: 5.8752\n",
      "Epoch: 380 \tTrain_loss: 604.5242 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7955 \tTest_loss: 555.6046 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8145 \tTime: 5.9077\n",
      "Epoch: 381 \tTrain_loss: 601.9511 \tTrain_accuracy: 0.7966 \tTrain_accuracy_1: 0.7985 \tTest_loss: 552.7432 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8163 \tTime: 5.8807\n",
      "Epoch: 382 \tTrain_loss: 602.3401 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.8006 \tTest_loss: 558.8480 \tTest_accuracy: 0.8011 \tTest_accuracy_1: 0.8130 \tTime: 5.8363\n",
      "Epoch: 383 \tTrain_loss: 606.2470 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7943 \tTest_loss: 561.4435 \tTest_accuracy: 0.8003 \tTest_accuracy_1: 0.8094 \tTime: 5.8295\n",
      "Epoch: 384 \tTrain_loss: 603.9393 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7946 \tTest_loss: 557.3226 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8156 \tTime: 5.8815\n",
      "Epoch: 385 \tTrain_loss: 603.6253 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7949 \tTest_loss: 561.2750 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8145 \tTime: 5.8149\n",
      "Epoch: 386 \tTrain_loss: 602.9661 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.8008 \tTest_loss: 559.1479 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8127 \tTime: 5.8428\n",
      "Epoch: 387 \tTrain_loss: 604.4686 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7988 \tTest_loss: 561.0780 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8156 \tTime: 5.9910\n",
      "Epoch: 388 \tTrain_loss: 603.1397 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7974 \tTest_loss: 557.4460 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8132 \tTime: 5.8575\n",
      "Epoch: 389 \tTrain_loss: 603.9951 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7975 \tTest_loss: 562.5281 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8112 \tTime: 5.8414\n",
      "Epoch: 390 \tTrain_loss: 605.2933 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7975 \tTest_loss: 570.6976 \tTest_accuracy: 0.7986 \tTest_accuracy_1: 0.8032 \tTime: 5.8679\n",
      "Epoch: 391 \tTrain_loss: 602.7514 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7969 \tTest_loss: 554.0732 \tTest_accuracy: 0.8056 \tTest_accuracy_1: 0.8124 \tTime: 6.5118\n",
      "Epoch: 392 \tTrain_loss: 602.9005 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7958 \tTest_loss: 555.9466 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8126 \tTime: 6.1240\n",
      "Epoch: 393 \tTrain_loss: 607.0577 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7927 \tTest_loss: 548.0624 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8202 \tTime: 6.8108\n",
      "Epoch: 394 \tTrain_loss: 603.7193 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7984 \tTest_loss: 555.6400 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8154 \tTime: 8.0397\n",
      "Epoch: 395 \tTrain_loss: 609.1046 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7932 \tTest_loss: 560.7308 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8090 \tTime: 6.7948\n",
      "Epoch: 396 \tTrain_loss: 601.2867 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7940 \tTest_loss: 561.1737 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8106 \tTime: 6.4133\n",
      "Epoch: 397 \tTrain_loss: 605.1489 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7952 \tTest_loss: 556.7817 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8138 \tTime: 6.3490\n",
      "Epoch: 398 \tTrain_loss: 604.9196 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.7999 \tTest_loss: 559.2211 \tTest_accuracy: 0.7994 \tTest_accuracy_1: 0.8087 \tTime: 6.7958\n",
      "Epoch: 399 \tTrain_loss: 603.5330 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.7957 \tTest_loss: 556.6943 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8091 \tTime: 6.9860\n",
      "Epoch: 400 \tTrain_loss: 603.4273 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7939 \tTest_loss: 557.7943 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8122 \tTime: 6.3244\n",
      "Epoch: 401 \tTrain_loss: 608.2275 \tTrain_accuracy: 0.7934 \tTrain_accuracy_1: 0.7929 \tTest_loss: 555.2554 \tTest_accuracy: 0.8043 \tTest_accuracy_1: 0.8153 \tTime: 5.9314\n",
      "Epoch: 402 \tTrain_loss: 605.2318 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7935 \tTest_loss: 558.0032 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8119 \tTime: 6.5962\n",
      "Epoch: 403 \tTrain_loss: 602.8236 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7977 \tTest_loss: 556.0168 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8167 \tTime: 6.7994\n",
      "Epoch: 404 \tTrain_loss: 604.4661 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.7992 \tTest_loss: 556.1785 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8149 \tTime: 7.3028\n",
      "Epoch: 405 \tTrain_loss: 603.7667 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7985 \tTest_loss: 558.2389 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8075 \tTime: 6.6328\n",
      "Epoch: 406 \tTrain_loss: 600.1273 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7976 \tTest_loss: 550.6818 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8136 \tTime: 6.6037\n",
      "Epoch: 407 \tTrain_loss: 603.8639 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7953 \tTest_loss: 553.2559 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8137 \tTime: 7.0724\n",
      "Epoch: 408 \tTrain_loss: 606.5353 \tTrain_accuracy: 0.7935 \tTrain_accuracy_1: 0.7924 \tTest_loss: 558.7111 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8179 \tTime: 6.2093\n",
      "Epoch: 409 \tTrain_loss: 604.8702 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7983 \tTest_loss: 560.3351 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8130 \tTime: 6.0419\n",
      "Epoch: 410 \tTrain_loss: 602.4869 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7988 \tTest_loss: 554.4966 \tTest_accuracy: 0.8011 \tTest_accuracy_1: 0.8113 \tTime: 5.7411\n",
      "Epoch: 411 \tTrain_loss: 604.3480 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7927 \tTest_loss: 558.0945 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8095 \tTime: 6.5313\n",
      "Epoch: 412 \tTrain_loss: 604.7081 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7943 \tTest_loss: 559.6743 \tTest_accuracy: 0.8033 \tTest_accuracy_1: 0.8129 \tTime: 6.2742\n",
      "Epoch: 413 \tTrain_loss: 605.5276 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7957 \tTest_loss: 560.1735 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.8152 \tTime: 6.0613\n",
      "Epoch: 414 \tTrain_loss: 605.6019 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7973 \tTest_loss: 553.1639 \tTest_accuracy: 0.8035 \tTest_accuracy_1: 0.8175 \tTime: 6.1098\n",
      "Epoch: 415 \tTrain_loss: 603.0006 \tTrain_accuracy: 0.7967 \tTrain_accuracy_1: 0.7974 \tTest_loss: 569.1788 \tTest_accuracy: 0.7960 \tTest_accuracy_1: 0.8040 \tTime: 6.1300\n",
      "Epoch: 416 \tTrain_loss: 604.7212 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7971 \tTest_loss: 555.9446 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8097 \tTime: 6.1574\n",
      "Epoch: 417 \tTrain_loss: 605.0202 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7953 \tTest_loss: 563.9904 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8098 \tTime: 5.9680\n",
      "Epoch: 418 \tTrain_loss: 606.9600 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7952 \tTest_loss: 550.4828 \tTest_accuracy: 0.8055 \tTest_accuracy_1: 0.8136 \tTime: 5.8228\n",
      "Epoch: 419 \tTrain_loss: 603.8890 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7955 \tTest_loss: 557.8927 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.8099 \tTime: 5.8427\n",
      "Epoch: 420 \tTrain_loss: 605.0034 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7945 \tTest_loss: 555.3535 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8104 \tTime: 5.7777\n",
      "Epoch: 421 \tTrain_loss: 602.8497 \tTrain_accuracy: 0.7968 \tTrain_accuracy_1: 0.7959 \tTest_loss: 557.8878 \tTest_accuracy: 0.8057 \tTest_accuracy_1: 0.8092 \tTime: 5.8713\n",
      "Epoch: 422 \tTrain_loss: 605.2721 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7939 \tTest_loss: 550.1298 \tTest_accuracy: 0.8053 \tTest_accuracy_1: 0.8159 \tTime: 6.2722\n",
      "Epoch: 423 \tTrain_loss: 607.3319 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7936 \tTest_loss: 561.5882 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.8055 \tTime: 6.5412\n",
      "Epoch: 424 \tTrain_loss: 605.1343 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7955 \tTest_loss: 563.4006 \tTest_accuracy: 0.8016 \tTest_accuracy_1: 0.8067 \tTime: 6.1606\n",
      "Epoch: 425 \tTrain_loss: 604.6413 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7973 \tTest_loss: 552.2339 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8208 \tTime: 6.2959\n",
      "Epoch: 426 \tTrain_loss: 603.9683 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7996 \tTest_loss: 553.4372 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8111 \tTime: 6.3163\n",
      "Epoch: 427 \tTrain_loss: 605.4828 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7937 \tTest_loss: 551.4108 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8137 \tTime: 6.1816\n",
      "Epoch: 428 \tTrain_loss: 602.8028 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7970 \tTest_loss: 549.9061 \tTest_accuracy: 0.8063 \tTest_accuracy_1: 0.8118 \tTime: 6.1480\n",
      "Epoch: 429 \tTrain_loss: 605.6066 \tTrain_accuracy: 0.7938 \tTrain_accuracy_1: 0.7962 \tTest_loss: 551.4224 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8119 \tTime: 6.2056\n",
      "Epoch: 430 \tTrain_loss: 601.0708 \tTrain_accuracy: 0.7967 \tTrain_accuracy_1: 0.7986 \tTest_loss: 551.1149 \tTest_accuracy: 0.8081 \tTest_accuracy_1: 0.8166 \tTime: 6.2231\n",
      "Epoch: 431 \tTrain_loss: 607.1034 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7947 \tTest_loss: 558.3772 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8137 \tTime: 6.0563\n",
      "Epoch: 432 \tTrain_loss: 605.5351 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7955 \tTest_loss: 560.2181 \tTest_accuracy: 0.8004 \tTest_accuracy_1: 0.8132 \tTime: 6.1969\n",
      "Epoch: 433 \tTrain_loss: 606.3263 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7961 \tTest_loss: 552.6392 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8139 \tTime: 6.1855\n",
      "Epoch: 434 \tTrain_loss: 606.0721 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7927 \tTest_loss: 562.5787 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8063 \tTime: 6.2790\n",
      "Epoch: 435 \tTrain_loss: 599.8201 \tTrain_accuracy: 0.7975 \tTrain_accuracy_1: 0.7954 \tTest_loss: 563.0579 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8116 \tTime: 6.2399\n",
      "Epoch: 436 \tTrain_loss: 606.3441 \tTrain_accuracy: 0.7966 \tTrain_accuracy_1: 0.7984 \tTest_loss: 562.5001 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8113 \tTime: 6.1587\n",
      "Epoch: 437 \tTrain_loss: 603.3729 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7987 \tTest_loss: 557.6265 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8176 \tTime: 6.0806\n",
      "Epoch: 438 \tTrain_loss: 601.0456 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7981 \tTest_loss: 556.4262 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8150 \tTime: 6.0782\n",
      "Epoch: 439 \tTrain_loss: 604.2365 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7943 \tTest_loss: 559.0882 \tTest_accuracy: 0.8023 \tTest_accuracy_1: 0.8090 \tTime: 6.0705\n",
      "Epoch: 440 \tTrain_loss: 602.0890 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7972 \tTest_loss: 552.0690 \tTest_accuracy: 0.8035 \tTest_accuracy_1: 0.8148 \tTime: 5.9926\n",
      "Epoch: 441 \tTrain_loss: 603.1747 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7979 \tTest_loss: 556.1478 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8109 \tTime: 5.9197\n",
      "Epoch: 442 \tTrain_loss: 607.7616 \tTrain_accuracy: 0.7933 \tTrain_accuracy_1: 0.7905 \tTest_loss: 553.8206 \tTest_accuracy: 0.8078 \tTest_accuracy_1: 0.8158 \tTime: 5.9735\n",
      "Epoch: 443 \tTrain_loss: 605.4237 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7955 \tTest_loss: 558.9789 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8178 \tTime: 5.7482\n",
      "Epoch: 444 \tTrain_loss: 606.3479 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7974 \tTest_loss: 556.9106 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8158 \tTime: 6.1331\n",
      "Epoch: 445 \tTrain_loss: 602.2359 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7970 \tTest_loss: 553.6443 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8128 \tTime: 5.8994\n",
      "Epoch: 446 \tTrain_loss: 609.5671 \tTrain_accuracy: 0.7929 \tTrain_accuracy_1: 0.7894 \tTest_loss: 549.0526 \tTest_accuracy: 0.8047 \tTest_accuracy_1: 0.8162 \tTime: 5.8375\n",
      "Epoch: 447 \tTrain_loss: 605.8795 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7924 \tTest_loss: 556.5273 \tTest_accuracy: 0.8009 \tTest_accuracy_1: 0.8080 \tTime: 5.8991\n",
      "Epoch: 448 \tTrain_loss: 604.1827 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7981 \tTest_loss: 556.3024 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8121 \tTime: 6.0570\n",
      "Epoch: 449 \tTrain_loss: 605.3765 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7955 \tTest_loss: 556.4819 \tTest_accuracy: 0.8041 \tTest_accuracy_1: 0.8151 \tTime: 6.0960\n",
      "Epoch: 450 \tTrain_loss: 602.3133 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7955 \tTest_loss: 563.3793 \tTest_accuracy: 0.8014 \tTest_accuracy_1: 0.8073 \tTime: 6.0269\n",
      "Epoch: 451 \tTrain_loss: 602.0830 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7965 \tTest_loss: 565.7596 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.8100 \tTime: 6.0341\n",
      "Epoch: 452 \tTrain_loss: 604.2076 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7969 \tTest_loss: 553.2920 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8162 \tTime: 5.9783\n",
      "Epoch: 453 \tTrain_loss: 601.0066 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7957 \tTest_loss: 553.2020 \tTest_accuracy: 0.8050 \tTest_accuracy_1: 0.8181 \tTime: 6.0566\n",
      "Epoch: 454 \tTrain_loss: 604.8013 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7957 \tTest_loss: 558.4415 \tTest_accuracy: 0.8011 \tTest_accuracy_1: 0.8124 \tTime: 6.0561\n",
      "Epoch: 455 \tTrain_loss: 603.8553 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7951 \tTest_loss: 556.3159 \tTest_accuracy: 0.7999 \tTest_accuracy_1: 0.8128 \tTime: 5.8986\n",
      "Epoch: 456 \tTrain_loss: 608.3353 \tTrain_accuracy: 0.7938 \tTrain_accuracy_1: 0.7923 \tTest_loss: 567.1416 \tTest_accuracy: 0.7991 \tTest_accuracy_1: 0.8052 \tTime: 5.7570\n",
      "Epoch: 457 \tTrain_loss: 602.3917 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7957 \tTest_loss: 557.1331 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8170 \tTime: 5.7837\n",
      "Epoch: 458 \tTrain_loss: 603.8242 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7975 \tTest_loss: 554.2646 \tTest_accuracy: 0.8014 \tTest_accuracy_1: 0.8166 \tTime: 5.6729\n",
      "Epoch: 459 \tTrain_loss: 604.9395 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7950 \tTest_loss: 552.4347 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8096 \tTime: 5.6789\n",
      "Epoch: 460 \tTrain_loss: 606.1245 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7926 \tTest_loss: 563.5789 \tTest_accuracy: 0.8014 \tTest_accuracy_1: 0.8069 \tTime: 5.6850\n",
      "Epoch: 461 \tTrain_loss: 603.7318 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7976 \tTest_loss: 556.2712 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8153 \tTime: 5.7400\n",
      "Epoch: 462 \tTrain_loss: 603.5018 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7989 \tTest_loss: 558.9342 \tTest_accuracy: 0.8000 \tTest_accuracy_1: 0.8156 \tTime: 5.7179\n",
      "Epoch: 463 \tTrain_loss: 602.6356 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7996 \tTest_loss: 554.1008 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8187 \tTime: 5.7046\n",
      "Epoch: 464 \tTrain_loss: 605.5236 \tTrain_accuracy: 0.7936 \tTrain_accuracy_1: 0.7930 \tTest_loss: 563.4855 \tTest_accuracy: 0.8006 \tTest_accuracy_1: 0.8068 \tTime: 5.6742\n",
      "Epoch: 465 \tTrain_loss: 607.7577 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7942 \tTest_loss: 559.6787 \tTest_accuracy: 0.8009 \tTest_accuracy_1: 0.8111 \tTime: 5.7359\n",
      "Epoch: 466 \tTrain_loss: 605.8196 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7956 \tTest_loss: 553.5910 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8093 \tTime: 5.7559\n",
      "Epoch: 467 \tTrain_loss: 604.7861 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7945 \tTest_loss: 556.0154 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8126 \tTime: 5.7065\n",
      "Epoch: 468 \tTrain_loss: 601.1422 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.7988 \tTest_loss: 556.3514 \tTest_accuracy: 0.8021 \tTest_accuracy_1: 0.8149 \tTime: 5.7235\n",
      "Epoch: 469 \tTrain_loss: 607.2045 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7944 \tTest_loss: 556.5078 \tTest_accuracy: 0.8038 \tTest_accuracy_1: 0.8151 \tTime: 5.7652\n",
      "Epoch: 470 \tTrain_loss: 608.6781 \tTrain_accuracy: 0.7937 \tTrain_accuracy_1: 0.7928 \tTest_loss: 553.3392 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8117 \tTime: 5.7425\n",
      "Epoch: 471 \tTrain_loss: 600.2956 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7980 \tTest_loss: 554.3407 \tTest_accuracy: 0.8035 \tTest_accuracy_1: 0.8109 \tTime: 5.7146\n",
      "Epoch: 472 \tTrain_loss: 606.8381 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7929 \tTest_loss: 560.5792 \tTest_accuracy: 0.8037 \tTest_accuracy_1: 0.8113 \tTime: 6.0381\n",
      "Epoch: 473 \tTrain_loss: 603.5682 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7967 \tTest_loss: 553.3597 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8147 \tTime: 6.2713\n",
      "Epoch: 474 \tTrain_loss: 604.3199 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7964 \tTest_loss: 554.1671 \tTest_accuracy: 0.8010 \tTest_accuracy_1: 0.8172 \tTime: 6.1412\n",
      "Epoch: 475 \tTrain_loss: 600.6317 \tTrain_accuracy: 0.7961 \tTrain_accuracy_1: 0.8000 \tTest_loss: 559.2710 \tTest_accuracy: 0.8021 \tTest_accuracy_1: 0.8127 \tTime: 6.5994\n",
      "Epoch: 476 \tTrain_loss: 605.4045 \tTrain_accuracy: 0.7965 \tTrain_accuracy_1: 0.7956 \tTest_loss: 554.5610 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8128 \tTime: 5.8005\n",
      "Epoch: 477 \tTrain_loss: 606.0316 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7946 \tTest_loss: 547.4832 \tTest_accuracy: 0.8062 \tTest_accuracy_1: 0.8137 \tTime: 5.9831\n",
      "Epoch: 478 \tTrain_loss: 604.6489 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7945 \tTest_loss: 554.4371 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8181 \tTime: 6.3825\n",
      "Epoch: 479 \tTrain_loss: 600.8702 \tTrain_accuracy: 0.7965 \tTrain_accuracy_1: 0.7989 \tTest_loss: 555.2856 \tTest_accuracy: 0.8057 \tTest_accuracy_1: 0.8128 \tTime: 6.9492\n",
      "Epoch: 480 \tTrain_loss: 601.8712 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.8001 \tTest_loss: 562.9534 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8126 \tTime: 6.4908\n",
      "Epoch: 481 \tTrain_loss: 603.5869 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7932 \tTest_loss: 567.1780 \tTest_accuracy: 0.8002 \tTest_accuracy_1: 0.8053 \tTime: 5.9420\n",
      "Epoch: 482 \tTrain_loss: 602.4233 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7961 \tTest_loss: 555.5272 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8154 \tTime: 6.0965\n",
      "Epoch: 483 \tTrain_loss: 604.3742 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7969 \tTest_loss: 561.5114 \tTest_accuracy: 0.7980 \tTest_accuracy_1: 0.8070 \tTime: 6.1712\n",
      "Epoch: 484 \tTrain_loss: 603.4107 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7953 \tTest_loss: 551.1869 \tTest_accuracy: 0.8055 \tTest_accuracy_1: 0.8126 \tTime: 6.9749\n",
      "Epoch: 485 \tTrain_loss: 604.4409 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7964 \tTest_loss: 557.3181 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8125 \tTime: 6.9734\n",
      "Epoch: 486 \tTrain_loss: 605.0063 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7986 \tTest_loss: 557.7996 \tTest_accuracy: 0.8066 \tTest_accuracy_1: 0.8143 \tTime: 6.7380\n",
      "Epoch: 487 \tTrain_loss: 602.9942 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7957 \tTest_loss: 556.4243 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8126 \tTime: 6.9382\n",
      "Epoch: 488 \tTrain_loss: 605.1687 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7926 \tTest_loss: 555.8000 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8173 \tTime: 6.8581\n",
      "Epoch: 489 \tTrain_loss: 601.8712 \tTrain_accuracy: 0.7968 \tTrain_accuracy_1: 0.7979 \tTest_loss: 559.2917 \tTest_accuracy: 0.8065 \tTest_accuracy_1: 0.8107 \tTime: 6.7561\n",
      "Epoch: 490 \tTrain_loss: 609.5451 \tTrain_accuracy: 0.7937 \tTrain_accuracy_1: 0.7932 \tTest_loss: 559.8256 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8110 \tTime: 6.6596\n",
      "Epoch: 491 \tTrain_loss: 602.0697 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7983 \tTest_loss: 553.3751 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8182 \tTime: 6.0366\n",
      "Epoch: 492 \tTrain_loss: 605.8088 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7915 \tTest_loss: 555.9274 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8101 \tTime: 6.4295\n",
      "Epoch: 493 \tTrain_loss: 607.8896 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7950 \tTest_loss: 558.2316 \tTest_accuracy: 0.8062 \tTest_accuracy_1: 0.8130 \tTime: 6.1794\n",
      "Epoch: 494 \tTrain_loss: 606.1142 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7956 \tTest_loss: 562.3210 \tTest_accuracy: 0.8003 \tTest_accuracy_1: 0.8078 \tTime: 5.9274\n",
      "Epoch: 495 \tTrain_loss: 604.6339 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7957 \tTest_loss: 555.9575 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8156 \tTime: 5.8892\n",
      "Epoch: 496 \tTrain_loss: 607.1650 \tTrain_accuracy: 0.7943 \tTrain_accuracy_1: 0.7947 \tTest_loss: 563.2803 \tTest_accuracy: 0.8001 \tTest_accuracy_1: 0.8107 \tTime: 5.8520\n",
      "Epoch: 497 \tTrain_loss: 603.5479 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7979 \tTest_loss: 557.4803 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8110 \tTime: 5.7233\n",
      "Epoch: 498 \tTrain_loss: 601.2332 \tTrain_accuracy: 0.7971 \tTrain_accuracy_1: 0.7987 \tTest_loss: 559.7515 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8062 \tTime: 6.4737\n",
      "Epoch: 499 \tTrain_loss: 607.8376 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7947 \tTest_loss: 555.9333 \tTest_accuracy: 0.8055 \tTest_accuracy_1: 0.8127 \tTime: 6.5863\n",
      "Epoch: 500 \tTrain_loss: 604.5158 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7939 \tTest_loss: 557.5903 \tTest_accuracy: 0.8026 \tTest_accuracy_1: 0.8142 \tTime: 5.9882\n",
      "Epoch: 501 \tTrain_loss: 603.3021 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7961 \tTest_loss: 556.2277 \tTest_accuracy: 0.8043 \tTest_accuracy_1: 0.8112 \tTime: 6.1186\n",
      "Epoch: 502 \tTrain_loss: 602.2571 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7979 \tTest_loss: 558.8238 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8135 \tTime: 6.2124\n",
      "Epoch: 503 \tTrain_loss: 604.8575 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7969 \tTest_loss: 562.4703 \tTest_accuracy: 0.8013 \tTest_accuracy_1: 0.8097 \tTime: 6.0152\n",
      "Epoch: 504 \tTrain_loss: 603.3978 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7969 \tTest_loss: 561.2029 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8088 \tTime: 6.5962\n",
      "Epoch: 505 \tTrain_loss: 604.4519 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7962 \tTest_loss: 560.3436 \tTest_accuracy: 0.8021 \tTest_accuracy_1: 0.8114 \tTime: 5.8233\n",
      "Epoch: 506 \tTrain_loss: 603.1245 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7979 \tTest_loss: 554.6779 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8167 \tTime: 5.7510\n",
      "Epoch: 507 \tTrain_loss: 604.6136 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7974 \tTest_loss: 556.0568 \tTest_accuracy: 0.8064 \tTest_accuracy_1: 0.8150 \tTime: 5.7798\n",
      "Epoch: 508 \tTrain_loss: 604.5474 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7971 \tTest_loss: 557.4418 \tTest_accuracy: 0.8018 \tTest_accuracy_1: 0.8128 \tTime: 6.4396\n",
      "Epoch: 509 \tTrain_loss: 603.6186 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7941 \tTest_loss: 555.8079 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8180 \tTime: 6.4746\n",
      "Epoch: 510 \tTrain_loss: 601.1736 \tTrain_accuracy: 0.7978 \tTrain_accuracy_1: 0.7994 \tTest_loss: 552.2672 \tTest_accuracy: 0.8057 \tTest_accuracy_1: 0.8234 \tTime: 6.4137\n",
      "Epoch: 511 \tTrain_loss: 605.7106 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7985 \tTest_loss: 555.4227 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8110 \tTime: 6.3819\n",
      "Epoch: 512 \tTrain_loss: 605.4978 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7916 \tTest_loss: 554.1929 \tTest_accuracy: 0.8021 \tTest_accuracy_1: 0.8124 \tTime: 6.4805\n",
      "Epoch: 513 \tTrain_loss: 602.9591 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7927 \tTest_loss: 564.4501 \tTest_accuracy: 0.8013 \tTest_accuracy_1: 0.8077 \tTime: 6.1989\n",
      "Epoch: 514 \tTrain_loss: 601.8423 \tTrain_accuracy: 0.7975 \tTrain_accuracy_1: 0.7980 \tTest_loss: 556.3965 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8181 \tTime: 6.8779\n",
      "Epoch: 515 \tTrain_loss: 604.6464 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7970 \tTest_loss: 552.4058 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8181 \tTime: 6.2900\n",
      "Epoch: 516 \tTrain_loss: 605.8334 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7952 \tTest_loss: 562.4735 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8100 \tTime: 6.3736\n",
      "Epoch: 517 \tTrain_loss: 604.0139 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7958 \tTest_loss: 550.8984 \tTest_accuracy: 0.8059 \tTest_accuracy_1: 0.8159 \tTime: 6.8278\n",
      "Epoch: 518 \tTrain_loss: 604.7529 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7979 \tTest_loss: 556.8530 \tTest_accuracy: 0.7999 \tTest_accuracy_1: 0.8128 \tTime: 6.5962\n",
      "Epoch: 519 \tTrain_loss: 606.4317 \tTrain_accuracy: 0.7939 \tTrain_accuracy_1: 0.7957 \tTest_loss: 556.2896 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8117 \tTime: 6.2833\n",
      "Epoch: 520 \tTrain_loss: 604.1813 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7954 \tTest_loss: 554.0026 \tTest_accuracy: 0.8057 \tTest_accuracy_1: 0.8164 \tTime: 6.7877\n",
      "Epoch: 521 \tTrain_loss: 607.2908 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7928 \tTest_loss: 554.7724 \tTest_accuracy: 0.8029 \tTest_accuracy_1: 0.8131 \tTime: 6.5511\n",
      "Epoch: 522 \tTrain_loss: 601.8773 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7982 \tTest_loss: 554.3231 \tTest_accuracy: 0.8057 \tTest_accuracy_1: 0.8141 \tTime: 6.0454\n",
      "Epoch: 523 \tTrain_loss: 598.7381 \tTrain_accuracy: 0.7985 \tTrain_accuracy_1: 0.8021 \tTest_loss: 555.1431 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8118 \tTime: 6.0573\n",
      "Epoch: 524 \tTrain_loss: 603.6375 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7959 \tTest_loss: 551.4670 \tTest_accuracy: 0.8057 \tTest_accuracy_1: 0.8145 \tTime: 7.1088\n",
      "Epoch: 525 \tTrain_loss: 605.3486 \tTrain_accuracy: 0.7940 \tTrain_accuracy_1: 0.7944 \tTest_loss: 556.8075 \tTest_accuracy: 0.8051 \tTest_accuracy_1: 0.8167 \tTime: 6.6799\n",
      "Epoch: 526 \tTrain_loss: 603.4788 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7961 \tTest_loss: 560.0464 \tTest_accuracy: 0.8040 \tTest_accuracy_1: 0.8133 \tTime: 6.7461\n",
      "Epoch: 527 \tTrain_loss: 605.4142 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7971 \tTest_loss: 556.1148 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.8197 \tTime: 6.4569\n",
      "Epoch: 528 \tTrain_loss: 603.1721 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7970 \tTest_loss: 552.8619 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8147 \tTime: 6.0556\n",
      "Epoch: 529 \tTrain_loss: 606.6067 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7981 \tTest_loss: 552.3062 \tTest_accuracy: 0.8066 \tTest_accuracy_1: 0.8150 \tTime: 6.3879\n",
      "Epoch: 530 \tTrain_loss: 603.9355 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7938 \tTest_loss: 559.2565 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8098 \tTime: 6.9433\n",
      "Epoch: 531 \tTrain_loss: 605.0307 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7977 \tTest_loss: 556.7183 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8115 \tTime: 6.2005\n",
      "Epoch: 532 \tTrain_loss: 603.0972 \tTrain_accuracy: 0.7966 \tTrain_accuracy_1: 0.7978 \tTest_loss: 552.7280 \tTest_accuracy: 0.8060 \tTest_accuracy_1: 0.8125 \tTime: 6.2356\n",
      "Epoch: 533 \tTrain_loss: 603.6954 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7969 \tTest_loss: 553.8450 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8126 \tTime: 6.4177\n",
      "Epoch: 534 \tTrain_loss: 603.3563 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7982 \tTest_loss: 559.1948 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8118 \tTime: 6.1203\n",
      "Epoch: 535 \tTrain_loss: 602.9688 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7957 \tTest_loss: 560.8589 \tTest_accuracy: 0.8017 \tTest_accuracy_1: 0.8104 \tTime: 6.0083\n",
      "Epoch: 536 \tTrain_loss: 604.8193 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7930 \tTest_loss: 553.2811 \tTest_accuracy: 0.8055 \tTest_accuracy_1: 0.8143 \tTime: 6.2065\n",
      "Epoch: 537 \tTrain_loss: 606.0420 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7964 \tTest_loss: 557.7009 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8161 \tTime: 5.8786\n",
      "Epoch: 538 \tTrain_loss: 601.3647 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7979 \tTest_loss: 562.7676 \tTest_accuracy: 0.7992 \tTest_accuracy_1: 0.8072 \tTime: 6.3889\n",
      "Epoch: 539 \tTrain_loss: 601.9592 \tTrain_accuracy: 0.7970 \tTrain_accuracy_1: 0.8000 \tTest_loss: 548.9417 \tTest_accuracy: 0.8067 \tTest_accuracy_1: 0.8150 \tTime: 6.3136\n",
      "Epoch: 540 \tTrain_loss: 602.3666 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7953 \tTest_loss: 550.2123 \tTest_accuracy: 0.8061 \tTest_accuracy_1: 0.8127 \tTime: 6.3174\n",
      "Epoch: 541 \tTrain_loss: 602.1577 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7971 \tTest_loss: 565.6168 \tTest_accuracy: 0.7994 \tTest_accuracy_1: 0.8096 \tTime: 6.3073\n",
      "Epoch: 542 \tTrain_loss: 601.9394 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7973 \tTest_loss: 554.0002 \tTest_accuracy: 0.8022 \tTest_accuracy_1: 0.8148 \tTime: 6.0850\n",
      "Epoch: 543 \tTrain_loss: 598.1798 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.8011 \tTest_loss: 553.8707 \tTest_accuracy: 0.8013 \tTest_accuracy_1: 0.8177 \tTime: 5.9706\n",
      "Epoch: 544 \tTrain_loss: 601.0160 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7999 \tTest_loss: 557.3882 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8100 \tTime: 5.8909\n",
      "Epoch: 545 \tTrain_loss: 605.3292 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7954 \tTest_loss: 554.7194 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8139 \tTime: 5.9895\n",
      "Epoch: 546 \tTrain_loss: 602.9916 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7979 \tTest_loss: 561.5081 \tTest_accuracy: 0.8034 \tTest_accuracy_1: 0.8150 \tTime: 5.7989\n",
      "Epoch: 547 \tTrain_loss: 605.4642 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7960 \tTest_loss: 558.8979 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8100 \tTime: 5.8695\n",
      "Epoch: 548 \tTrain_loss: 602.9278 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7983 \tTest_loss: 550.7374 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8135 \tTime: 5.8765\n",
      "Epoch: 549 \tTrain_loss: 603.2878 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7947 \tTest_loss: 546.2744 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8134 \tTime: 5.7901\n",
      "Epoch: 550 \tTrain_loss: 603.2337 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7948 \tTest_loss: 560.1327 \tTest_accuracy: 0.8025 \tTest_accuracy_1: 0.8130 \tTime: 6.0070\n",
      "Epoch: 551 \tTrain_loss: 607.0556 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7959 \tTest_loss: 556.5747 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8173 \tTime: 5.9921\n",
      "Epoch: 552 \tTrain_loss: 604.0939 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7961 \tTest_loss: 566.9137 \tTest_accuracy: 0.8009 \tTest_accuracy_1: 0.8037 \tTime: 5.9522\n",
      "Epoch: 553 \tTrain_loss: 604.0046 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7963 \tTest_loss: 564.1702 \tTest_accuracy: 0.8017 \tTest_accuracy_1: 0.8110 \tTime: 5.9936\n",
      "Epoch: 554 \tTrain_loss: 604.6390 \tTrain_accuracy: 0.7950 \tTrain_accuracy_1: 0.7976 \tTest_loss: 564.4041 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8103 \tTime: 6.6051\n",
      "Epoch: 555 \tTrain_loss: 606.3600 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7930 \tTest_loss: 562.2612 \tTest_accuracy: 0.8004 \tTest_accuracy_1: 0.8082 \tTime: 6.1641\n",
      "Epoch: 556 \tTrain_loss: 604.1352 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7979 \tTest_loss: 557.9062 \tTest_accuracy: 0.8013 \tTest_accuracy_1: 0.8130 \tTime: 6.2828\n",
      "Epoch: 557 \tTrain_loss: 606.6306 \tTrain_accuracy: 0.7942 \tTrain_accuracy_1: 0.7942 \tTest_loss: 562.5957 \tTest_accuracy: 0.8032 \tTest_accuracy_1: 0.8083 \tTime: 6.7866\n",
      "Epoch: 558 \tTrain_loss: 602.6251 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7963 \tTest_loss: 551.3806 \tTest_accuracy: 0.8060 \tTest_accuracy_1: 0.8110 \tTime: 6.8947\n",
      "Epoch: 559 \tTrain_loss: 606.3680 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7909 \tTest_loss: 549.0870 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8115 \tTime: 6.3821\n",
      "Epoch: 560 \tTrain_loss: 605.9846 \tTrain_accuracy: 0.7948 \tTrain_accuracy_1: 0.7918 \tTest_loss: 558.0522 \tTest_accuracy: 0.8024 \tTest_accuracy_1: 0.8134 \tTime: 6.0513\n",
      "Epoch: 561 \tTrain_loss: 608.1961 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7985 \tTest_loss: 563.1149 \tTest_accuracy: 0.8020 \tTest_accuracy_1: 0.8129 \tTime: 5.9626\n",
      "Epoch: 562 \tTrain_loss: 603.3525 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.8009 \tTest_loss: 549.5900 \tTest_accuracy: 0.8075 \tTest_accuracy_1: 0.8173 \tTime: 6.0038\n",
      "Epoch: 563 \tTrain_loss: 603.2308 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7972 \tTest_loss: 557.4930 \tTest_accuracy: 0.8051 \tTest_accuracy_1: 0.8063 \tTime: 5.7801\n",
      "Epoch: 564 \tTrain_loss: 606.6943 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7916 \tTest_loss: 554.5780 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8134 \tTime: 5.9346\n",
      "Epoch: 565 \tTrain_loss: 604.2531 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7960 \tTest_loss: 559.2076 \tTest_accuracy: 0.8055 \tTest_accuracy_1: 0.8154 \tTime: 6.1563\n",
      "Epoch: 566 \tTrain_loss: 604.5411 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7986 \tTest_loss: 559.0922 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8145 \tTime: 6.2751\n",
      "Epoch: 567 \tTrain_loss: 606.2563 \tTrain_accuracy: 0.7938 \tTrain_accuracy_1: 0.7969 \tTest_loss: 563.4162 \tTest_accuracy: 0.7997 \tTest_accuracy_1: 0.8032 \tTime: 5.8678\n",
      "Epoch: 568 \tTrain_loss: 603.9842 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7917 \tTest_loss: 554.6865 \tTest_accuracy: 0.8028 \tTest_accuracy_1: 0.8117 \tTime: 6.0616\n",
      "Epoch: 569 \tTrain_loss: 604.1314 \tTrain_accuracy: 0.7952 \tTrain_accuracy_1: 0.7949 \tTest_loss: 555.3035 \tTest_accuracy: 0.7999 \tTest_accuracy_1: 0.8127 \tTime: 5.8424\n",
      "Epoch: 570 \tTrain_loss: 609.0745 \tTrain_accuracy: 0.7931 \tTrain_accuracy_1: 0.7931 \tTest_loss: 571.2817 \tTest_accuracy: 0.7972 \tTest_accuracy_1: 0.8066 \tTime: 5.8206\n",
      "Epoch: 571 \tTrain_loss: 606.9209 \tTrain_accuracy: 0.7937 \tTrain_accuracy_1: 0.7977 \tTest_loss: 559.4817 \tTest_accuracy: 0.8019 \tTest_accuracy_1: 0.8148 \tTime: 5.8829\n",
      "Epoch: 572 \tTrain_loss: 605.5766 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7947 \tTest_loss: 553.6002 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8113 \tTime: 5.9548\n",
      "Epoch: 573 \tTrain_loss: 604.7770 \tTrain_accuracy: 0.7953 \tTrain_accuracy_1: 0.7974 \tTest_loss: 555.3436 \tTest_accuracy: 0.8046 \tTest_accuracy_1: 0.8145 \tTime: 5.8948\n",
      "Epoch: 574 \tTrain_loss: 602.7582 \tTrain_accuracy: 0.7964 \tTrain_accuracy_1: 0.7985 \tTest_loss: 559.9202 \tTest_accuracy: 0.8012 \tTest_accuracy_1: 0.8106 \tTime: 5.9069\n",
      "Epoch: 575 \tTrain_loss: 603.4397 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.7973 \tTest_loss: 564.4311 \tTest_accuracy: 0.7992 \tTest_accuracy_1: 0.8098 \tTime: 5.9527\n",
      "Epoch: 576 \tTrain_loss: 604.3691 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7978 \tTest_loss: 557.8303 \tTest_accuracy: 0.8009 \tTest_accuracy_1: 0.8105 \tTime: 5.8628\n",
      "Epoch: 577 \tTrain_loss: 605.5741 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7954 \tTest_loss: 556.1631 \tTest_accuracy: 0.8050 \tTest_accuracy_1: 0.8139 \tTime: 5.8056\n",
      "Epoch: 578 \tTrain_loss: 604.9848 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7958 \tTest_loss: 556.9193 \tTest_accuracy: 0.8031 \tTest_accuracy_1: 0.8091 \tTime: 5.9722\n",
      "Epoch: 579 \tTrain_loss: 602.7381 \tTrain_accuracy: 0.7969 \tTrain_accuracy_1: 0.7970 \tTest_loss: 548.7482 \tTest_accuracy: 0.8080 \tTest_accuracy_1: 0.8160 \tTime: 6.0382\n",
      "Epoch: 580 \tTrain_loss: 605.7278 \tTrain_accuracy: 0.7947 \tTrain_accuracy_1: 0.7930 \tTest_loss: 553.7257 \tTest_accuracy: 0.8055 \tTest_accuracy_1: 0.8127 \tTime: 5.8924\n",
      "Epoch: 581 \tTrain_loss: 602.3055 \tTrain_accuracy: 0.7951 \tTrain_accuracy_1: 0.7969 \tTest_loss: 555.0784 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8149 \tTime: 5.7924\n",
      "Epoch: 582 \tTrain_loss: 602.1048 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7997 \tTest_loss: 555.5211 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8121 \tTime: 6.0213\n",
      "Epoch: 583 \tTrain_loss: 605.3220 \tTrain_accuracy: 0.7955 \tTrain_accuracy_1: 0.7959 \tTest_loss: 560.5659 \tTest_accuracy: 0.8054 \tTest_accuracy_1: 0.8116 \tTime: 5.7953\n",
      "Epoch: 584 \tTrain_loss: 600.8528 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7978 \tTest_loss: 556.2438 \tTest_accuracy: 0.8027 \tTest_accuracy_1: 0.8093 \tTime: 5.8371\n",
      "Epoch: 585 \tTrain_loss: 604.3841 \tTrain_accuracy: 0.7959 \tTrain_accuracy_1: 0.7978 \tTest_loss: 554.2748 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8125 \tTime: 5.7524\n",
      "Epoch: 586 \tTrain_loss: 607.1596 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7928 \tTest_loss: 553.5172 \tTest_accuracy: 0.8061 \tTest_accuracy_1: 0.8128 \tTime: 5.8274\n",
      "Epoch: 587 \tTrain_loss: 604.5094 \tTrain_accuracy: 0.7945 \tTrain_accuracy_1: 0.7953 \tTest_loss: 557.1755 \tTest_accuracy: 0.8044 \tTest_accuracy_1: 0.8165 \tTime: 5.8155\n",
      "Epoch: 588 \tTrain_loss: 604.4189 \tTrain_accuracy: 0.7954 \tTrain_accuracy_1: 0.7979 \tTest_loss: 557.6304 \tTest_accuracy: 0.8039 \tTest_accuracy_1: 0.8124 \tTime: 6.3084\n",
      "Epoch: 589 \tTrain_loss: 604.3879 \tTrain_accuracy: 0.7956 \tTrain_accuracy_1: 0.7937 \tTest_loss: 551.7816 \tTest_accuracy: 0.8042 \tTest_accuracy_1: 0.8141 \tTime: 6.6611\n",
      "Epoch: 590 \tTrain_loss: 603.2925 \tTrain_accuracy: 0.7962 \tTrain_accuracy_1: 0.7955 \tTest_loss: 558.3429 \tTest_accuracy: 0.8014 \tTest_accuracy_1: 0.8154 \tTime: 6.7041\n",
      "Epoch: 591 \tTrain_loss: 607.7540 \tTrain_accuracy: 0.7957 \tTrain_accuracy_1: 0.7978 \tTest_loss: 563.5360 \tTest_accuracy: 0.8030 \tTest_accuracy_1: 0.8105 \tTime: 6.6451\n",
      "Epoch: 592 \tTrain_loss: 606.0860 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7985 \tTest_loss: 553.2628 \tTest_accuracy: 0.8052 \tTest_accuracy_1: 0.8093 \tTime: 6.4394\n",
      "Epoch: 593 \tTrain_loss: 607.9610 \tTrain_accuracy: 0.7941 \tTrain_accuracy_1: 0.7912 \tTest_loss: 556.3313 \tTest_accuracy: 0.7994 \tTest_accuracy_1: 0.8083 \tTime: 6.5824\n",
      "Epoch: 594 \tTrain_loss: 603.8467 \tTrain_accuracy: 0.7963 \tTrain_accuracy_1: 0.7957 \tTest_loss: 566.0248 \tTest_accuracy: 0.8015 \tTest_accuracy_1: 0.8054 \tTime: 6.0993\n",
      "Epoch: 595 \tTrain_loss: 605.5504 \tTrain_accuracy: 0.7949 \tTrain_accuracy_1: 0.7984 \tTest_loss: 564.4489 \tTest_accuracy: 0.8008 \tTest_accuracy_1: 0.8105 \tTime: 6.0906\n",
      "Epoch: 596 \tTrain_loss: 606.0119 \tTrain_accuracy: 0.7946 \tTrain_accuracy_1: 0.7966 \tTest_loss: 563.1497 \tTest_accuracy: 0.8036 \tTest_accuracy_1: 0.8155 \tTime: 6.1978\n",
      "Epoch: 597 \tTrain_loss: 600.4755 \tTrain_accuracy: 0.7960 \tTrain_accuracy_1: 0.7971 \tTest_loss: 557.3777 \tTest_accuracy: 0.8048 \tTest_accuracy_1: 0.8063 \tTime: 6.5082\n",
      "Epoch: 598 \tTrain_loss: 602.3031 \tTrain_accuracy: 0.7958 \tTrain_accuracy_1: 0.7959 \tTest_loss: 553.4088 \tTest_accuracy: 0.8049 \tTest_accuracy_1: 0.8179 \tTime: 5.8674\n",
      "Epoch: 599 \tTrain_loss: 601.9994 \tTrain_accuracy: 0.7973 \tTrain_accuracy_1: 0.8019 \tTest_loss: 552.2358 \tTest_accuracy: 0.8063 \tTest_accuracy_1: 0.8189 \tTime: 5.9442\n",
      "Epoch: 600 \tTrain_loss: 605.3644 \tTrain_accuracy: 0.7944 \tTrain_accuracy_1: 0.7932 \tTest_loss: 556.4561 \tTest_accuracy: 0.8045 \tTest_accuracy_1: 0.8140 \tTime: 5.8016\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "for epoch in range(600):\n",
    "    begin = time.time()\n",
    "    train_total_loss = 0\n",
    "    train_total_correct = 0\n",
    "    train_total_correct_1 = 0\n",
    "\n",
    "    for batch_idx, data_pair in enumerate(train_loader):\n",
    "        # input_pair = torch.cat((data_pair[:, :, 0], data_pair[:, :, 1]), 1).to(device)\n",
    "        \n",
    "        x = data_pair[:, :, 0].float().to(device)\n",
    "        y = data_pair[:, :, 1].float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_correct_1 = 0\n",
    "        \n",
    "        for i, x_i in enumerate(x):\n",
    "            y_i = y[i]\n",
    "            y_hat = forward_model(x_i.unsqueeze(-1), adj)\n",
    "            y_hat = y_hat.squeeze(-1)\n",
    "            forward_loss,correct_t,correct_1_t= loss_all(y_i, y_hat.squeeze(-1))\n",
    "            train_correct += correct_t\n",
    "            train_correct_1 += correct_1_t\n",
    "            train_loss += forward_loss    \n",
    "         \n",
    "        train_total_loss += train_loss.item()   \n",
    "        train_loss = train_loss/x.size(0)  \n",
    "        # train_total_loss += train_loss.item()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 训练准确度\n",
    "        \n",
    "        # train_correct = train_correct/x.size(0) \n",
    "        # train_correct_1 = train_correct_1/x.size(0) \n",
    "        train_total_correct += train_correct\n",
    "        train_total_correct_1 += train_correct_1\n",
    "        \n",
    "        for p in forward_model.parameters():\n",
    "            p.data.clamp_(min=0)\n",
    "        \n",
    "    # 在测试集上进行评估\n",
    "    test_total_loss = 0\n",
    "    test_total_correct = 0\n",
    "    test_total_correct_1 = 0\n",
    "    \n",
    "    # total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data_pair in enumerate(test_loader):\n",
    "            x = data_pair[:, :, 0].float().to(device)\n",
    "            y = data_pair[:, :, 1].float().to(device)\n",
    "            test_loss = 0.0\n",
    "            test_correct = 0\n",
    "            test_correct_1 = 0\n",
    "            \n",
    "            for i, x_i in enumerate(x):\n",
    "                y_i = y[i]\n",
    "                y_hat = forward_model(x_i.unsqueeze(-1), adj)\n",
    "                y_hat = y_hat.squeeze(-1)\n",
    "                forward_loss,correct_t,correct_1_t= loss_all(y_i, y_hat.squeeze(-1))\n",
    "                test_correct += correct_t\n",
    "                test_correct_1 += correct_1_t\n",
    "                test_loss += forward_loss\n",
    "            \n",
    "            test_total_loss += test_loss\n",
    "            test_total_correct += test_correct\n",
    "            test_total_correct_1 += test_correct_1      \n",
    "    \n",
    "            \n",
    "    end = time.time()\n",
    "    print(\"Epoch: {}\".format(epoch+1), \n",
    "          \"\\tTrain_loss: {:.4f}\".format(train_total_loss / len(train_set)),\n",
    "          \"\\tTrain_accuracy: {:.4f}\".format(train_total_correct / len(train_set)),\n",
    "          \"\\tTrain_accuracy_1: {:.4f}\".format(train_total_correct_1 / len(train_set)),\n",
    "          \"\\tTest_loss: {:.4f}\".format(test_total_loss / len(test_set)),\n",
    "          \"\\tTest_accuracy: {:.4f}\".format(test_total_correct / len(test_set)),\n",
    "          \"\\tTest_accuracy_1: {:.4f}\".format(test_total_correct_1 / len(test_set)),\n",
    "          \"\\tTime: {:.4f}\".format(end - begin)\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
