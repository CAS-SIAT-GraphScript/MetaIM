{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = '/home/zjy/project/MetaIM/deepIM/data_deepIM/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_981237/1388658084.py:23: DeprecationWarning: Please use `csr_matrix` from the `scipy.sparse` namespace, the `scipy.sparse.csr` namespace is deprecated.\n",
      "  graph = pickle.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"GenIM\")\n",
    "datasets = ['jazz', 'cora_ml', 'power_grid', 'netscience', 'random5']\n",
    "parser.add_argument(\"-d\", \"--dataset\", default=\"cora_ml\", type=str,\n",
    "                    help=\"one of: {}\".format(\", \".join(sorted(datasets))))\n",
    "diffusion = ['IC', 'LT', 'SIS']\n",
    "parser.add_argument(\"-dm\", \"--diffusion_model\", default=\"SIS\", type=str,\n",
    "                    help=\"one of: {}\".format(\", \".join(sorted(diffusion))))\n",
    "seed_rate = [1, 5, 10, 20]\n",
    "parser.add_argument(\"-sp\", \"--seed_rate\", default=1, type=int,\n",
    "                    help=\"one of: {}\".format(\", \".join(str(sorted(seed_rate)))))\n",
    "mode = ['Normal', 'Budget Constraint']\n",
    "parser.add_argument(\"-m\", \"--mode\", default=\"normal\", type=str,\n",
    "                    help=\"one of: {}\".format(\", \".join(sorted(mode))))\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "with open(pwd+ args.dataset + '_mean_' + args.diffusion_model + str(50) + '.SG', 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(140.)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['inverse_pairs'][0][:,0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import ndlib.models.ModelConfig as mc\n",
    "import ndlib.models.epidemics as ep\n",
    "\n",
    "def diffusion_evaluation(adj_matrix, seed, diffusion='LT'):\n",
    "\n",
    "    total_infect = 0\n",
    "    G = nx.from_scipy_sparse_array(adj_matrix)\n",
    "    inflect_vec = np.zeros(len(G.nodes()))\n",
    "    for i in range(10):\n",
    "        \n",
    "        if diffusion == 'LT':\n",
    "            model = ep.ThresholdModel(G)\n",
    "            config = mc.Configuration()\n",
    "            for n in G.nodes():\n",
    "                config.add_node_configuration(\"threshold\", n, 0.5)\n",
    "        elif diffusion == 'IC':\n",
    "            model = ep.IndependentCascadesModel(G)\n",
    "            config = mc.Configuration()\n",
    "            for e in G.edges():\n",
    "                config.add_edge_configuration(\"threshold\", e, 1/nx.degree(G)[e[1]])\n",
    "        elif diffusion == 'SIS':\n",
    "            model = ep.SISModel(G)\n",
    "            config = mc.Configuration()\n",
    "            config.add_model_parameter('beta', 0.001)\n",
    "            config.add_model_parameter('lambda', 0.001)\n",
    "        else:\n",
    "            raise ValueError('Only IC, LT and SIS are supported.')\n",
    "\n",
    "        config.add_model_initial_configuration(\"Infected\", seed)\n",
    "\n",
    "        model.set_initial_status(config)\n",
    "\n",
    "        iterations = model.iteration_bunch(100)\n",
    "\n",
    "        node_status = iterations[0]['status']\n",
    "\n",
    "        seed_vec = np.array(list(node_status.values()))\n",
    "\n",
    "        for j in range(1, len(iterations)):\n",
    "            node_status.update(iterations[j]['status'])\n",
    "\n",
    "        inf_vec = np.array(list(node_status.values()))\n",
    "        inf_vec[inf_vec == 2] = 1\n",
    "        \n",
    "        inflect_vec += inf_vec\n",
    "\n",
    "        # total_infect += inf_vec.sum()\n",
    "    \n",
    "    inflect_vec[inflect_vec > 0] = 1\n",
    "    \n",
    "    return inflect_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/51r_nlz93n7__jn387b614040000gn/T/ipykernel_81968/4003716307.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(graph['inverse_pairs'][0][:,0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([   5,   17,   33,   34,   35,   45,   47,   49,   57,   59,   60,\n",
       "         66,   82,   84,   86,   87,   93,   94,   96,  102,  103,  106,\n",
       "        107,  119,  124,  129,  132,  140,  169,  188,  189,  234,  236,\n",
       "        241,  249,  264,  315,  347,  413,  433,  466,  499,  509,  525,\n",
       "        554,  555,  557,  562,  565,  589,  602,  611,  614,  645,  693,\n",
       "        730,  851,  852,  856, 1021, 1049, 1059, 1060, 1063, 1101, 1109,\n",
       "       1146, 1152, 1185, 1190, 1199, 1261, 1268, 1278, 1289, 1296, 1341,\n",
       "       1385, 1391, 1393, 1399, 1416, 1439, 1446, 1450, 1563, 1581, 1582,\n",
       "       1702, 1724, 1763, 1775, 1787, 1848, 1902, 1933, 1946, 1955, 1969,\n",
       "       1973, 2036, 2100, 2108, 2111, 2120, 2122, 2130, 2140, 2171, 2197,\n",
       "       2210, 2240, 2301, 2325, 2344, 2347, 2349, 2374, 2390, 2401, 2402,\n",
       "       2407, 2470, 2483, 2504, 2545, 2550, 2568, 2573, 2575, 2677, 2698,\n",
       "       2700, 2722, 2735, 2736, 2742, 2751, 2769, 2773])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "input = torch.tensor(graph['inverse_pairs'][0][:,0])\n",
    "seed = (input > 0).nonzero().flatten().detach().numpy()\n",
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = graph['adj']\n",
    "inflect_vec = diffusion_evaluation(adj, seed, diffusion = args.diffusion_model)\n",
    "inflect_vec.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflect_vec_t = np.zeros((len(inflect_vec),len(inflect_vec)))\n",
    "inflect_vec_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "# 定义任务函数\n",
    "def evaluate_diffusion(adj_matrix, seed, diffusion_model):\n",
    "    return diffusion_evaluation(adj_matrix, seed, diffusion_model)\n",
    "\n",
    "# 创建线程池\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    # 提交任务并获取结果\n",
    "    future_to_index = {executor.submit(evaluate_diffusion, adj, [i], args.diffusion_model): i for i in range(len(inflect_vec))}\n",
    "    for future in concurrent.futures.as_completed(future_to_index):\n",
    "        index = future_to_index[future]\n",
    "        inflect_vec_t[index] = future.result()\n",
    "\n",
    "# 输出结果\n",
    "print(inflect_vec_t)\n",
    "\n",
    "\n",
    "# for i in range(len(inflect_vec)):\n",
    "#     inflect_vec_t[i] = diffusion_evaluation(adj, [i], diffusion = args.diffusion_model)\n",
    "# inflect_vec_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数组保存到本地文件\n",
    "np.save(f'cora_{args.diffusion_model}_50.npy', inflect_vec_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 读取 .npy 文件\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcora_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43margs\u001b[49m\u001b[38;5;241m.\u001b[39mdiffusion_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_50_e.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m data\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 读取 .npy 文件\n",
    "data = np.load(f'cora_{args.diffusion_model}_50_e.npy')\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflect_vec_T = np.zeros(len(inflect_vec))\n",
    "for i in range(len(seed)):\n",
    "    inflect_vec_T += inflect_vec_t[seed[i]]\n",
    "\n",
    "inflect_vec_T[inflect_vec_T > 0] = 1\n",
    "inflect_vec_T.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adj': <2810x2810 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 15962 stored elements in Compressed Sparse Row format>,\n",
       " 'inverse_pairs': tensor([[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 1.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 0.]]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_out = graph\n",
    "graph_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9b/51r_nlz93n7__jn387b614040000gn/T/ipykernel_23061/3219990898.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_t = torch.tensor(graph['inverse_pairs'][i][:,0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'adj': <2810x2810 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 15962 stored elements in Compressed Sparse Row format>,\n",
       " 'inverse_pairs': tensor([[[0., 0.],\n",
       "          [0., 0.],\n",
       "          [0., 0.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         [[0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 0.]],\n",
       " \n",
       "         [[0., 0.],\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.]],\n",
       " \n",
       "         [[0., 1.],\n",
       "          [0., 1.],\n",
       "          [0., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          [1., 1.]]])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = graph['adj']\n",
    "for i in range(graph['inverse_pairs'].shape[0]):\n",
    "    input_t = torch.tensor(graph['inverse_pairs'][i][:,0])\n",
    "    seed_t = (input_t > 0).nonzero().flatten().detach().numpy()\n",
    "    inflect_vec_feat = np.zeros(len(inflect_vec))\n",
    "    for j in range(len(seed_t)):\n",
    "        inflect_vec_feat += inflect_vec_t[seed_t[j]]\n",
    "    inflect_vec_feat[inflect_vec_feat > 0] = 1\n",
    "    inflect_vec_label = diffusion_evaluation(adj, seed_t, diffusion = args.diffusion_model)\n",
    "    graph_out['inverse_pairs'][i][:, 0] = torch.tensor(inflect_vec_feat)\n",
    "    graph_out['inverse_pairs'][i][:, 1] = torch.tensor(inflect_vec_label)\n",
    "    \n",
    "graph_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_out['inverse_pairs'] = graph_out['inverse_pairs'].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# 保存字典到本地文件\n",
    "with open('cora_SIS_50.SG', 'wb') as f:\n",
    "    pickle.dump(graph_out, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('cora_LT_50.SG', 'rb') as f:\n",
    "    graph = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def normalize_adj(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    r_inv_sqrt[np.isinf(r_inv_sqrt)] = 0.\n",
    "    r_mat_inv_sqrt = sp.diags(r_inv_sqrt)\n",
    "    return mx.dot(r_mat_inv_sqrt).transpose().dot(r_mat_inv_sqrt)\n",
    "\n",
    "batch_size = 16\n",
    "hidden_dim = 1024\n",
    "latent_dim = 512\n",
    "\n",
    "adj, inverse_pairs = graph['adj'], graph['inverse_pairs']\n",
    "adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
    "adj = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "adj = torch.Tensor(adj.toarray()).to_sparse()\n",
    "\n",
    "train_set, test_set = torch.utils.data.random_split(inverse_pairs, \n",
    "                                                    [len(inverse_pairs)-batch_size, \n",
    "                                                     batch_size])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "test_loader  = DataLoader(dataset=test_set,  batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpGAT(\n",
       "  (attention_0): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention_1): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention_2): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention_3): SpGraphAttentionLayer (1 -> 64)\n",
       "  (attention1_0): SpGraphAttentionLayer (256 -> 64)\n",
       "  (attention1_1): SpGraphAttentionLayer (256 -> 64)\n",
       "  (attention1_2): SpGraphAttentionLayer (256 -> 64)\n",
       "  (attention1_3): SpGraphAttentionLayer (256 -> 64)\n",
       "  (out_att): SpGraphAttentionLayer (256 -> 1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main.model.gat import GAT, SpGAT\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "\n",
    "forward_model = SpGAT(nfeat=1, \n",
    "                nhid=64, \n",
    "                nclass=1, \n",
    "                dropout=0.2, \n",
    "                nheads=4, \n",
    "                alpha=0.2)\n",
    "\n",
    "optimizer = Adam([{'params': forward_model.parameters()}], \n",
    "                 lr=1e-3)\n",
    "\n",
    "adj = adj.to(device)\n",
    "forward_model = forward_model.to(device)\n",
    "forward_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTotal: 1499.0434 \tTest_loss: 1424.5707 \tTest_accuracy: 0.7877 \tTest_accuracy_1: 0.8820 \tTime: 5.9139\n",
      "Epoch: 2 \tTotal: 1502.8730 \tTest_loss: 1434.0422 \tTest_accuracy: 0.7834 \tTest_accuracy_1: 0.8795 \tTime: 5.8210\n",
      "Epoch: 3 \tTotal: 1500.1562 \tTest_loss: 1435.6721 \tTest_accuracy: 0.7844 \tTest_accuracy_1: 0.8713 \tTime: 5.6824\n",
      "Epoch: 4 \tTotal: 1503.0981 \tTest_loss: 1427.6118 \tTest_accuracy: 0.7864 \tTest_accuracy_1: 0.8793 \tTime: 5.6809\n",
      "Epoch: 5 \tTotal: 1500.2390 \tTest_loss: 1427.3278 \tTest_accuracy: 0.7844 \tTest_accuracy_1: 0.8801 \tTime: 5.7007\n",
      "Epoch: 6 \tTotal: 1504.5316 \tTest_loss: 1426.1654 \tTest_accuracy: 0.7856 \tTest_accuracy_1: 0.8805 \tTime: 5.6905\n",
      "Epoch: 7 \tTotal: 1498.1593 \tTest_loss: 1430.8925 \tTest_accuracy: 0.7825 \tTest_accuracy_1: 0.8729 \tTime: 5.6599\n",
      "Epoch: 8 \tTotal: 1499.8725 \tTest_loss: 1420.9655 \tTest_accuracy: 0.7830 \tTest_accuracy_1: 0.8890 \tTime: 5.6602\n",
      "Epoch: 9 \tTotal: 1503.3292 \tTest_loss: 1428.4436 \tTest_accuracy: 0.7848 \tTest_accuracy_1: 0.8810 \tTime: 5.6978\n",
      "Epoch: 10 \tTotal: 1497.0268 \tTest_loss: 1436.4327 \tTest_accuracy: 0.7831 \tTest_accuracy_1: 0.8758 \tTime: 5.8459\n",
      "Epoch: 11 \tTotal: 1498.2577 \tTest_loss: 1434.6586 \tTest_accuracy: 0.7849 \tTest_accuracy_1: 0.8783 \tTime: 5.7861\n",
      "Epoch: 12 \tTotal: 1499.8900 \tTest_loss: 1434.8149 \tTest_accuracy: 0.7845 \tTest_accuracy_1: 0.8724 \tTime: 5.7298\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m total_overall \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m/\u001b[39mx\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m forward_model\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m~/anaconda3/envs/mdp/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mdp/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mdp/lib/python3.10/site-packages/torch/autograd/function.py:288\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    287\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/projects/DeepIM/main/model/gat.py:128\u001b[0m, in \u001b[0;36mSpecialSpmmFunction.backward\u001b[0;34m(ctx, grad_output)\u001b[0m\n\u001b[1;32m    126\u001b[0m grad_values \u001b[38;5;241m=\u001b[39m grad_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mneeds_input_grad[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 128\u001b[0m     grad_a_dense \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     edge_idx \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_indices()[\u001b[38;5;241m0\u001b[39m, :] \u001b[38;5;241m*\u001b[39m ctx\u001b[38;5;241m.\u001b[39mN \u001b[38;5;241m+\u001b[39m a\u001b[38;5;241m.\u001b[39m_indices()[\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m    130\u001b[0m     grad_values \u001b[38;5;241m=\u001b[39m grad_a_dense\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[edge_idx]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(600):\n",
    "    begin = time.time()\n",
    "    total_overall = 0\n",
    "    forward_loss = 0\n",
    "\n",
    "    for batch_idx, data_pair in enumerate(train_loader):\n",
    "        # input_pair = torch.cat((data_pair[:, :, 0], data_pair[:, :, 1]), 1).to(device)\n",
    "        \n",
    "        x = data_pair[:, :, 0].float().to(device)\n",
    "        y = data_pair[:, :, 1].float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        for i, x_i in enumerate(x):\n",
    "            y_i = y[i]\n",
    "            y_hat = forward_model(x_i.unsqueeze(-1), adj)\n",
    "            # forward_loss = F.mse_loss(y_hat.squeeze(-1), y_i, reduction='sum')\n",
    "            forward_loss = F.binary_cross_entropy(y_hat.squeeze(-1), y_i, reduction='sum')            \n",
    "            loss += forward_loss    \n",
    "        \n",
    "        total_overall += loss.item()\n",
    "        loss = loss/x.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        for p in forward_model.parameters():\n",
    "            p.data.clamp_(min=0)\n",
    "        \n",
    "        \n",
    "    # 在测试集上进行评估\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    correct_1 = 0\n",
    "    # total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data_pair in enumerate(test_loader):\n",
    "            x = data_pair[:, :, 0].float().to(device)\n",
    "            y = data_pair[:, :, 1].float().to(device)\n",
    "            \n",
    "            correct_t = 0\n",
    "            correct_t_1 = 0\n",
    "            count = 0\n",
    "            for i, x_i in enumerate(x):\n",
    "                count += 1\n",
    "                y_i = y[i]\n",
    "            \n",
    "                y_hat = forward_model(x_i.unsqueeze(-1), adj)\n",
    "                # forward_loss = F.mse_loss(y_hat.squeeze(-1), y_i, reduction='sum')\n",
    "                forward_loss = F.binary_cross_entropy(y_hat.squeeze(-1), y_i, reduction='sum')         \n",
    "                test_loss += forward_loss\n",
    "                \n",
    "                # 将大于阈值的元素设置为 1，小于等于阈值的元素设置为 0\n",
    "                threshold = 0.6\n",
    "                y_pre = y_hat.squeeze(-1)\n",
    "                \n",
    "                filtered_y_hat = (y_pre > threshold).float()\n",
    "\n",
    "                correct_t += ((filtered_y_hat == y_i).sum()/len(y_i))\n",
    "                \n",
    "                count_both_ones = torch.sum((filtered_y_hat == 1) & (y_i == 1))\n",
    "                correct_t_1 += count_both_ones/y_i.sum()\n",
    "                \n",
    "            correct_t /= count\n",
    "            correct_t_1 /= count\n",
    "            correct += correct_t\n",
    "            correct_1 += correct_t_1\n",
    "            \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    test_accuracy_1 = correct_1/ len(test_loader.dataset)\n",
    "            \n",
    "    end = time.time()\n",
    "    print(\"Epoch: {}\".format(epoch+1), \n",
    "          \"\\tTotal: {:.4f}\".format(total_overall / len(train_set)),\n",
    "          \"\\tTest_loss: {:.4f}\".format(test_loss),\n",
    "          \"\\tTest_accuracy: {:.4f}\".format(test_accuracy),\n",
    "          \"\\tTest_accuracy_1: {:.4f}\".format(test_accuracy_1),\n",
    "        #   \"\\tReconstruction Precision: {:.4f}\".format(precision_re / len(train_set)),\n",
    "        #   \"\\tReconstruction Recall: {:.4f}\".format(recall_re / len(train_set)),\n",
    "          \"\\tTime: {:.4f}\".format(end - begin)\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
